game: laser_tag(horizon=20)

GameType.chance_mode = ChanceMode.EXPLICIT_STOCHASTIC
GameType.dynamics = Dynamics.SIMULTANEOUS
GameType.information = Information.PERFECT_INFORMATION
GameType.long_name = "Laser Tag"
GameType.max_num_players = 2
GameType.min_num_players = 2
GameType.parameter_specification = ["grid", "horizon", "zero_sum"]
GameType.provides_information_state_string = False
GameType.provides_information_state_tensor = False
GameType.provides_observation_string = True
GameType.provides_observation_tensor = True
GameType.provides_factored_observation_string = False
GameType.reward_model = RewardModel.REWARDS
GameType.short_name = "laser_tag"
GameType.utility = Utility.GENERAL_SUM

NumDistinctActions() = 10
PolicyTensorShape() = [10]
MaxChanceOutcomes() = 6
GetParameters() = {grid=S.....S\n.......\n..*.*..\n.**.**.\n..*.*..\n.......\nS.....S,horizon=20,zero_sum=False}
NumPlayers() = 2
MinUtility() = -20.0
MaxUtility() = 20.0
UtilitySum() = 0.0
ObservationTensorShape() = [4, 7, 7]
ObservationTensorLayout() = TensorLayout.CHW
ObservationTensorSize() = 196
MaxGameLength() = 20
ToString() = "laser_tag(horizon=20)"

# State 0
# .......
# .......
# ..*.*..
# .**.**.
# ..*.*..
# .......
# .......
# Orientations: 1 1
# Chance Node
IsTerminal() = False
History() = []
HistoryString() = ""
IsChanceNode() = True
IsSimultaneousNode() = False
CurrentPlayer() = -1
ObservationString(0) = ".......\n.......\n..*.*..\n.**.**.\n..*.*..\n.......\n.......\nOrientations: 1 1\nChance Node"
ObservationString(1) = ".......\n.......\n..*.*..\n.**.**.\n..*.*..\n.......\n.......\nOrientations: 1 1\nChance Node"
ObservationTensor(0):
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◉◯◉◯◉◉  ◯◯◉◯◉◯◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◯◯◉◯◯◉  ◯◉◉◯◉◉◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◉◯◉◯◉◉  ◯◯◉◯◉◯◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◉◯◉◯◉◉  ◯◯◉◯◉◯◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◯◯◉◯◯◉  ◯◉◉◯◉◉◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◉◯◉◯◉◉  ◯◯◉◯◉◯◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯
ChanceOutcomes() = [(2, 0.25), (3, 0.25), (4, 0.25), (5, 0.25)]
LegalActions() = [2, 3, 4, 5]
StringLegalActions() = ["(spawned at location #0)", "(spawned at location #1)", "(spawned at location #2)", "(spawned at location #3)"]

# Apply action "(spawned at location #1)"
action: 3

# State 1
# ......B
# .......
# ..*.*..
# .**.**.
# ..*.*..
# .......
# .......
# Orientations: 1 1
# Chance Node
IsTerminal() = False
History() = [3]
HistoryString() = "3"
IsChanceNode() = True
IsSimultaneousNode() = False
CurrentPlayer() = -1
ObservationString(0) = "......B\n.......\n..*.*..\n.**.**.\n..*.*..\n.......\n.......\nOrientations: 1 1\nChance Node"
ObservationString(1) = "......B\n.......\n..*.*..\n.**.**.\n..*.*..\n.......\n.......\nOrientations: 1 1\nChance Node"
ObservationTensor(0):
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◉  ◉◉◉◉◉◉◯  ◯◯◯◯◯◯◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◉◯◉◯◉◉  ◯◯◉◯◉◯◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◯◯◉◯◯◉  ◯◉◉◯◉◉◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◉◯◉◯◉◉  ◯◯◉◯◉◯◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◉  ◉◉◉◉◉◉◯  ◯◯◯◯◯◯◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◉◯◉◯◉◉  ◯◯◉◯◉◯◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◯◯◉◯◯◉  ◯◉◉◯◉◉◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◉◯◉◯◉◉  ◯◯◉◯◉◯◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯
ChanceOutcomes() = [(2, 0.3333333333333333), (4, 0.3333333333333333), (5, 0.3333333333333333)]
LegalActions() = [2, 4, 5]
StringLegalActions() = ["(spawned at location #0)", "(spawned at location #2)", "(spawned at location #3)"]

# Apply action "(spawned at location #3)"
action: 5

# State 2
# ......B
# .......
# ..*.*..
# .**.**.
# ..*.*..
# .......
# ......A
# Orientations: 1 1
IsTerminal() = False
History() = [3, 5]
HistoryString() = "3, 5"
IsChanceNode() = False
IsSimultaneousNode() = True
CurrentPlayer() = -2
ObservationString(0) = "......B\n.......\n..*.*..\n.**.**.\n..*.*..\n.......\n......A\nOrientations: 1 1\n"
ObservationString(1) = "......B\n.......\n..*.*..\n.**.**.\n..*.*..\n.......\n......A\nOrientations: 1 1\n"
ObservationTensor(0):
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◉  ◉◉◉◉◉◉◯  ◯◯◯◯◯◯◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◉◯◉◯◉◉  ◯◯◉◯◉◯◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◯◯◉◯◯◉  ◯◉◉◯◉◉◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◉◯◉◯◉◉  ◯◯◉◯◉◯◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯
◯◯◯◯◯◯◉  ◯◯◯◯◯◯◯  ◉◉◉◉◉◉◯  ◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◉  ◉◉◉◉◉◉◯  ◯◯◯◯◯◯◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◉◯◉◯◉◉  ◯◯◉◯◉◯◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◯◯◉◯◯◉  ◯◉◉◯◉◉◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◉◯◉◯◉◉  ◯◯◉◯◉◯◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯
◯◯◯◯◯◯◉  ◯◯◯◯◯◯◯  ◉◉◉◉◉◉◯  ◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions(0) = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
LegalActions(1) = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
StringLegalActions(0) = ["left turn", "right turn", "move forward", "move backward", "step left", "step right", "stand", "step forward and left turn", "step forward and right turn", "fire"]
StringLegalActions(1) = ["left turn", "right turn", "move forward", "move backward", "step left", "step right", "stand", "step forward and left turn", "step forward and right turn", "fire"]

# Apply joint action ["step forward and left turn", "step forward and right turn"]
actions: [7, 8]

# State 3
# Apply action "(A's action first)"
action: 0

# State 4
# .......
# ......B
# ..*.*..
# .**.**.
# ..*.*..
# .......
# ......A
# Orientations: 1 3
IsTerminal() = False
History() = [3, 5, 7, 8, 0]
HistoryString() = "3, 5, 7, 8, 0"
IsChanceNode() = False
IsSimultaneousNode() = True
CurrentPlayer() = -2
ObservationString(0) = ".......\n......B\n..*.*..\n.**.**.\n..*.*..\n.......\n......A\nOrientations: 1 3\n"
ObservationString(1) = ".......\n......B\n..*.*..\n.**.**.\n..*.*..\n.......\n......A\nOrientations: 1 3\n"
ObservationTensor(0):
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◉  ◉◉◉◉◉◉◯  ◯◯◯◯◯◯◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◉◯◉◯◉◉  ◯◯◉◯◉◯◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◯◯◉◯◯◉  ◯◉◉◯◉◉◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◉◯◉◯◉◉  ◯◯◉◯◉◯◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯
◯◯◯◯◯◯◉  ◯◯◯◯◯◯◯  ◉◉◉◉◉◉◯  ◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◉  ◉◉◉◉◉◉◯  ◯◯◯◯◯◯◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◉◯◉◯◉◉  ◯◯◉◯◉◯◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◯◯◉◯◯◉  ◯◉◉◯◉◉◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◉◯◉◯◉◉  ◯◯◉◯◉◯◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯
◯◯◯◯◯◯◉  ◯◯◯◯◯◯◯  ◉◉◉◉◉◉◯  ◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions(0) = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
LegalActions(1) = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
StringLegalActions(0) = ["left turn", "right turn", "move forward", "move backward", "step left", "step right", "stand", "step forward and left turn", "step forward and right turn", "fire"]
StringLegalActions(1) = ["left turn", "right turn", "move forward", "move backward", "step left", "step right", "stand", "step forward and left turn", "step forward and right turn", "fire"]

# Apply joint action ["move backward", "step left"]
actions: [3, 4]

# State 5
# Apply action "(B's action first)"
action: 1

# State 6
# .......
# .......
# ..*.*.B
# .**.**.
# ..*.*..
# ......A
# .......
# Orientations: 1 3
IsTerminal() = False
History() = [3, 5, 7, 8, 0, 3, 4, 1]
HistoryString() = "3, 5, 7, 8, 0, 3, 4, 1"
IsChanceNode() = False
IsSimultaneousNode() = True
CurrentPlayer() = -2
ObservationString(0) = ".......\n.......\n..*.*.B\n.**.**.\n..*.*..\n......A\n.......\nOrientations: 1 3\n"
ObservationString(1) = ".......\n.......\n..*.*.B\n.**.**.\n..*.*..\n......A\n.......\nOrientations: 1 3\n"
ObservationTensor(0):
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◉  ◉◉◯◉◯◉◯  ◯◯◉◯◉◯◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◯◯◉◯◯◉  ◯◉◉◯◉◉◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◉◯◉◯◉◉  ◯◯◉◯◉◯◯
◯◯◯◯◯◯◉  ◯◯◯◯◯◯◯  ◉◉◉◉◉◉◯  ◯◯◯◯◯◯◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◉  ◉◉◯◉◯◉◯  ◯◯◉◯◉◯◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◯◯◉◯◯◉  ◯◉◉◯◉◉◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◉◯◉◯◉◉  ◯◯◉◯◉◯◯
◯◯◯◯◯◯◉  ◯◯◯◯◯◯◯  ◉◉◉◉◉◉◯  ◯◯◯◯◯◯◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions(0) = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
LegalActions(1) = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
StringLegalActions(0) = ["left turn", "right turn", "move forward", "move backward", "step left", "step right", "stand", "step forward and left turn", "step forward and right turn", "fire"]
StringLegalActions(1) = ["left turn", "right turn", "move forward", "move backward", "step left", "step right", "stand", "step forward and left turn", "step forward and right turn", "fire"]

# Apply joint action ["step right", "fire"]
actions: [5, 9]

# State 7
# Apply action "(B's action first)"
action: 1

# State 8
# Apply joint action ["fire", "step right"]
actions: [9, 5]

# State 9
# Apply action "(A's action first)"
action: 0

# State 10
# Apply joint action ["move backward", "move forward"]
actions: [3, 2]

# State 11
# Apply action "(B's action first)"
action: 1

# State 12
# Apply joint action ["move forward", "step left"]
actions: [2, 4]

# State 13
# Apply action "(A's action first)"
action: 0

# State 14
# Apply joint action ["move forward", "step left"]
actions: [2, 4]

# State 15
# Apply action "(B's action first)"
action: 1

# State 16
# Apply joint action ["stand", "move backward"]
actions: [6, 3]

# State 17
# Apply action "(B's action first)"
action: 1

# State 18
# Apply joint action ["move backward", "right turn"]
actions: [3, 1]

# State 19
# Apply action "(B's action first)"
action: 1

# State 20
# Apply joint action ["step left", "step left"]
actions: [4, 4]

# State 21
# Apply action "(A's action first)"
action: 0

# State 22
# .......
# .......
# ..*.*B.
# .**.**.
# ..*.*..
# ......A
# .......
# Orientations: 1 0
IsTerminal() = False
History() = [3, 5, 7, 8, 0, 3, 4, 1, 5, 9, 1, 9, 5, 0, 3, 2, 1, 2, 4, 0, 2, 4, 1, 6, 3, 1, 3, 1, 1, 4, 4, 0]
HistoryString() = "3, 5, 7, 8, 0, 3, 4, 1, 5, 9, 1, 9, 5, 0, 3, 2, 1, 2, 4, 0, 2, 4, 1, 6, 3, 1, 3, 1, 1, 4, 4, 0"
IsChanceNode() = False
IsSimultaneousNode() = True
CurrentPlayer() = -2
ObservationString(0) = ".......\n.......\n..*.*B.\n.**.**.\n..*.*..\n......A\n.......\nOrientations: 1 0\n"
ObservationString(1) = ".......\n.......\n..*.*B.\n.**.**.\n..*.*..\n......A\n.......\nOrientations: 1 0\n"
ObservationTensor(0):
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯  ◉◉◯◉◯◯◉  ◯◯◉◯◉◯◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◯◯◉◯◯◉  ◯◉◉◯◉◉◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◉◯◉◯◉◉  ◯◯◉◯◉◯◯
◯◯◯◯◯◯◉  ◯◯◯◯◯◯◯  ◉◉◉◉◉◉◯  ◯◯◯◯◯◯◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯  ◉◉◯◉◯◯◉  ◯◯◉◯◉◯◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◯◯◉◯◯◉  ◯◉◉◯◉◉◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◉◯◉◯◉◉  ◯◯◉◯◉◯◯
◯◯◯◯◯◯◉  ◯◯◯◯◯◯◯  ◉◉◉◉◉◉◯  ◯◯◯◯◯◯◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions(0) = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
LegalActions(1) = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
StringLegalActions(0) = ["left turn", "right turn", "move forward", "move backward", "step left", "step right", "stand", "step forward and left turn", "step forward and right turn", "fire"]
StringLegalActions(1) = ["left turn", "right turn", "move forward", "move backward", "step left", "step right", "stand", "step forward and left turn", "step forward and right turn", "fire"]

# Apply joint action ["stand", "right turn"]
actions: [6, 1]

# State 23
# Apply action "(A's action first)"
action: 0

# State 24
# Apply joint action ["right turn", "fire"]
actions: [1, 9]

# State 25
# Apply action "(A's action first)"
action: 0

# State 26
# Apply joint action ["stand", "stand"]
actions: [6, 6]

# State 27
# Apply action "(B's action first)"
action: 1

# State 28
# Apply joint action ["step forward and right turn", "stand"]
actions: [8, 6]

# State 29
# Apply action "(B's action first)"
action: 1

# State 30
# Apply joint action ["stand", "step left"]
actions: [6, 4]

# State 31
# Apply action "(B's action first)"
action: 1

# State 32
# Apply joint action ["move backward", "step forward and right turn"]
actions: [3, 8]

# State 33
# Apply action "(A's action first)"
action: 0

# State 34
# Apply joint action ["step forward and right turn", "left turn"]
actions: [8, 0]

# State 35
# Apply action "(A's action first)"
action: 0

# State 36
# Apply joint action ["step left", "move backward"]
actions: [4, 3]

# State 37
# Apply action "(A's action first)"
action: 0

# State 38
# Apply joint action ["step left", "step left"]
actions: [4, 4]

# State 39
# Apply action "(A's action first)"
action: 0

# State 40
# Apply joint action ["left turn", "fire"]
actions: [0, 9]

# State 41
# Apply action "(A's action first)"
action: 0

# State 42
# .....B.
# .......
# ..*.*..
# .**.**.
# ..*.*A.
# .......
# .......
# Orientations: 0 2
IsTerminal() = True
History() = [3, 5, 7, 8, 0, 3, 4, 1, 5, 9, 1, 9, 5, 0, 3, 2, 1, 2, 4, 0, 2, 4, 1, 6, 3, 1, 3, 1, 1, 4, 4, 0, 6, 1, 0, 1, 9, 0, 6, 6, 1, 8, 6, 1, 6, 4, 1, 3, 8, 0, 8, 0, 0, 4, 3, 0, 4, 4, 0, 0, 9, 0]
HistoryString() = "3, 5, 7, 8, 0, 3, 4, 1, 5, 9, 1, 9, 5, 0, 3, 2, 1, 2, 4, 0, 2, 4, 1, 6, 3, 1, 3, 1, 1, 4, 4, 0, 6, 1, 0, 1, 9, 0, 6, 6, 1, 8, 6, 1, 6, 4, 1, 3, 8, 0, 8, 0, 0, 4, 3, 0, 4, 4, 0, 0, 9, 0"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = -4
ObservationString(0) = ".....B.\n.......\n..*.*..\n.**.**.\n..*.*A.\n.......\n.......\nOrientations: 0 2\n"
ObservationString(1) = ".....B.\n.......\n..*.*..\n.**.**.\n..*.*A.\n.......\n.......\nOrientations: 0 2\n"
ObservationTensor(0):
◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯  ◉◉◉◉◉◯◉  ◯◯◯◯◯◯◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◉◯◉◯◉◉  ◯◯◉◯◉◯◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◯◯◉◯◯◉  ◯◉◉◯◉◉◯
◯◯◯◯◯◉◯  ◯◯◯◯◯◯◯  ◉◉◯◉◯◯◉  ◯◯◉◯◉◯◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯  ◉◉◉◉◉◯◉  ◯◯◯◯◯◯◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◉◯◉◯◉◉  ◯◯◉◯◉◯◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◯◯◉◯◯◉  ◯◉◉◯◉◉◯
◯◯◯◯◯◉◯  ◯◯◯◯◯◯◯  ◉◉◯◉◯◯◉  ◯◯◉◯◉◯◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯
◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉  ◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
