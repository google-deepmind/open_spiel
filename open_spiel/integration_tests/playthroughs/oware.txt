game: oware

GameType.chance_mode = ChanceMode.DETERMINISTIC
GameType.dynamics = Dynamics.SEQUENTIAL
GameType.information = Information.PERFECT_INFORMATION
GameType.long_name = "Oware"
GameType.max_num_players = 2
GameType.min_num_players = 2
GameType.parameter_specification = ["num_houses_per_player", "num_seeds_per_house"]
GameType.provides_information_state_string = False
GameType.provides_information_state_tensor = False
GameType.provides_observation_string = True
GameType.provides_observation_tensor = True
GameType.provides_factored_observation_string = False
GameType.reward_model = RewardModel.TERMINAL
GameType.short_name = "oware"
GameType.utility = Utility.ZERO_SUM

NumDistinctActions() = 6
PolicyTensorShape() = [6]
MaxChanceOutcomes() = 0
GetParameters() = {num_houses_per_player=6,num_seeds_per_house=4}
NumPlayers() = 2
MinUtility() = -1.0
MaxUtility() = 1.0
UtilitySum() = 0.0
ObservationTensorShape() = [14]
ObservationTensorLayout() = TensorLayout.CHW
ObservationTensorSize() = 14
MaxGameLength() = 1000
ToString() = "oware()"

# State 0
# Player 1 score = 0
#   f  e  d  c  b  a
#   4  4  4  4  4  4
#   4  4  4  4  4  4
#   A  B  C  D  E  F
# Player 0 score = 0 [PLAYING]
IsTerminal() = False
History() = []
HistoryString() = ""
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "0 | 0 0 | 4 4 4 4 4 4 4 4 4 4 4 4"
ObservationString(1) = "0 | 0 0 | 4 4 4 4 4 4 4 4 4 4 4 4"
ObservationTensor(0) = [0.08333, 0.08333, 0.08333, 0.08333, 0.08333, 0.08333, 0.08333, 0.08333, 0.08333, 0.08333, 0.08333, 0.08333, 0.0, 0.0]
ObservationTensor(1) = [0.08333, 0.08333, 0.08333, 0.08333, 0.08333, 0.08333, 0.08333, 0.08333, 0.08333, 0.08333, 0.08333, 0.08333, 0.0, 0.0]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 2, 3, 4, 5]
StringLegalActions() = ["A", "B", "C", "D", "E", "F"]

# Apply action "C"
action: 2

# State 1
# Player 1 score = 0 [PLAYING]
#   f  e  d  c  b  a
#   4  4  4  4  4  5
#   4  4  0  5  5  5
#   A  B  C  D  E  F
# Player 0 score = 0
IsTerminal() = False
History() = [2]
HistoryString() = "2"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
ObservationString(0) = "1 | 0 0 | 4 4 0 5 5 5 5 4 4 4 4 4"
ObservationString(1) = "1 | 0 0 | 4 4 0 5 5 5 5 4 4 4 4 4"
ObservationTensor(0) = [0.08333, 0.08333, 0.0, 0.10417, 0.10417, 0.10417, 0.10417, 0.08333, 0.08333, 0.08333, 0.08333, 0.08333, 0.0, 0.0]
ObservationTensor(1) = [0.08333, 0.08333, 0.0, 0.10417, 0.10417, 0.10417, 0.10417, 0.08333, 0.08333, 0.08333, 0.08333, 0.08333, 0.0, 0.0]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 2, 3, 4, 5]
StringLegalActions() = ["a", "b", "c", "d", "e", "f"]

# Apply action "f"
action: 5

# State 2
# Player 1 score = 0
#   f  e  d  c  b  a
#   0  4  4  4  4  5
#   5  5  1  6  5  5
#   A  B  C  D  E  F
# Player 0 score = 0 [PLAYING]
IsTerminal() = False
History() = [2, 5]
HistoryString() = "2 5"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "0 | 0 0 | 5 5 1 6 5 5 5 4 4 4 4 0"
ObservationString(1) = "0 | 0 0 | 5 5 1 6 5 5 5 4 4 4 4 0"
ObservationTensor(0) = [0.10417, 0.10417, 0.02083, 0.125, 0.10417, 0.10417, 0.10417, 0.08333, 0.08333, 0.08333, 0.08333, 0.0, 0.0, 0.0]
ObservationTensor(1) = [0.10417, 0.10417, 0.02083, 0.125, 0.10417, 0.10417, 0.10417, 0.08333, 0.08333, 0.08333, 0.08333, 0.0, 0.0, 0.0]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 2, 3, 4, 5]
StringLegalActions() = ["A", "B", "C", "D", "E", "F"]

# Apply action "C"
action: 2

# State 3
# Player 1 score = 0 [PLAYING]
#   f  e  d  c  b  a
#   0  4  4  4  4  5
#   5  5  0  7  5  5
#   A  B  C  D  E  F
# Player 0 score = 0
IsTerminal() = False
History() = [2, 5, 2]
HistoryString() = "2 5 2"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
ObservationString(0) = "1 | 0 0 | 5 5 0 7 5 5 5 4 4 4 4 0"
ObservationString(1) = "1 | 0 0 | 5 5 0 7 5 5 5 4 4 4 4 0"
ObservationTensor(0) = [0.10417, 0.10417, 0.0, 0.14583, 0.10417, 0.10417, 0.10417, 0.08333, 0.08333, 0.08333, 0.08333, 0.0, 0.0, 0.0]
ObservationTensor(1) = [0.10417, 0.10417, 0.0, 0.14583, 0.10417, 0.10417, 0.10417, 0.08333, 0.08333, 0.08333, 0.08333, 0.0, 0.0, 0.0]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 2, 3, 4]
StringLegalActions() = ["a", "b", "c", "d", "e"]

# Apply action "b"
action: 1

# State 4
# Player 1 score = 0
#   f  e  d  c  b  a
#   1  5  5  5  0  5
#   5  5  0  7  5  5
#   A  B  C  D  E  F
# Player 0 score = 0 [PLAYING]
IsTerminal() = False
History() = [2, 5, 2, 1]
HistoryString() = "2 5 2 1"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "0 | 0 0 | 5 5 0 7 5 5 5 0 5 5 5 1"
ObservationString(1) = "0 | 0 0 | 5 5 0 7 5 5 5 0 5 5 5 1"
ObservationTensor(0) = [0.10417, 0.10417, 0.0, 0.14583, 0.10417, 0.10417, 0.10417, 0.0, 0.10417, 0.10417, 0.10417, 0.02083, 0.0, 0.0]
ObservationTensor(1) = [0.10417, 0.10417, 0.0, 0.14583, 0.10417, 0.10417, 0.10417, 0.0, 0.10417, 0.10417, 0.10417, 0.02083, 0.0, 0.0]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 3, 4, 5]
StringLegalActions() = ["A", "B", "D", "E", "F"]

# Apply action "B"
action: 1

# State 5
# Player 1 score = 0 [PLAYING]
#   f  e  d  c  b  a
#   1  5  5  5  0  6
#   5  0  1  8  6  6
#   A  B  C  D  E  F
# Player 0 score = 0
IsTerminal() = False
History() = [2, 5, 2, 1, 1]
HistoryString() = "2 5 2 1 1"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
ObservationString(0) = "1 | 0 0 | 5 0 1 8 6 6 6 0 5 5 5 1"
ObservationString(1) = "1 | 0 0 | 5 0 1 8 6 6 6 0 5 5 5 1"
ObservationTensor(0) = [0.10417, 0.0, 0.02083, 0.16667, 0.125, 0.125, 0.125, 0.0, 0.10417, 0.10417, 0.10417, 0.02083, 0.0, 0.0]
ObservationTensor(1) = [0.10417, 0.0, 0.02083, 0.16667, 0.125, 0.125, 0.125, 0.0, 0.10417, 0.10417, 0.10417, 0.02083, 0.0, 0.0]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 5]
StringLegalActions() = ["a", "c", "d", "e", "f"]

# Apply action "c"
action: 2

# State 6
# Player 1 score = 0
#   f  e  d  c  b  a
#   2  6  6  0  0  6
#   6  1  1  8  6  6
#   A  B  C  D  E  F
# Player 0 score = 0 [PLAYING]
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2]
HistoryString() = "2 5 2 1 1 2"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "0 | 0 0 | 6 1 1 8 6 6 6 0 0 6 6 2"
ObservationString(1) = "0 | 0 0 | 6 1 1 8 6 6 6 0 0 6 6 2"
ObservationTensor(0) = [0.125, 0.02083, 0.02083, 0.16667, 0.125, 0.125, 0.125, 0.0, 0.0, 0.125, 0.125, 0.04167, 0.0, 0.0]
ObservationTensor(1) = [0.125, 0.02083, 0.02083, 0.16667, 0.125, 0.125, 0.125, 0.0, 0.0, 0.125, 0.125, 0.04167, 0.0, 0.0]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 2, 3, 4, 5]
StringLegalActions() = ["A", "B", "C", "D", "E", "F"]

# Apply action "C"
action: 2

# State 7
# Player 1 score = 0 [PLAYING]
#   f  e  d  c  b  a
#   2  6  6  0  0  6
#   6  1  0  9  6  6
#   A  B  C  D  E  F
# Player 0 score = 0
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2]
HistoryString() = "2 5 2 1 1 2 2"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
ObservationString(0) = "1 | 0 0 | 6 1 0 9 6 6 6 0 0 6 6 2"
ObservationString(1) = "1 | 0 0 | 6 1 0 9 6 6 6 0 0 6 6 2"
ObservationTensor(0) = [0.125, 0.02083, 0.0, 0.1875, 0.125, 0.125, 0.125, 0.0, 0.0, 0.125, 0.125, 0.04167, 0.0, 0.0]
ObservationTensor(1) = [0.125, 0.02083, 0.0, 0.1875, 0.125, 0.125, 0.125, 0.0, 0.0, 0.125, 0.125, 0.04167, 0.0, 0.0]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 3, 4, 5]
StringLegalActions() = ["a", "d", "e", "f"]

# Apply action "d"
action: 3

# State 8
# Player 1 score = 0
#   f  e  d  c  b  a
#   3  7  0  0  0  6
#   7  2  1 10  6  6
#   A  B  C  D  E  F
# Player 0 score = 0 [PLAYING]
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3]
HistoryString() = "2 5 2 1 1 2 2 3"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "0 | 0 0 | 7 2 1 10 6 6 6 0 0 0 7 3"
ObservationString(1) = "0 | 0 0 | 7 2 1 10 6 6 6 0 0 0 7 3"
ObservationTensor(0) = [0.14583, 0.04167, 0.02083, 0.20833, 0.125, 0.125, 0.125, 0.0, 0.0, 0.0, 0.14583, 0.0625, 0.0, 0.0]
ObservationTensor(1) = [0.14583, 0.04167, 0.02083, 0.20833, 0.125, 0.125, 0.125, 0.0, 0.0, 0.0, 0.14583, 0.0625, 0.0, 0.0]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 2, 3, 4, 5]
StringLegalActions() = ["A", "B", "C", "D", "E", "F"]

# Apply action "F"
action: 5

# State 9
# Player 1 score = 0 [PLAYING]
#   f  e  d  c  b  a
#   4  8  1  1  1  7
#   7  2  1 10  6  0
#   A  B  C  D  E  F
# Player 0 score = 0
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5]
HistoryString() = "2 5 2 1 1 2 2 3 5"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
ObservationString(0) = "1 | 0 0 | 7 2 1 10 6 0 7 1 1 1 8 4"
ObservationString(1) = "1 | 0 0 | 7 2 1 10 6 0 7 1 1 1 8 4"
ObservationTensor(0) = [0.14583, 0.04167, 0.02083, 0.20833, 0.125, 0.0, 0.14583, 0.02083, 0.02083, 0.02083, 0.16667, 0.08333, 0.0, 0.0]
ObservationTensor(1) = [0.14583, 0.04167, 0.02083, 0.20833, 0.125, 0.0, 0.14583, 0.02083, 0.02083, 0.02083, 0.16667, 0.08333, 0.0, 0.0]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 2, 3, 4, 5]
StringLegalActions() = ["a", "b", "c", "d", "e", "f"]

# Apply action "e"
action: 4

# State 10
# Player 1 score = 0
#   f  e  d  c  b  a
#   5  0  1  1  1  8
#   8  3  2 11  7  1
#   A  B  C  D  E  F
# Player 0 score = 0 [PLAYING]
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4]
HistoryString() = "2 5 2 1 1 2 2 3 5 4"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "0 | 0 0 | 8 3 2 11 7 1 8 1 1 1 0 5"
ObservationString(1) = "0 | 0 0 | 8 3 2 11 7 1 8 1 1 1 0 5"
ObservationTensor(0) = [0.16667, 0.0625, 0.04167, 0.22917, 0.14583, 0.02083, 0.16667, 0.02083, 0.02083, 0.02083, 0.0, 0.10417, 0.0, 0.0]
ObservationTensor(1) = [0.16667, 0.0625, 0.04167, 0.22917, 0.14583, 0.02083, 0.16667, 0.02083, 0.02083, 0.02083, 0.0, 0.10417, 0.0, 0.0]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 2, 3, 4, 5]
StringLegalActions() = ["A", "B", "C", "D", "E", "F"]

# Apply action "C"
action: 2

# State 11
# Player 1 score = 0 [PLAYING]
#   f  e  d  c  b  a
#   5  0  1  1  1  8
#   8  3  0 12  8  1
#   A  B  C  D  E  F
# Player 0 score = 0
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
ObservationString(0) = "1 | 0 0 | 8 3 0 12 8 1 8 1 1 1 0 5"
ObservationString(1) = "1 | 0 0 | 8 3 0 12 8 1 8 1 1 1 0 5"
ObservationTensor(0) = [0.16667, 0.0625, 0.0, 0.25, 0.16667, 0.02083, 0.16667, 0.02083, 0.02083, 0.02083, 0.0, 0.10417, 0.0, 0.0]
ObservationTensor(1) = [0.16667, 0.0625, 0.0, 0.25, 0.16667, 0.02083, 0.16667, 0.02083, 0.02083, 0.02083, 0.0, 0.10417, 0.0, 0.0]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 2, 3, 5]
StringLegalActions() = ["a", "b", "c", "d", "f"]

# Apply action "d"
action: 3

# State 12
# Player 1 score = 0
#   f  e  d  c  b  a
#   5  1  0  1  1  8
#   8  3  0 12  8  1
#   A  B  C  D  E  F
# Player 0 score = 0 [PLAYING]
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "0 | 0 0 | 8 3 0 12 8 1 8 1 1 0 1 5"
ObservationString(1) = "0 | 0 0 | 8 3 0 12 8 1 8 1 1 0 1 5"
ObservationTensor(0) = [0.16667, 0.0625, 0.0, 0.25, 0.16667, 0.02083, 0.16667, 0.02083, 0.02083, 0.0, 0.02083, 0.10417, 0.0, 0.0]
ObservationTensor(1) = [0.16667, 0.0625, 0.0, 0.25, 0.16667, 0.02083, 0.16667, 0.02083, 0.02083, 0.0, 0.02083, 0.10417, 0.0, 0.0]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 3, 4, 5]
StringLegalActions() = ["A", "B", "D", "E", "F"]

# Apply action "D"
action: 3

# State 13
# Player 1 score = 0 [PLAYING]
#   f  e  d  c  b  a
#   6  2  1  2  2  9
#   9  4  1  0 10  2
#   A  B  C  D  E  F
# Player 0 score = 0
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
ObservationString(0) = "1 | 0 0 | 9 4 1 0 10 2 9 2 2 1 2 6"
ObservationString(1) = "1 | 0 0 | 9 4 1 0 10 2 9 2 2 1 2 6"
ObservationTensor(0) = [0.1875, 0.08333, 0.02083, 0.0, 0.20833, 0.04167, 0.1875, 0.04167, 0.04167, 0.02083, 0.04167, 0.125, 0.0, 0.0]
ObservationTensor(1) = [0.1875, 0.08333, 0.02083, 0.0, 0.20833, 0.04167, 0.1875, 0.04167, 0.04167, 0.02083, 0.04167, 0.125, 0.0, 0.0]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 2, 3, 4, 5]
StringLegalActions() = ["a", "b", "c", "d", "e", "f"]

# Apply action "e"
action: 4

# State 14
# Player 1 score = 0
#   f  e  d  c  b  a
#   7  0  1  2  2  9
#  10  4  1  0 10  2
#   A  B  C  D  E  F
# Player 0 score = 0 [PLAYING]
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "0 | 0 0 | 10 4 1 0 10 2 9 2 2 1 0 7"
ObservationString(1) = "0 | 0 0 | 10 4 1 0 10 2 9 2 2 1 0 7"
ObservationTensor(0) = [0.20833, 0.08333, 0.02083, 0.0, 0.20833, 0.04167, 0.1875, 0.04167, 0.04167, 0.02083, 0.0, 0.14583, 0.0, 0.0]
ObservationTensor(1) = [0.20833, 0.08333, 0.02083, 0.0, 0.20833, 0.04167, 0.1875, 0.04167, 0.04167, 0.02083, 0.0, 0.14583, 0.0, 0.0]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 2, 4, 5]
StringLegalActions() = ["A", "B", "C", "E", "F"]

# Apply action "A"
action: 0

# State 15
# Player 1 score = 0 [PLAYING]
#   f  e  d  c  b  a
#   7  1  2  3  3 10
#   0  5  2  1 11  3
#   A  B  C  D  E  F
# Player 0 score = 0
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
ObservationString(0) = "1 | 0 0 | 0 5 2 1 11 3 10 3 3 2 1 7"
ObservationString(1) = "1 | 0 0 | 0 5 2 1 11 3 10 3 3 2 1 7"
ObservationTensor(0) = [0.0, 0.10417, 0.04167, 0.02083, 0.22917, 0.0625, 0.20833, 0.0625, 0.0625, 0.04167, 0.02083, 0.14583, 0.0, 0.0]
ObservationTensor(1) = [0.0, 0.10417, 0.04167, 0.02083, 0.22917, 0.0625, 0.20833, 0.0625, 0.0625, 0.04167, 0.02083, 0.14583, 0.0, 0.0]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 2, 3, 4, 5]
StringLegalActions() = ["a", "b", "c", "d", "e", "f"]

# Apply action "b"
action: 1

# State 16
# Player 1 score = 0
#   f  e  d  c  b  a
#   7  2  3  4  0 10
#   0  5  2  1 11  3
#   A  B  C  D  E  F
# Player 0 score = 0 [PLAYING]
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "0 | 0 0 | 0 5 2 1 11 3 10 0 4 3 2 7"
ObservationString(1) = "0 | 0 0 | 0 5 2 1 11 3 10 0 4 3 2 7"
ObservationTensor(0) = [0.0, 0.10417, 0.04167, 0.02083, 0.22917, 0.0625, 0.20833, 0.0, 0.08333, 0.0625, 0.04167, 0.14583, 0.0, 0.0]
ObservationTensor(1) = [0.0, 0.10417, 0.04167, 0.02083, 0.22917, 0.0625, 0.20833, 0.0, 0.08333, 0.0625, 0.04167, 0.14583, 0.0, 0.0]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [1, 2, 3, 4, 5]
StringLegalActions() = ["B", "C", "D", "E", "F"]

# Apply action "D"
action: 3

# State 17
# Player 1 score = 0 [PLAYING]
#   f  e  d  c  b  a
#   7  2  3  4  0 10
#   0  5  2  0 12  3
#   A  B  C  D  E  F
# Player 0 score = 0
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
ObservationString(0) = "1 | 0 0 | 0 5 2 0 12 3 10 0 4 3 2 7"
ObservationString(1) = "1 | 0 0 | 0 5 2 0 12 3 10 0 4 3 2 7"
ObservationTensor(0) = [0.0, 0.10417, 0.04167, 0.0, 0.25, 0.0625, 0.20833, 0.0, 0.08333, 0.0625, 0.04167, 0.14583, 0.0, 0.0]
ObservationTensor(1) = [0.0, 0.10417, 0.04167, 0.0, 0.25, 0.0625, 0.20833, 0.0, 0.08333, 0.0625, 0.04167, 0.14583, 0.0, 0.0]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 5]
StringLegalActions() = ["a", "c", "d", "e", "f"]

# Apply action "a"
action: 0

# State 18
# Player 1 score = 0
#   f  e  d  c  b  a
#   8  3  4  5  1  0
#   1  6  3  1 13  3
#   A  B  C  D  E  F
# Player 0 score = 0 [PLAYING]
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "0 | 0 0 | 1 6 3 1 13 3 0 1 5 4 3 8"
ObservationString(1) = "0 | 0 0 | 1 6 3 1 13 3 0 1 5 4 3 8"
ObservationTensor(0) = [0.02083, 0.125, 0.0625, 0.02083, 0.27083, 0.0625, 0.0, 0.02083, 0.10417, 0.08333, 0.0625, 0.16667, 0.0, 0.0]
ObservationTensor(1) = [0.02083, 0.125, 0.0625, 0.02083, 0.27083, 0.0625, 0.0, 0.02083, 0.10417, 0.08333, 0.0625, 0.16667, 0.0, 0.0]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 2, 3, 4, 5]
StringLegalActions() = ["A", "B", "C", "D", "E", "F"]

# Apply action "C"
action: 2

# State 19
# Player 1 score = 0 [PLAYING]
#   f  e  d  c  b  a
#   8  3  4  5  1  0
#   1  6  0  2 14  4
#   A  B  C  D  E  F
# Player 0 score = 0
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
ObservationString(0) = "1 | 0 0 | 1 6 0 2 14 4 0 1 5 4 3 8"
ObservationString(1) = "1 | 0 0 | 1 6 0 2 14 4 0 1 5 4 3 8"
ObservationTensor(0) = [0.02083, 0.125, 0.0, 0.04167, 0.29167, 0.08333, 0.0, 0.02083, 0.10417, 0.08333, 0.0625, 0.16667, 0.0, 0.0]
ObservationTensor(1) = [0.02083, 0.125, 0.0, 0.04167, 0.29167, 0.08333, 0.0, 0.02083, 0.10417, 0.08333, 0.0625, 0.16667, 0.0, 0.0]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [1, 2, 3, 4, 5]
StringLegalActions() = ["b", "c", "d", "e", "f"]

# Apply action "c"
action: 2

# State 20
# Player 1 score = 0
#   f  e  d  c  b  a
#   9  4  5  0  1  0
#   2  7  0  2 14  4
#   A  B  C  D  E  F
# Player 0 score = 0 [PLAYING]
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "0 | 0 0 | 2 7 0 2 14 4 0 1 0 5 4 9"
ObservationString(1) = "0 | 0 0 | 2 7 0 2 14 4 0 1 0 5 4 9"
ObservationTensor(0) = [0.04167, 0.14583, 0.0, 0.04167, 0.29167, 0.08333, 0.0, 0.02083, 0.0, 0.10417, 0.08333, 0.1875, 0.0, 0.0]
ObservationTensor(1) = [0.04167, 0.14583, 0.0, 0.04167, 0.29167, 0.08333, 0.0, 0.02083, 0.0, 0.10417, 0.08333, 0.1875, 0.0, 0.0]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 3, 4, 5]
StringLegalActions() = ["A", "B", "D", "E", "F"]

# Apply action "E"
action: 4

# State 21
# Player 1 score = 0 [PLAYING]
#   f  e  d  c  b  a
#  10  5  6  1  0  0
#   3  8  1  3  0  6
#   A  B  C  D  E  F
# Player 0 score = 5
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
ObservationString(0) = "1 | 5 0 | 3 8 1 3 0 6 0 0 1 6 5 10"
ObservationString(1) = "1 | 5 0 | 3 8 1 3 0 6 0 0 1 6 5 10"
ObservationTensor(0) = [0.0625, 0.16667, 0.02083, 0.0625, 0.0, 0.125, 0.0, 0.0, 0.02083, 0.125, 0.10417, 0.20833, 0.10417, 0.0]
ObservationTensor(1) = [0.0625, 0.16667, 0.02083, 0.0625, 0.0, 0.125, 0.0, 0.0, 0.02083, 0.125, 0.10417, 0.20833, 0.10417, 0.0]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [2, 3, 4, 5]
StringLegalActions() = ["c", "d", "e", "f"]

# Apply action "c"
action: 2

# State 22
# Player 1 score = 0
#   f  e  d  c  b  a
#  10  5  7  0  0  0
#   3  8  1  3  0  6
#   A  B  C  D  E  F
# Player 0 score = 5 [PLAYING]
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "0 | 5 0 | 3 8 1 3 0 6 0 0 0 7 5 10"
ObservationString(1) = "0 | 5 0 | 3 8 1 3 0 6 0 0 0 7 5 10"
ObservationTensor(0) = [0.0625, 0.16667, 0.02083, 0.0625, 0.0, 0.125, 0.0, 0.0, 0.0, 0.14583, 0.10417, 0.20833, 0.10417, 0.0]
ObservationTensor(1) = [0.0625, 0.16667, 0.02083, 0.0625, 0.0, 0.125, 0.0, 0.0, 0.0, 0.14583, 0.10417, 0.20833, 0.10417, 0.0]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 2, 3, 5]
StringLegalActions() = ["A", "B", "C", "D", "F"]

# Apply action "C"
action: 2

# State 23
# Player 1 score = 0 [PLAYING]
#   f  e  d  c  b  a
#  10  5  7  0  0  0
#   3  8  0  4  0  6
#   A  B  C  D  E  F
# Player 0 score = 5
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
ObservationString(0) = "1 | 5 0 | 3 8 0 4 0 6 0 0 0 7 5 10"
ObservationString(1) = "1 | 5 0 | 3 8 0 4 0 6 0 0 0 7 5 10"
ObservationTensor(0) = [0.0625, 0.16667, 0.0, 0.08333, 0.0, 0.125, 0.0, 0.0, 0.0, 0.14583, 0.10417, 0.20833, 0.10417, 0.0]
ObservationTensor(1) = [0.0625, 0.16667, 0.0, 0.08333, 0.0, 0.125, 0.0, 0.0, 0.0, 0.14583, 0.10417, 0.20833, 0.10417, 0.0]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [3, 4, 5]
StringLegalActions() = ["d", "e", "f"]

# Apply action "e"
action: 4

# State 24
# Player 1 score = 0
#   f  e  d  c  b  a
#  11  0  7  0  0  0
#   4  9  1  5  0  6
#   A  B  C  D  E  F
# Player 0 score = 5 [PLAYING]
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "0 | 5 0 | 4 9 1 5 0 6 0 0 0 7 0 11"
ObservationString(1) = "0 | 5 0 | 4 9 1 5 0 6 0 0 0 7 0 11"
ObservationTensor(0) = [0.08333, 0.1875, 0.02083, 0.10417, 0.0, 0.125, 0.0, 0.0, 0.0, 0.14583, 0.0, 0.22917, 0.10417, 0.0]
ObservationTensor(1) = [0.08333, 0.1875, 0.02083, 0.10417, 0.0, 0.125, 0.0, 0.0, 0.0, 0.14583, 0.0, 0.22917, 0.10417, 0.0]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 2, 3, 5]
StringLegalActions() = ["A", "B", "C", "D", "F"]

# Apply action "D"
action: 3

# State 25
# Player 1 score = 0 [PLAYING]
#   f  e  d  c  b  a
#  11  0  7  1  1  1
#   4  9  1  0  1  7
#   A  B  C  D  E  F
# Player 0 score = 5
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
ObservationString(0) = "1 | 5 0 | 4 9 1 0 1 7 1 1 1 7 0 11"
ObservationString(1) = "1 | 5 0 | 4 9 1 0 1 7 1 1 1 7 0 11"
ObservationTensor(0) = [0.08333, 0.1875, 0.02083, 0.0, 0.02083, 0.14583, 0.02083, 0.02083, 0.02083, 0.14583, 0.0, 0.22917, 0.10417, 0.0]
ObservationTensor(1) = [0.08333, 0.1875, 0.02083, 0.0, 0.02083, 0.14583, 0.02083, 0.02083, 0.02083, 0.14583, 0.0, 0.22917, 0.10417, 0.0]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 2, 3, 5]
StringLegalActions() = ["a", "b", "c", "d", "f"]

# Apply action "d"
action: 3

# State 26
# Player 1 score = 2
#   f  e  d  c  b  a
#  12  1  0  1  1  1
#   5 10  2  1  0  7
#   A  B  C  D  E  F
# Player 0 score = 5 [PLAYING]
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "0 | 5 2 | 5 10 2 1 0 7 1 1 1 0 1 12"
ObservationString(1) = "0 | 5 2 | 5 10 2 1 0 7 1 1 1 0 1 12"
ObservationTensor(0) = [0.10417, 0.20833, 0.04167, 0.02083, 0.0, 0.14583, 0.02083, 0.02083, 0.02083, 0.0, 0.02083, 0.25, 0.10417, 0.04167]
ObservationTensor(1) = [0.10417, 0.20833, 0.04167, 0.02083, 0.0, 0.14583, 0.02083, 0.02083, 0.02083, 0.0, 0.02083, 0.25, 0.10417, 0.04167]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 2, 3, 5]
StringLegalActions() = ["A", "B", "C", "D", "F"]

# Apply action "A"
action: 0

# State 27
# Player 1 score = 2 [PLAYING]
#   f  e  d  c  b  a
#  12  1  0  1  1  1
#   0 11  3  2  1  8
#   A  B  C  D  E  F
# Player 0 score = 5
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
ObservationString(0) = "1 | 5 2 | 0 11 3 2 1 8 1 1 1 0 1 12"
ObservationString(1) = "1 | 5 2 | 0 11 3 2 1 8 1 1 1 0 1 12"
ObservationTensor(0) = [0.0, 0.22917, 0.0625, 0.04167, 0.02083, 0.16667, 0.02083, 0.02083, 0.02083, 0.0, 0.02083, 0.25, 0.10417, 0.04167]
ObservationTensor(1) = [0.0, 0.22917, 0.0625, 0.04167, 0.02083, 0.16667, 0.02083, 0.02083, 0.02083, 0.0, 0.02083, 0.25, 0.10417, 0.04167]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 2, 4, 5]
StringLegalActions() = ["a", "b", "c", "e", "f"]

# Apply action "e"
action: 4

# State 28
# Player 1 score = 2
#   f  e  d  c  b  a
#  13  0  0  1  1  1
#   0 11  3  2  1  8
#   A  B  C  D  E  F
# Player 0 score = 5 [PLAYING]
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "0 | 5 2 | 0 11 3 2 1 8 1 1 1 0 0 13"
ObservationString(1) = "0 | 5 2 | 0 11 3 2 1 8 1 1 1 0 0 13"
ObservationTensor(0) = [0.0, 0.22917, 0.0625, 0.04167, 0.02083, 0.16667, 0.02083, 0.02083, 0.02083, 0.0, 0.0, 0.27083, 0.10417, 0.04167]
ObservationTensor(1) = [0.0, 0.22917, 0.0625, 0.04167, 0.02083, 0.16667, 0.02083, 0.02083, 0.02083, 0.0, 0.0, 0.27083, 0.10417, 0.04167]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [1, 2, 3, 4, 5]
StringLegalActions() = ["B", "C", "D", "E", "F"]

# Apply action "F"
action: 5

# State 29
# Player 1 score = 2 [PLAYING]
#   f  e  d  c  b  a
#  14  1  1  2  2  2
#   1 12  3  2  1  0
#   A  B  C  D  E  F
# Player 0 score = 5
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
ObservationString(0) = "1 | 5 2 | 1 12 3 2 1 0 2 2 2 1 1 14"
ObservationString(1) = "1 | 5 2 | 1 12 3 2 1 0 2 2 2 1 1 14"
ObservationTensor(0) = [0.02083, 0.25, 0.0625, 0.04167, 0.02083, 0.0, 0.04167, 0.04167, 0.04167, 0.02083, 0.02083, 0.29167, 0.10417, 0.04167]
ObservationTensor(1) = [0.02083, 0.25, 0.0625, 0.04167, 0.02083, 0.0, 0.04167, 0.04167, 0.04167, 0.02083, 0.02083, 0.29167, 0.10417, 0.04167]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 2, 3, 4, 5]
StringLegalActions() = ["a", "b", "c", "d", "e", "f"]

# Apply action "b"
action: 1

# State 30
# Player 1 score = 2
#   f  e  d  c  b  a
#  14  1  2  3  0  2
#   1 12  3  2  1  0
#   A  B  C  D  E  F
# Player 0 score = 5 [PLAYING]
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "0 | 5 2 | 1 12 3 2 1 0 2 0 3 2 1 14"
ObservationString(1) = "0 | 5 2 | 1 12 3 2 1 0 2 0 3 2 1 14"
ObservationTensor(0) = [0.02083, 0.25, 0.0625, 0.04167, 0.02083, 0.0, 0.04167, 0.0, 0.0625, 0.04167, 0.02083, 0.29167, 0.10417, 0.04167]
ObservationTensor(1) = [0.02083, 0.25, 0.0625, 0.04167, 0.02083, 0.0, 0.04167, 0.0, 0.0625, 0.04167, 0.02083, 0.29167, 0.10417, 0.04167]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 2, 3, 4]
StringLegalActions() = ["A", "B", "C", "D", "E"]

# Apply action "A"
action: 0

# State 31
# Player 1 score = 2 [PLAYING]
#   f  e  d  c  b  a
#  14  1  2  3  0  2
#   0 13  3  2  1  0
#   A  B  C  D  E  F
# Player 0 score = 5
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
ObservationString(0) = "1 | 5 2 | 0 13 3 2 1 0 2 0 3 2 1 14"
ObservationString(1) = "1 | 5 2 | 0 13 3 2 1 0 2 0 3 2 1 14"
ObservationTensor(0) = [0.0, 0.27083, 0.0625, 0.04167, 0.02083, 0.0, 0.04167, 0.0, 0.0625, 0.04167, 0.02083, 0.29167, 0.10417, 0.04167]
ObservationTensor(1) = [0.0, 0.27083, 0.0625, 0.04167, 0.02083, 0.0, 0.04167, 0.0, 0.0625, 0.04167, 0.02083, 0.29167, 0.10417, 0.04167]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 5]
StringLegalActions() = ["a", "c", "d", "e", "f"]

# Apply action "e"
action: 4

# State 32
# Player 1 score = 2
#   f  e  d  c  b  a
#  15  0  2  3  0  2
#   0 13  3  2  1  0
#   A  B  C  D  E  F
# Player 0 score = 5 [PLAYING]
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "0 | 5 2 | 0 13 3 2 1 0 2 0 3 2 0 15"
ObservationString(1) = "0 | 5 2 | 0 13 3 2 1 0 2 0 3 2 0 15"
ObservationTensor(0) = [0.0, 0.27083, 0.0625, 0.04167, 0.02083, 0.0, 0.04167, 0.0, 0.0625, 0.04167, 0.0, 0.3125, 0.10417, 0.04167]
ObservationTensor(1) = [0.0, 0.27083, 0.0625, 0.04167, 0.02083, 0.0, 0.04167, 0.0, 0.0625, 0.04167, 0.0, 0.3125, 0.10417, 0.04167]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [1, 2, 3, 4]
StringLegalActions() = ["B", "C", "D", "E"]

# Apply action "E"
action: 4

# State 33
# Player 1 score = 2 [PLAYING]
#   f  e  d  c  b  a
#  15  0  2  3  0  2
#   0 13  3  2  0  1
#   A  B  C  D  E  F
# Player 0 score = 5
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
ObservationString(0) = "1 | 5 2 | 0 13 3 2 0 1 2 0 3 2 0 15"
ObservationString(1) = "1 | 5 2 | 0 13 3 2 0 1 2 0 3 2 0 15"
ObservationTensor(0) = [0.0, 0.27083, 0.0625, 0.04167, 0.0, 0.02083, 0.04167, 0.0, 0.0625, 0.04167, 0.0, 0.3125, 0.10417, 0.04167]
ObservationTensor(1) = [0.0, 0.27083, 0.0625, 0.04167, 0.0, 0.02083, 0.04167, 0.0, 0.0625, 0.04167, 0.0, 0.3125, 0.10417, 0.04167]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 5]
StringLegalActions() = ["a", "c", "d", "f"]

# Apply action "a"
action: 0

# State 34
# Player 1 score = 2
#   f  e  d  c  b  a
#  15  0  2  4  1  0
#   0 13  3  2  0  1
#   A  B  C  D  E  F
# Player 0 score = 5 [PLAYING]
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "0 | 5 2 | 0 13 3 2 0 1 0 1 4 2 0 15"
ObservationString(1) = "0 | 5 2 | 0 13 3 2 0 1 0 1 4 2 0 15"
ObservationTensor(0) = [0.0, 0.27083, 0.0625, 0.04167, 0.0, 0.02083, 0.0, 0.02083, 0.08333, 0.04167, 0.0, 0.3125, 0.10417, 0.04167]
ObservationTensor(1) = [0.0, 0.27083, 0.0625, 0.04167, 0.0, 0.02083, 0.0, 0.02083, 0.08333, 0.04167, 0.0, 0.3125, 0.10417, 0.04167]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [1, 2, 3, 5]
StringLegalActions() = ["B", "C", "D", "F"]

# Apply action "F"
action: 5

# State 35
# Player 1 score = 2 [PLAYING]
#   f  e  d  c  b  a
#  15  0  2  4  1  1
#   0 13  3  2  0  0
#   A  B  C  D  E  F
# Player 0 score = 5
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
ObservationString(0) = "1 | 5 2 | 0 13 3 2 0 0 1 1 4 2 0 15"
ObservationString(1) = "1 | 5 2 | 0 13 3 2 0 0 1 1 4 2 0 15"
ObservationTensor(0) = [0.0, 0.27083, 0.0625, 0.04167, 0.0, 0.0, 0.02083, 0.02083, 0.08333, 0.04167, 0.0, 0.3125, 0.10417, 0.04167]
ObservationTensor(1) = [0.0, 0.27083, 0.0625, 0.04167, 0.0, 0.0, 0.02083, 0.02083, 0.08333, 0.04167, 0.0, 0.3125, 0.10417, 0.04167]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 2, 3, 5]
StringLegalActions() = ["a", "b", "c", "d", "f"]

# Apply action "b"
action: 1

# State 36
# Player 1 score = 2
#   f  e  d  c  b  a
#  15  0  2  5  0  1
#   0 13  3  2  0  0
#   A  B  C  D  E  F
# Player 0 score = 5 [PLAYING]
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "0 | 5 2 | 0 13 3 2 0 0 1 0 5 2 0 15"
ObservationString(1) = "0 | 5 2 | 0 13 3 2 0 0 1 0 5 2 0 15"
ObservationTensor(0) = [0.0, 0.27083, 0.0625, 0.04167, 0.0, 0.0, 0.02083, 0.0, 0.10417, 0.04167, 0.0, 0.3125, 0.10417, 0.04167]
ObservationTensor(1) = [0.0, 0.27083, 0.0625, 0.04167, 0.0, 0.0, 0.02083, 0.0, 0.10417, 0.04167, 0.0, 0.3125, 0.10417, 0.04167]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [1, 2, 3]
StringLegalActions() = ["B", "C", "D"]

# Apply action "B"
action: 1

# State 37
# Player 1 score = 2 [PLAYING]
#   f  e  d  c  b  a
#  16  1  3  6  1  2
#   1  0  5  4  1  1
#   A  B  C  D  E  F
# Player 0 score = 5
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
ObservationString(0) = "1 | 5 2 | 1 0 5 4 1 1 2 1 6 3 1 16"
ObservationString(1) = "1 | 5 2 | 1 0 5 4 1 1 2 1 6 3 1 16"
ObservationTensor(0) = [0.02083, 0.0, 0.10417, 0.08333, 0.02083, 0.02083, 0.04167, 0.02083, 0.125, 0.0625, 0.02083, 0.33333, 0.10417, 0.04167]
ObservationTensor(1) = [0.02083, 0.0, 0.10417, 0.08333, 0.02083, 0.02083, 0.04167, 0.02083, 0.125, 0.0625, 0.02083, 0.33333, 0.10417, 0.04167]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 2, 3, 4, 5]
StringLegalActions() = ["a", "b", "c", "d", "e", "f"]

# Apply action "e"
action: 4

# State 38
# Player 1 score = 2
#   f  e  d  c  b  a
#  17  0  3  6  1  2
#   1  0  5  4  1  1
#   A  B  C  D  E  F
# Player 0 score = 5 [PLAYING]
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "0 | 5 2 | 1 0 5 4 1 1 2 1 6 3 0 17"
ObservationString(1) = "0 | 5 2 | 1 0 5 4 1 1 2 1 6 3 0 17"
ObservationTensor(0) = [0.02083, 0.0, 0.10417, 0.08333, 0.02083, 0.02083, 0.04167, 0.02083, 0.125, 0.0625, 0.0, 0.35417, 0.10417, 0.04167]
ObservationTensor(1) = [0.02083, 0.0, 0.10417, 0.08333, 0.02083, 0.02083, 0.04167, 0.02083, 0.125, 0.0625, 0.0, 0.35417, 0.10417, 0.04167]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 5]
StringLegalActions() = ["A", "C", "D", "E", "F"]

# Apply action "A"
action: 0

# State 39
# Player 1 score = 2 [PLAYING]
#   f  e  d  c  b  a
#  17  0  3  6  1  2
#   0  1  5  4  1  1
#   A  B  C  D  E  F
# Player 0 score = 5
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
ObservationString(0) = "1 | 5 2 | 0 1 5 4 1 1 2 1 6 3 0 17"
ObservationString(1) = "1 | 5 2 | 0 1 5 4 1 1 2 1 6 3 0 17"
ObservationTensor(0) = [0.0, 0.02083, 0.10417, 0.08333, 0.02083, 0.02083, 0.04167, 0.02083, 0.125, 0.0625, 0.0, 0.35417, 0.10417, 0.04167]
ObservationTensor(1) = [0.0, 0.02083, 0.10417, 0.08333, 0.02083, 0.02083, 0.04167, 0.02083, 0.125, 0.0625, 0.0, 0.35417, 0.10417, 0.04167]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 2, 3, 5]
StringLegalActions() = ["a", "b", "c", "d", "f"]

# Apply action "d"
action: 3

# State 40
# Player 1 score = 2
#   f  e  d  c  b  a
#  18  1  0  6  1  2
#   1  1  5  4  1  1
#   A  B  C  D  E  F
# Player 0 score = 5 [PLAYING]
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "0 | 5 2 | 1 1 5 4 1 1 2 1 6 0 1 18"
ObservationString(1) = "0 | 5 2 | 1 1 5 4 1 1 2 1 6 0 1 18"
ObservationTensor(0) = [0.02083, 0.02083, 0.10417, 0.08333, 0.02083, 0.02083, 0.04167, 0.02083, 0.125, 0.0, 0.02083, 0.375, 0.10417, 0.04167]
ObservationTensor(1) = [0.02083, 0.02083, 0.10417, 0.08333, 0.02083, 0.02083, 0.04167, 0.02083, 0.125, 0.0, 0.02083, 0.375, 0.10417, 0.04167]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 2, 3, 4, 5]
StringLegalActions() = ["A", "B", "C", "D", "E", "F"]

# Apply action "D"
action: 3

# State 41
# Player 1 score = 2 [PLAYING]
#   f  e  d  c  b  a
#  18  1  0  6  0  0
#   1  1  5  0  2  2
#   A  B  C  D  E  F
# Player 0 score = 10
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
ObservationString(0) = "1 | 10 2 | 1 1 5 0 2 2 0 0 6 0 1 18"
ObservationString(1) = "1 | 10 2 | 1 1 5 0 2 2 0 0 6 0 1 18"
ObservationTensor(0) = [0.02083, 0.02083, 0.10417, 0.0, 0.04167, 0.04167, 0.0, 0.0, 0.125, 0.0, 0.02083, 0.375, 0.20833, 0.04167]
ObservationTensor(1) = [0.02083, 0.02083, 0.10417, 0.0, 0.04167, 0.04167, 0.0, 0.0, 0.125, 0.0, 0.02083, 0.375, 0.20833, 0.04167]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [2, 4, 5]
StringLegalActions() = ["c", "e", "f"]

# Apply action "e"
action: 4

# State 42
# Player 1 score = 2
#   f  e  d  c  b  a
#  19  0  0  6  0  0
#   1  1  5  0  2  2
#   A  B  C  D  E  F
# Player 0 score = 10 [PLAYING]
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "0 | 10 2 | 1 1 5 0 2 2 0 0 6 0 0 19"
ObservationString(1) = "0 | 10 2 | 1 1 5 0 2 2 0 0 6 0 0 19"
ObservationTensor(0) = [0.02083, 0.02083, 0.10417, 0.0, 0.04167, 0.04167, 0.0, 0.0, 0.125, 0.0, 0.0, 0.39583, 0.20833, 0.04167]
ObservationTensor(1) = [0.02083, 0.02083, 0.10417, 0.0, 0.04167, 0.04167, 0.0, 0.0, 0.125, 0.0, 0.0, 0.39583, 0.20833, 0.04167]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 2, 4, 5]
StringLegalActions() = ["A", "B", "C", "E", "F"]

# Apply action "B"
action: 1

# State 43
# Player 1 score = 2 [PLAYING]
#   f  e  d  c  b  a
#  19  0  0  6  0  0
#   1  0  6  0  2  2
#   A  B  C  D  E  F
# Player 0 score = 10
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
ObservationString(0) = "1 | 10 2 | 1 0 6 0 2 2 0 0 6 0 0 19"
ObservationString(1) = "1 | 10 2 | 1 0 6 0 2 2 0 0 6 0 0 19"
ObservationTensor(0) = [0.02083, 0.0, 0.125, 0.0, 0.04167, 0.04167, 0.0, 0.0, 0.125, 0.0, 0.0, 0.39583, 0.20833, 0.04167]
ObservationTensor(1) = [0.02083, 0.0, 0.125, 0.0, 0.04167, 0.04167, 0.0, 0.0, 0.125, 0.0, 0.0, 0.39583, 0.20833, 0.04167]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [2, 5]
StringLegalActions() = ["c", "f"]

# Apply action "f"
action: 5

# State 44
# Player 1 score = 2
#   f  e  d  c  b  a
#   0  1  1  7  2  2
#   3  2  8  2  4  4
#   A  B  C  D  E  F
# Player 0 score = 10 [PLAYING]
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "0 | 10 2 | 3 2 8 2 4 4 2 2 7 1 1 0"
ObservationString(1) = "0 | 10 2 | 3 2 8 2 4 4 2 2 7 1 1 0"
ObservationTensor(0) = [0.0625, 0.04167, 0.16667, 0.04167, 0.08333, 0.08333, 0.04167, 0.04167, 0.14583, 0.02083, 0.02083, 0.0, 0.20833, 0.04167]
ObservationTensor(1) = [0.0625, 0.04167, 0.16667, 0.04167, 0.08333, 0.08333, 0.04167, 0.04167, 0.14583, 0.02083, 0.02083, 0.0, 0.20833, 0.04167]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 2, 3, 4, 5]
StringLegalActions() = ["A", "B", "C", "D", "E", "F"]

# Apply action "D"
action: 3

# State 45
# Player 1 score = 2 [PLAYING]
#   f  e  d  c  b  a
#   0  1  1  7  2  2
#   3  2  8  0  5  5
#   A  B  C  D  E  F
# Player 0 score = 10
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
ObservationString(0) = "1 | 10 2 | 3 2 8 0 5 5 2 2 7 1 1 0"
ObservationString(1) = "1 | 10 2 | 3 2 8 0 5 5 2 2 7 1 1 0"
ObservationTensor(0) = [0.0625, 0.04167, 0.16667, 0.0, 0.10417, 0.10417, 0.04167, 0.04167, 0.14583, 0.02083, 0.02083, 0.0, 0.20833, 0.04167]
ObservationTensor(1) = [0.0625, 0.04167, 0.16667, 0.0, 0.10417, 0.10417, 0.04167, 0.04167, 0.14583, 0.02083, 0.02083, 0.0, 0.20833, 0.04167]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 2, 3, 4]
StringLegalActions() = ["a", "b", "c", "d", "e"]

# Apply action "c"
action: 2

# State 46
# Player 1 score = 2
#   f  e  d  c  b  a
#   1  2  2  0  2  2
#   4  3  9  1  5  5
#   A  B  C  D  E  F
# Player 0 score = 10 [PLAYING]
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "0 | 10 2 | 4 3 9 1 5 5 2 2 0 2 2 1"
ObservationString(1) = "0 | 10 2 | 4 3 9 1 5 5 2 2 0 2 2 1"
ObservationTensor(0) = [0.08333, 0.0625, 0.1875, 0.02083, 0.10417, 0.10417, 0.04167, 0.04167, 0.0, 0.04167, 0.04167, 0.02083, 0.20833, 0.04167]
ObservationTensor(1) = [0.08333, 0.0625, 0.1875, 0.02083, 0.10417, 0.10417, 0.04167, 0.04167, 0.0, 0.04167, 0.04167, 0.02083, 0.20833, 0.04167]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 2, 3, 4, 5]
StringLegalActions() = ["A", "B", "C", "D", "E", "F"]

# Apply action "A"
action: 0

# State 47
# Player 1 score = 2 [PLAYING]
#   f  e  d  c  b  a
#   1  2  2  0  2  2
#   0  4 10  2  6  5
#   A  B  C  D  E  F
# Player 0 score = 10
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
ObservationString(0) = "1 | 10 2 | 0 4 10 2 6 5 2 2 0 2 2 1"
ObservationString(1) = "1 | 10 2 | 0 4 10 2 6 5 2 2 0 2 2 1"
ObservationTensor(0) = [0.0, 0.08333, 0.20833, 0.04167, 0.125, 0.10417, 0.04167, 0.04167, 0.0, 0.04167, 0.04167, 0.02083, 0.20833, 0.04167]
ObservationTensor(1) = [0.0, 0.08333, 0.20833, 0.04167, 0.125, 0.10417, 0.04167, 0.04167, 0.0, 0.04167, 0.04167, 0.02083, 0.20833, 0.04167]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 3, 4, 5]
StringLegalActions() = ["a", "b", "d", "e", "f"]

# Apply action "d"
action: 3

# State 48
# Player 1 score = 2
#   f  e  d  c  b  a
#   2  3  0  0  2  2
#   0  4 10  2  6  5
#   A  B  C  D  E  F
# Player 0 score = 10 [PLAYING]
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0, 3]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0 3"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "0 | 10 2 | 0 4 10 2 6 5 2 2 0 0 3 2"
ObservationString(1) = "0 | 10 2 | 0 4 10 2 6 5 2 2 0 0 3 2"
ObservationTensor(0) = [0.0, 0.08333, 0.20833, 0.04167, 0.125, 0.10417, 0.04167, 0.04167, 0.0, 0.0, 0.0625, 0.04167, 0.20833, 0.04167]
ObservationTensor(1) = [0.0, 0.08333, 0.20833, 0.04167, 0.125, 0.10417, 0.04167, 0.04167, 0.0, 0.0, 0.0625, 0.04167, 0.20833, 0.04167]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [1, 2, 3, 4, 5]
StringLegalActions() = ["B", "C", "D", "E", "F"]

# Apply action "F"
action: 5

# State 49
# Player 1 score = 2 [PLAYING]
#   f  e  d  c  b  a
#   2  4  1  1  3  3
#   0  4 10  2  6  0
#   A  B  C  D  E  F
# Player 0 score = 10
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0, 3, 5]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0 3 5"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
ObservationString(0) = "1 | 10 2 | 0 4 10 2 6 0 3 3 1 1 4 2"
ObservationString(1) = "1 | 10 2 | 0 4 10 2 6 0 3 3 1 1 4 2"
ObservationTensor(0) = [0.0, 0.08333, 0.20833, 0.04167, 0.125, 0.0, 0.0625, 0.0625, 0.02083, 0.02083, 0.08333, 0.04167, 0.20833, 0.04167]
ObservationTensor(1) = [0.0, 0.08333, 0.20833, 0.04167, 0.125, 0.0, 0.0625, 0.0625, 0.02083, 0.02083, 0.08333, 0.04167, 0.20833, 0.04167]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 2, 3, 4, 5]
StringLegalActions() = ["a", "b", "c", "d", "e", "f"]

# Apply action "f"
action: 5

# State 50
# Player 1 score = 2
#   f  e  d  c  b  a
#   0  4  1  1  3  3
#   1  5 10  2  6  0
#   A  B  C  D  E  F
# Player 0 score = 10 [PLAYING]
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0, 3, 5, 5]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0 3 5 5"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "0 | 10 2 | 1 5 10 2 6 0 3 3 1 1 4 0"
ObservationString(1) = "0 | 10 2 | 1 5 10 2 6 0 3 3 1 1 4 0"
ObservationTensor(0) = [0.02083, 0.10417, 0.20833, 0.04167, 0.125, 0.0, 0.0625, 0.0625, 0.02083, 0.02083, 0.08333, 0.0, 0.20833, 0.04167]
ObservationTensor(1) = [0.02083, 0.10417, 0.20833, 0.04167, 0.125, 0.0, 0.0625, 0.0625, 0.02083, 0.02083, 0.08333, 0.0, 0.20833, 0.04167]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 2, 3, 4]
StringLegalActions() = ["A", "B", "C", "D", "E"]

# Apply action "B"
action: 1

# State 51
# Player 1 score = 2 [PLAYING]
#   f  e  d  c  b  a
#   0  4  1  1  3  4
#   1  0 11  3  7  1
#   A  B  C  D  E  F
# Player 0 score = 10
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0, 3, 5, 5, 1]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0 3 5 5 1"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
ObservationString(0) = "1 | 10 2 | 1 0 11 3 7 1 4 3 1 1 4 0"
ObservationString(1) = "1 | 10 2 | 1 0 11 3 7 1 4 3 1 1 4 0"
ObservationTensor(0) = [0.02083, 0.0, 0.22917, 0.0625, 0.14583, 0.02083, 0.08333, 0.0625, 0.02083, 0.02083, 0.08333, 0.0, 0.20833, 0.04167]
ObservationTensor(1) = [0.02083, 0.0, 0.22917, 0.0625, 0.14583, 0.02083, 0.08333, 0.0625, 0.02083, 0.02083, 0.08333, 0.0, 0.20833, 0.04167]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 2, 3, 4]
StringLegalActions() = ["a", "b", "c", "d", "e"]

# Apply action "b"
action: 1

# State 52
# Player 1 score = 2
#   f  e  d  c  b  a
#   0  5  2  2  0  4
#   1  0 11  3  7  1
#   A  B  C  D  E  F
# Player 0 score = 10 [PLAYING]
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0, 3, 5, 5, 1, 1]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0 3 5 5 1 1"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "0 | 10 2 | 1 0 11 3 7 1 4 0 2 2 5 0"
ObservationString(1) = "0 | 10 2 | 1 0 11 3 7 1 4 0 2 2 5 0"
ObservationTensor(0) = [0.02083, 0.0, 0.22917, 0.0625, 0.14583, 0.02083, 0.08333, 0.0, 0.04167, 0.04167, 0.10417, 0.0, 0.20833, 0.04167]
ObservationTensor(1) = [0.02083, 0.0, 0.22917, 0.0625, 0.14583, 0.02083, 0.08333, 0.0, 0.04167, 0.04167, 0.10417, 0.0, 0.20833, 0.04167]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 5]
StringLegalActions() = ["A", "C", "D", "E", "F"]

# Apply action "D"
action: 3

# State 53
# Player 1 score = 2 [PLAYING]
#   f  e  d  c  b  a
#   0  5  2  2  0  5
#   1  0 11  0  8  2
#   A  B  C  D  E  F
# Player 0 score = 10
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0, 3, 5, 5, 1, 1, 3]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0 3 5 5 1 1 3"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
ObservationString(0) = "1 | 10 2 | 1 0 11 0 8 2 5 0 2 2 5 0"
ObservationString(1) = "1 | 10 2 | 1 0 11 0 8 2 5 0 2 2 5 0"
ObservationTensor(0) = [0.02083, 0.0, 0.22917, 0.0, 0.16667, 0.04167, 0.10417, 0.0, 0.04167, 0.04167, 0.10417, 0.0, 0.20833, 0.04167]
ObservationTensor(1) = [0.02083, 0.0, 0.22917, 0.0, 0.16667, 0.04167, 0.10417, 0.0, 0.04167, 0.04167, 0.10417, 0.0, 0.20833, 0.04167]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4]
StringLegalActions() = ["a", "c", "d", "e"]

# Apply action "c"
action: 2

# State 54
# Player 1 score = 2
#   f  e  d  c  b  a
#   0  6  3  0  0  5
#   1  0 11  0  8  2
#   A  B  C  D  E  F
# Player 0 score = 10 [PLAYING]
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0, 3, 5, 5, 1, 1, 3, 2]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0 3 5 5 1 1 3 2"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "0 | 10 2 | 1 0 11 0 8 2 5 0 0 3 6 0"
ObservationString(1) = "0 | 10 2 | 1 0 11 0 8 2 5 0 0 3 6 0"
ObservationTensor(0) = [0.02083, 0.0, 0.22917, 0.0, 0.16667, 0.04167, 0.10417, 0.0, 0.0, 0.0625, 0.125, 0.0, 0.20833, 0.04167]
ObservationTensor(1) = [0.02083, 0.0, 0.22917, 0.0, 0.16667, 0.04167, 0.10417, 0.0, 0.0, 0.0625, 0.125, 0.0, 0.20833, 0.04167]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 4, 5]
StringLegalActions() = ["A", "C", "E", "F"]

# Apply action "C"
action: 2

# State 55
# Player 1 score = 2 [PLAYING]
#   f  e  d  c  b  a
#   1  7  4  1  1  6
#   2  1  0  1  9  3
#   A  B  C  D  E  F
# Player 0 score = 10
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0, 3, 5, 5, 1, 1, 3, 2, 2]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0 3 5 5 1 1 3 2 2"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
ObservationString(0) = "1 | 10 2 | 2 1 0 1 9 3 6 1 1 4 7 1"
ObservationString(1) = "1 | 10 2 | 2 1 0 1 9 3 6 1 1 4 7 1"
ObservationTensor(0) = [0.04167, 0.02083, 0.0, 0.02083, 0.1875, 0.0625, 0.125, 0.02083, 0.02083, 0.08333, 0.14583, 0.02083, 0.20833, 0.04167]
ObservationTensor(1) = [0.04167, 0.02083, 0.0, 0.02083, 0.1875, 0.0625, 0.125, 0.02083, 0.02083, 0.08333, 0.14583, 0.02083, 0.20833, 0.04167]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 2, 3, 4, 5]
StringLegalActions() = ["a", "b", "c", "d", "e", "f"]

# Apply action "d"
action: 3

# State 56
# Player 1 score = 7
#   f  e  d  c  b  a
#   2  8  0  1  1  6
#   0  0  0  1  9  3
#   A  B  C  D  E  F
# Player 0 score = 10 [PLAYING]
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0, 3, 5, 5, 1, 1, 3, 2, 2, 3]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0 3 5 5 1 1 3 2 2 3"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "0 | 10 7 | 0 0 0 1 9 3 6 1 1 0 8 2"
ObservationString(1) = "0 | 10 7 | 0 0 0 1 9 3 6 1 1 0 8 2"
ObservationTensor(0) = [0.0, 0.0, 0.0, 0.02083, 0.1875, 0.0625, 0.125, 0.02083, 0.02083, 0.0, 0.16667, 0.04167, 0.20833, 0.14583]
ObservationTensor(1) = [0.0, 0.0, 0.0, 0.02083, 0.1875, 0.0625, 0.125, 0.02083, 0.02083, 0.0, 0.16667, 0.04167, 0.20833, 0.14583]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [3, 4, 5]
StringLegalActions() = ["D", "E", "F"]

# Apply action "F"
action: 5

# State 57
# Player 1 score = 7 [PLAYING]
#   f  e  d  c  b  a
#   2  8  0  0  0  7
#   0  0  0  1  9  0
#   A  B  C  D  E  F
# Player 0 score = 14
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0, 3, 5, 5, 1, 1, 3, 2, 2, 3, 5]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0 3 5 5 1 1 3 2 2 3 5"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
ObservationString(0) = "1 | 14 7 | 0 0 0 1 9 0 7 0 0 0 8 2"
ObservationString(1) = "1 | 14 7 | 0 0 0 1 9 0 7 0 0 0 8 2"
ObservationTensor(0) = [0.0, 0.0, 0.0, 0.02083, 0.1875, 0.0, 0.14583, 0.0, 0.0, 0.0, 0.16667, 0.04167, 0.29167, 0.14583]
ObservationTensor(1) = [0.0, 0.0, 0.0, 0.02083, 0.1875, 0.0, 0.14583, 0.0, 0.0, 0.0, 0.16667, 0.04167, 0.29167, 0.14583]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 4, 5]
StringLegalActions() = ["a", "e", "f"]

# Apply action "f"
action: 5

# State 58
# Player 1 score = 7
#   f  e  d  c  b  a
#   0  8  0  0  0  7
#   1  1  0  1  9  0
#   A  B  C  D  E  F
# Player 0 score = 14 [PLAYING]
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0, 3, 5, 5, 1, 1, 3, 2, 2, 3, 5, 5]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0 3 5 5 1 1 3 2 2 3 5 5"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "0 | 14 7 | 1 1 0 1 9 0 7 0 0 0 8 0"
ObservationString(1) = "0 | 14 7 | 1 1 0 1 9 0 7 0 0 0 8 0"
ObservationTensor(0) = [0.02083, 0.02083, 0.0, 0.02083, 0.1875, 0.0, 0.14583, 0.0, 0.0, 0.0, 0.16667, 0.0, 0.29167, 0.14583]
ObservationTensor(1) = [0.02083, 0.02083, 0.0, 0.02083, 0.1875, 0.0, 0.14583, 0.0, 0.0, 0.0, 0.16667, 0.0, 0.29167, 0.14583]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 3, 4]
StringLegalActions() = ["A", "B", "D", "E"]

# Apply action "E"
action: 4

# State 59
# Player 1 score = 7 [PLAYING]
#   f  e  d  c  b  a
#   1  9  1  1  1  8
#   2  2  0  1  0  1
#   A  B  C  D  E  F
# Player 0 score = 14
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0, 3, 5, 5, 1, 1, 3, 2, 2, 3, 5, 5, 4]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0 3 5 5 1 1 3 2 2 3 5 5 4"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
ObservationString(0) = "1 | 14 7 | 2 2 0 1 0 1 8 1 1 1 9 1"
ObservationString(1) = "1 | 14 7 | 2 2 0 1 0 1 8 1 1 1 9 1"
ObservationTensor(0) = [0.04167, 0.04167, 0.0, 0.02083, 0.0, 0.02083, 0.16667, 0.02083, 0.02083, 0.02083, 0.1875, 0.02083, 0.29167, 0.14583]
ObservationTensor(1) = [0.04167, 0.04167, 0.0, 0.02083, 0.0, 0.02083, 0.16667, 0.02083, 0.02083, 0.02083, 0.1875, 0.02083, 0.29167, 0.14583]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 2, 3, 4, 5]
StringLegalActions() = ["a", "b", "c", "d", "e", "f"]

# Apply action "f"
action: 5

# State 60
# Player 1 score = 10
#   f  e  d  c  b  a
#   0  9  1  1  1  8
#   0  2  0  1  0  1
#   A  B  C  D  E  F
# Player 0 score = 14 [PLAYING]
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0, 3, 5, 5, 1, 1, 3, 2, 2, 3, 5, 5, 4, 5]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0 3 5 5 1 1 3 2 2 3 5 5 4 5"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "0 | 14 10 | 0 2 0 1 0 1 8 1 1 1 9 0"
ObservationString(1) = "0 | 14 10 | 0 2 0 1 0 1 8 1 1 1 9 0"
ObservationTensor(0) = [0.0, 0.04167, 0.0, 0.02083, 0.0, 0.02083, 0.16667, 0.02083, 0.02083, 0.02083, 0.1875, 0.0, 0.29167, 0.20833]
ObservationTensor(1) = [0.0, 0.04167, 0.0, 0.02083, 0.0, 0.02083, 0.16667, 0.02083, 0.02083, 0.02083, 0.1875, 0.0, 0.29167, 0.20833]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [1, 3, 5]
StringLegalActions() = ["B", "D", "F"]

# Apply action "D"
action: 3

# State 61
# Player 1 score = 10 [PLAYING]
#   f  e  d  c  b  a
#   0  9  1  1  1  8
#   0  2  0  0  1  1
#   A  B  C  D  E  F
# Player 0 score = 14
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0, 3, 5, 5, 1, 1, 3, 2, 2, 3, 5, 5, 4, 5, 3]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0 3 5 5 1 1 3 2 2 3 5 5 4 5 3"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
ObservationString(0) = "1 | 14 10 | 0 2 0 0 1 1 8 1 1 1 9 0"
ObservationString(1) = "1 | 14 10 | 0 2 0 0 1 1 8 1 1 1 9 0"
ObservationTensor(0) = [0.0, 0.04167, 0.0, 0.0, 0.02083, 0.02083, 0.16667, 0.02083, 0.02083, 0.02083, 0.1875, 0.0, 0.29167, 0.20833]
ObservationTensor(1) = [0.0, 0.04167, 0.0, 0.0, 0.02083, 0.02083, 0.16667, 0.02083, 0.02083, 0.02083, 0.1875, 0.0, 0.29167, 0.20833]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 2, 3, 4]
StringLegalActions() = ["a", "b", "c", "d", "e"]

# Apply action "d"
action: 3

# State 62
# Player 1 score = 10
#   f  e  d  c  b  a
#   0 10  0  1  1  8
#   0  2  0  0  1  1
#   A  B  C  D  E  F
# Player 0 score = 14 [PLAYING]
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0, 3, 5, 5, 1, 1, 3, 2, 2, 3, 5, 5, 4, 5, 3, 3]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0 3 5 5 1 1 3 2 2 3 5 5 4 5 3 3"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "0 | 14 10 | 0 2 0 0 1 1 8 1 1 0 10 0"
ObservationString(1) = "0 | 14 10 | 0 2 0 0 1 1 8 1 1 0 10 0"
ObservationTensor(0) = [0.0, 0.04167, 0.0, 0.0, 0.02083, 0.02083, 0.16667, 0.02083, 0.02083, 0.0, 0.20833, 0.0, 0.29167, 0.20833]
ObservationTensor(1) = [0.0, 0.04167, 0.0, 0.0, 0.02083, 0.02083, 0.16667, 0.02083, 0.02083, 0.0, 0.20833, 0.0, 0.29167, 0.20833]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [1, 4, 5]
StringLegalActions() = ["B", "E", "F"]

# Apply action "B"
action: 1

# State 63
# Player 1 score = 10 [PLAYING]
#   f  e  d  c  b  a
#   0 10  0  1  1  8
#   0  0  1  1  1  1
#   A  B  C  D  E  F
# Player 0 score = 14
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0, 3, 5, 5, 1, 1, 3, 2, 2, 3, 5, 5, 4, 5, 3, 3, 1]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0 3 5 5 1 1 3 2 2 3 5 5 4 5 3 3 1"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
ObservationString(0) = "1 | 14 10 | 0 0 1 1 1 1 8 1 1 0 10 0"
ObservationString(1) = "1 | 14 10 | 0 0 1 1 1 1 8 1 1 0 10 0"
ObservationTensor(0) = [0.0, 0.0, 0.02083, 0.02083, 0.02083, 0.02083, 0.16667, 0.02083, 0.02083, 0.0, 0.20833, 0.0, 0.29167, 0.20833]
ObservationTensor(1) = [0.0, 0.0, 0.02083, 0.02083, 0.02083, 0.02083, 0.16667, 0.02083, 0.02083, 0.0, 0.20833, 0.0, 0.29167, 0.20833]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 2, 4]
StringLegalActions() = ["a", "b", "c", "e"]

# Apply action "e"
action: 4

# State 64
# Player 1 score = 10
#   f  e  d  c  b  a
#   1  0  0  2  2  9
#   1  1  2  2  2  2
#   A  B  C  D  E  F
# Player 0 score = 14 [PLAYING]
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0, 3, 5, 5, 1, 1, 3, 2, 2, 3, 5, 5, 4, 5, 3, 3, 1, 4]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0 3 5 5 1 1 3 2 2 3 5 5 4 5 3 3 1 4"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "0 | 14 10 | 1 1 2 2 2 2 9 2 2 0 0 1"
ObservationString(1) = "0 | 14 10 | 1 1 2 2 2 2 9 2 2 0 0 1"
ObservationTensor(0) = [0.02083, 0.02083, 0.04167, 0.04167, 0.04167, 0.04167, 0.1875, 0.04167, 0.04167, 0.0, 0.0, 0.02083, 0.29167, 0.20833]
ObservationTensor(1) = [0.02083, 0.02083, 0.04167, 0.04167, 0.04167, 0.04167, 0.1875, 0.04167, 0.04167, 0.0, 0.0, 0.02083, 0.29167, 0.20833]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 2, 3, 4, 5]
StringLegalActions() = ["A", "B", "C", "D", "E", "F"]

# Apply action "D"
action: 3

# State 65
# Player 1 score = 10 [PLAYING]
#   f  e  d  c  b  a
#   1  0  0  2  2  9
#   1  1  2  0  3  3
#   A  B  C  D  E  F
# Player 0 score = 14
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0, 3, 5, 5, 1, 1, 3, 2, 2, 3, 5, 5, 4, 5, 3, 3, 1, 4, 3]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0 3 5 5 1 1 3 2 2 3 5 5 4 5 3 3 1 4 3"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
ObservationString(0) = "1 | 14 10 | 1 1 2 0 3 3 9 2 2 0 0 1"
ObservationString(1) = "1 | 14 10 | 1 1 2 0 3 3 9 2 2 0 0 1"
ObservationTensor(0) = [0.02083, 0.02083, 0.04167, 0.0, 0.0625, 0.0625, 0.1875, 0.04167, 0.04167, 0.0, 0.0, 0.02083, 0.29167, 0.20833]
ObservationTensor(1) = [0.02083, 0.02083, 0.04167, 0.0, 0.0625, 0.0625, 0.1875, 0.04167, 0.04167, 0.0, 0.0, 0.02083, 0.29167, 0.20833]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 2, 5]
StringLegalActions() = ["a", "b", "c", "f"]

# Apply action "b"
action: 1

# State 66
# Player 1 score = 10
#   f  e  d  c  b  a
#   1  0  1  3  0  9
#   1  1  2  0  3  3
#   A  B  C  D  E  F
# Player 0 score = 14 [PLAYING]
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0, 3, 5, 5, 1, 1, 3, 2, 2, 3, 5, 5, 4, 5, 3, 3, 1, 4, 3, 1]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0 3 5 5 1 1 3 2 2 3 5 5 4 5 3 3 1 4 3 1"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "0 | 14 10 | 1 1 2 0 3 3 9 0 3 1 0 1"
ObservationString(1) = "0 | 14 10 | 1 1 2 0 3 3 9 0 3 1 0 1"
ObservationTensor(0) = [0.02083, 0.02083, 0.04167, 0.0, 0.0625, 0.0625, 0.1875, 0.0, 0.0625, 0.02083, 0.0, 0.02083, 0.29167, 0.20833]
ObservationTensor(1) = [0.02083, 0.02083, 0.04167, 0.0, 0.0625, 0.0625, 0.1875, 0.0, 0.0625, 0.02083, 0.0, 0.02083, 0.29167, 0.20833]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 2, 4, 5]
StringLegalActions() = ["A", "B", "C", "E", "F"]

# Apply action "F"
action: 5

# State 67
# Player 1 score = 10 [PLAYING]
#   f  e  d  c  b  a
#   1  0  1  4  1 10
#   1  1  2  0  3  0
#   A  B  C  D  E  F
# Player 0 score = 14
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0, 3, 5, 5, 1, 1, 3, 2, 2, 3, 5, 5, 4, 5, 3, 3, 1, 4, 3, 1, 5]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0 3 5 5 1 1 3 2 2 3 5 5 4 5 3 3 1 4 3 1 5"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
ObservationString(0) = "1 | 14 10 | 1 1 2 0 3 0 10 1 4 1 0 1"
ObservationString(1) = "1 | 14 10 | 1 1 2 0 3 0 10 1 4 1 0 1"
ObservationTensor(0) = [0.02083, 0.02083, 0.04167, 0.0, 0.0625, 0.0, 0.20833, 0.02083, 0.08333, 0.02083, 0.0, 0.02083, 0.29167, 0.20833]
ObservationTensor(1) = [0.02083, 0.02083, 0.04167, 0.0, 0.0625, 0.0, 0.20833, 0.02083, 0.08333, 0.02083, 0.0, 0.02083, 0.29167, 0.20833]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 2, 3, 5]
StringLegalActions() = ["a", "b", "c", "d", "f"]

# Apply action "b"
action: 1

# State 68
# Player 1 score = 10
#   f  e  d  c  b  a
#   1  0  1  5  0 10
#   1  1  2  0  3  0
#   A  B  C  D  E  F
# Player 0 score = 14 [PLAYING]
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0, 3, 5, 5, 1, 1, 3, 2, 2, 3, 5, 5, 4, 5, 3, 3, 1, 4, 3, 1, 5, 1]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0 3 5 5 1 1 3 2 2 3 5 5 4 5 3 3 1 4 3 1 5 1"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "0 | 14 10 | 1 1 2 0 3 0 10 0 5 1 0 1"
ObservationString(1) = "0 | 14 10 | 1 1 2 0 3 0 10 0 5 1 0 1"
ObservationTensor(0) = [0.02083, 0.02083, 0.04167, 0.0, 0.0625, 0.0, 0.20833, 0.0, 0.10417, 0.02083, 0.0, 0.02083, 0.29167, 0.20833]
ObservationTensor(1) = [0.02083, 0.02083, 0.04167, 0.0, 0.0625, 0.0, 0.20833, 0.0, 0.10417, 0.02083, 0.0, 0.02083, 0.29167, 0.20833]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 2, 4]
StringLegalActions() = ["A", "B", "C", "E"]

# Apply action "E"
action: 4

# State 69
# Player 1 score = 10 [PLAYING]
#   f  e  d  c  b  a
#   1  0  1  5  1 11
#   1  1  2  0  0  1
#   A  B  C  D  E  F
# Player 0 score = 14
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0, 3, 5, 5, 1, 1, 3, 2, 2, 3, 5, 5, 4, 5, 3, 3, 1, 4, 3, 1, 5, 1, 4]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0 3 5 5 1 1 3 2 2 3 5 5 4 5 3 3 1 4 3 1 5 1 4"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
ObservationString(0) = "1 | 14 10 | 1 1 2 0 0 1 11 1 5 1 0 1"
ObservationString(1) = "1 | 14 10 | 1 1 2 0 0 1 11 1 5 1 0 1"
ObservationTensor(0) = [0.02083, 0.02083, 0.04167, 0.0, 0.0, 0.02083, 0.22917, 0.02083, 0.10417, 0.02083, 0.0, 0.02083, 0.29167, 0.20833]
ObservationTensor(1) = [0.02083, 0.02083, 0.04167, 0.0, 0.0, 0.02083, 0.22917, 0.02083, 0.10417, 0.02083, 0.0, 0.02083, 0.29167, 0.20833]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 2, 3, 5]
StringLegalActions() = ["a", "b", "c", "d", "f"]

# Apply action "d"
action: 3

# State 70
# Player 1 score = 10
#   f  e  d  c  b  a
#   1  1  0  5  1 11
#   1  1  2  0  0  1
#   A  B  C  D  E  F
# Player 0 score = 14 [PLAYING]
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0, 3, 5, 5, 1, 1, 3, 2, 2, 3, 5, 5, 4, 5, 3, 3, 1, 4, 3, 1, 5, 1, 4, 3]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0 3 5 5 1 1 3 2 2 3 5 5 4 5 3 3 1 4 3 1 5 1 4 3"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "0 | 14 10 | 1 1 2 0 0 1 11 1 5 0 1 1"
ObservationString(1) = "0 | 14 10 | 1 1 2 0 0 1 11 1 5 0 1 1"
ObservationTensor(0) = [0.02083, 0.02083, 0.04167, 0.0, 0.0, 0.02083, 0.22917, 0.02083, 0.10417, 0.0, 0.02083, 0.02083, 0.29167, 0.20833]
ObservationTensor(1) = [0.02083, 0.02083, 0.04167, 0.0, 0.0, 0.02083, 0.22917, 0.02083, 0.10417, 0.0, 0.02083, 0.02083, 0.29167, 0.20833]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 2, 5]
StringLegalActions() = ["A", "B", "C", "F"]

# Apply action "B"
action: 1

# State 71
# Player 1 score = 10 [PLAYING]
#   f  e  d  c  b  a
#   1  1  0  5  1 11
#   1  0  3  0  0  1
#   A  B  C  D  E  F
# Player 0 score = 14
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0, 3, 5, 5, 1, 1, 3, 2, 2, 3, 5, 5, 4, 5, 3, 3, 1, 4, 3, 1, 5, 1, 4, 3, 1]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0 3 5 5 1 1 3 2 2 3 5 5 4 5 3 3 1 4 3 1 5 1 4 3 1"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
ObservationString(0) = "1 | 14 10 | 1 0 3 0 0 1 11 1 5 0 1 1"
ObservationString(1) = "1 | 14 10 | 1 0 3 0 0 1 11 1 5 0 1 1"
ObservationTensor(0) = [0.02083, 0.0, 0.0625, 0.0, 0.0, 0.02083, 0.22917, 0.02083, 0.10417, 0.0, 0.02083, 0.02083, 0.29167, 0.20833]
ObservationTensor(1) = [0.02083, 0.0, 0.0625, 0.0, 0.0, 0.02083, 0.22917, 0.02083, 0.10417, 0.0, 0.02083, 0.02083, 0.29167, 0.20833]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 2, 4, 5]
StringLegalActions() = ["a", "b", "c", "e", "f"]

# Apply action "f"
action: 5

# State 72
# Player 1 score = 12
#   f  e  d  c  b  a
#   0  1  0  5  1 11
#   0  0  3  0  0  1
#   A  B  C  D  E  F
# Player 0 score = 14 [PLAYING]
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0, 3, 5, 5, 1, 1, 3, 2, 2, 3, 5, 5, 4, 5, 3, 3, 1, 4, 3, 1, 5, 1, 4, 3, 1, 5]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0 3 5 5 1 1 3 2 2 3 5 5 4 5 3 3 1 4 3 1 5 1 4 3 1 5"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "0 | 14 12 | 0 0 3 0 0 1 11 1 5 0 1 0"
ObservationString(1) = "0 | 14 12 | 0 0 3 0 0 1 11 1 5 0 1 0"
ObservationTensor(0) = [0.0, 0.0, 0.0625, 0.0, 0.0, 0.02083, 0.22917, 0.02083, 0.10417, 0.0, 0.02083, 0.0, 0.29167, 0.25]
ObservationTensor(1) = [0.0, 0.0, 0.0625, 0.0, 0.0, 0.02083, 0.22917, 0.02083, 0.10417, 0.0, 0.02083, 0.0, 0.29167, 0.25]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [2, 5]
StringLegalActions() = ["C", "F"]

# Apply action "C"
action: 2

# State 73
# Player 1 score = 12 [PLAYING]
#   f  e  d  c  b  a
#   0  1  0  5  1 11
#   0  0  0  1  1  2
#   A  B  C  D  E  F
# Player 0 score = 14
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0, 3, 5, 5, 1, 1, 3, 2, 2, 3, 5, 5, 4, 5, 3, 3, 1, 4, 3, 1, 5, 1, 4, 3, 1, 5, 2]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0 3 5 5 1 1 3 2 2 3 5 5 4 5 3 3 1 4 3 1 5 1 4 3 1 5 2"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
ObservationString(0) = "1 | 14 12 | 0 0 0 1 1 2 11 1 5 0 1 0"
ObservationString(1) = "1 | 14 12 | 0 0 0 1 1 2 11 1 5 0 1 0"
ObservationTensor(0) = [0.0, 0.0, 0.0, 0.02083, 0.02083, 0.04167, 0.22917, 0.02083, 0.10417, 0.0, 0.02083, 0.0, 0.29167, 0.25]
ObservationTensor(1) = [0.0, 0.0, 0.0, 0.02083, 0.02083, 0.04167, 0.22917, 0.02083, 0.10417, 0.0, 0.02083, 0.0, 0.29167, 0.25]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 2, 4]
StringLegalActions() = ["a", "b", "c", "e"]

# Apply action "b"
action: 1

# State 74
# Player 1 score = 12
#   f  e  d  c  b  a
#   0  1  0  6  0 11
#   0  0  0  1  1  2
#   A  B  C  D  E  F
# Player 0 score = 14 [PLAYING]
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0, 3, 5, 5, 1, 1, 3, 2, 2, 3, 5, 5, 4, 5, 3, 3, 1, 4, 3, 1, 5, 1, 4, 3, 1, 5, 2, 1]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0 3 5 5 1 1 3 2 2 3 5 5 4 5 3 3 1 4 3 1 5 1 4 3 1 5 2 1"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "0 | 14 12 | 0 0 0 1 1 2 11 0 6 0 1 0"
ObservationString(1) = "0 | 14 12 | 0 0 0 1 1 2 11 0 6 0 1 0"
ObservationTensor(0) = [0.0, 0.0, 0.0, 0.02083, 0.02083, 0.04167, 0.22917, 0.0, 0.125, 0.0, 0.02083, 0.0, 0.29167, 0.25]
ObservationTensor(1) = [0.0, 0.0, 0.0, 0.02083, 0.02083, 0.04167, 0.22917, 0.0, 0.125, 0.0, 0.02083, 0.0, 0.29167, 0.25]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [3, 4, 5]
StringLegalActions() = ["D", "E", "F"]

# Apply action "F"
action: 5

# State 75
# Player 1 score = 12 [PLAYING]
#   f  e  d  c  b  a
#   0  1  0  6  1 12
#   0  0  0  1  1  0
#   A  B  C  D  E  F
# Player 0 score = 14
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0, 3, 5, 5, 1, 1, 3, 2, 2, 3, 5, 5, 4, 5, 3, 3, 1, 4, 3, 1, 5, 1, 4, 3, 1, 5, 2, 1, 5]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0 3 5 5 1 1 3 2 2 3 5 5 4 5 3 3 1 4 3 1 5 1 4 3 1 5 2 1 5"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
ObservationString(0) = "1 | 14 12 | 0 0 0 1 1 0 12 1 6 0 1 0"
ObservationString(1) = "1 | 14 12 | 0 0 0 1 1 0 12 1 6 0 1 0"
ObservationTensor(0) = [0.0, 0.0, 0.0, 0.02083, 0.02083, 0.0, 0.25, 0.02083, 0.125, 0.0, 0.02083, 0.0, 0.29167, 0.25]
ObservationTensor(1) = [0.0, 0.0, 0.0, 0.02083, 0.02083, 0.0, 0.25, 0.02083, 0.125, 0.0, 0.02083, 0.0, 0.29167, 0.25]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 2, 4]
StringLegalActions() = ["a", "b", "c", "e"]

# Apply action "b"
action: 1

# State 76
# Player 1 score = 12
#   f  e  d  c  b  a
#   0  1  0  7  0 12
#   0  0  0  1  1  0
#   A  B  C  D  E  F
# Player 0 score = 14 [PLAYING]
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0, 3, 5, 5, 1, 1, 3, 2, 2, 3, 5, 5, 4, 5, 3, 3, 1, 4, 3, 1, 5, 1, 4, 3, 1, 5, 2, 1, 5, 1]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0 3 5 5 1 1 3 2 2 3 5 5 4 5 3 3 1 4 3 1 5 1 4 3 1 5 2 1 5 1"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "0 | 14 12 | 0 0 0 1 1 0 12 0 7 0 1 0"
ObservationString(1) = "0 | 14 12 | 0 0 0 1 1 0 12 0 7 0 1 0"
ObservationTensor(0) = [0.0, 0.0, 0.0, 0.02083, 0.02083, 0.0, 0.25, 0.0, 0.14583, 0.0, 0.02083, 0.0, 0.29167, 0.25]
ObservationTensor(1) = [0.0, 0.0, 0.0, 0.02083, 0.02083, 0.0, 0.25, 0.0, 0.14583, 0.0, 0.02083, 0.0, 0.29167, 0.25]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [3, 4]
StringLegalActions() = ["D", "E"]

# Apply action "D"
action: 3

# State 77
# Player 1 score = 12 [PLAYING]
#   f  e  d  c  b  a
#   0  1  0  7  0 12
#   0  0  0  0  2  0
#   A  B  C  D  E  F
# Player 0 score = 14
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0, 3, 5, 5, 1, 1, 3, 2, 2, 3, 5, 5, 4, 5, 3, 3, 1, 4, 3, 1, 5, 1, 4, 3, 1, 5, 2, 1, 5, 1, 3]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0 3 5 5 1 1 3 2 2 3 5 5 4 5 3 3 1 4 3 1 5 1 4 3 1 5 2 1 5 1 3"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
ObservationString(0) = "1 | 14 12 | 0 0 0 0 2 0 12 0 7 0 1 0"
ObservationString(1) = "1 | 14 12 | 0 0 0 0 2 0 12 0 7 0 1 0"
ObservationTensor(0) = [0.0, 0.0, 0.0, 0.0, 0.04167, 0.0, 0.25, 0.0, 0.14583, 0.0, 0.02083, 0.0, 0.29167, 0.25]
ObservationTensor(1) = [0.0, 0.0, 0.0, 0.0, 0.04167, 0.0, 0.25, 0.0, 0.14583, 0.0, 0.02083, 0.0, 0.29167, 0.25]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 4]
StringLegalActions() = ["a", "c", "e"]

# Apply action "c"
action: 2

# State 78
# Player 1 score = 12
#   f  e  d  c  b  a
#   1  2  1  0  0 12
#   1  1  1  1  2  0
#   A  B  C  D  E  F
# Player 0 score = 14 [PLAYING]
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0, 3, 5, 5, 1, 1, 3, 2, 2, 3, 5, 5, 4, 5, 3, 3, 1, 4, 3, 1, 5, 1, 4, 3, 1, 5, 2, 1, 5, 1, 3, 2]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0 3 5 5 1 1 3 2 2 3 5 5 4 5 3 3 1 4 3 1 5 1 4 3 1 5 2 1 5 1 3 2"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "0 | 14 12 | 1 1 1 1 2 0 12 0 0 1 2 1"
ObservationString(1) = "0 | 14 12 | 1 1 1 1 2 0 12 0 0 1 2 1"
ObservationTensor(0) = [0.02083, 0.02083, 0.02083, 0.02083, 0.04167, 0.0, 0.25, 0.0, 0.0, 0.02083, 0.04167, 0.02083, 0.29167, 0.25]
ObservationTensor(1) = [0.02083, 0.02083, 0.02083, 0.02083, 0.04167, 0.0, 0.25, 0.0, 0.0, 0.02083, 0.04167, 0.02083, 0.29167, 0.25]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 2, 3, 4]
StringLegalActions() = ["A", "B", "C", "D", "E"]

# Apply action "C"
action: 2

# State 79
# Player 1 score = 12 [PLAYING]
#   f  e  d  c  b  a
#   1  2  1  0  0 12
#   1  1  0  2  2  0
#   A  B  C  D  E  F
# Player 0 score = 14
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0, 3, 5, 5, 1, 1, 3, 2, 2, 3, 5, 5, 4, 5, 3, 3, 1, 4, 3, 1, 5, 1, 4, 3, 1, 5, 2, 1, 5, 1, 3, 2, 2]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0 3 5 5 1 1 3 2 2 3 5 5 4 5 3 3 1 4 3 1 5 1 4 3 1 5 2 1 5 1 3 2 2"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
ObservationString(0) = "1 | 14 12 | 1 1 0 2 2 0 12 0 0 1 2 1"
ObservationString(1) = "1 | 14 12 | 1 1 0 2 2 0 12 0 0 1 2 1"
ObservationTensor(0) = [0.02083, 0.02083, 0.0, 0.04167, 0.04167, 0.0, 0.25, 0.0, 0.0, 0.02083, 0.04167, 0.02083, 0.29167, 0.25]
ObservationTensor(1) = [0.02083, 0.02083, 0.0, 0.04167, 0.04167, 0.0, 0.25, 0.0, 0.0, 0.02083, 0.04167, 0.02083, 0.29167, 0.25]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 3, 4, 5]
StringLegalActions() = ["a", "d", "e", "f"]

# Apply action "f"
action: 5

# State 80
# Player 1 score = 14
#   f  e  d  c  b  a
#   0  2  1  0  0 12
#   0  1  0  2  2  0
#   A  B  C  D  E  F
# Player 0 score = 14 [PLAYING]
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0, 3, 5, 5, 1, 1, 3, 2, 2, 3, 5, 5, 4, 5, 3, 3, 1, 4, 3, 1, 5, 1, 4, 3, 1, 5, 2, 1, 5, 1, 3, 2, 2, 5]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0 3 5 5 1 1 3 2 2 3 5 5 4 5 3 3 1 4 3 1 5 1 4 3 1 5 2 1 5 1 3 2 2 5"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "0 | 14 14 | 0 1 0 2 2 0 12 0 0 1 2 0"
ObservationString(1) = "0 | 14 14 | 0 1 0 2 2 0 12 0 0 1 2 0"
ObservationTensor(0) = [0.0, 0.02083, 0.0, 0.04167, 0.04167, 0.0, 0.25, 0.0, 0.0, 0.02083, 0.04167, 0.0, 0.29167, 0.29167]
ObservationTensor(1) = [0.0, 0.02083, 0.0, 0.04167, 0.04167, 0.0, 0.25, 0.0, 0.0, 0.02083, 0.04167, 0.0, 0.29167, 0.29167]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [1, 3, 4]
StringLegalActions() = ["B", "D", "E"]

# Apply action "E"
action: 4

# State 81
# Player 1 score = 14 [PLAYING]
#   f  e  d  c  b  a
#   0  2  1  0  0 13
#   0  1  0  2  0  1
#   A  B  C  D  E  F
# Player 0 score = 14
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0, 3, 5, 5, 1, 1, 3, 2, 2, 3, 5, 5, 4, 5, 3, 3, 1, 4, 3, 1, 5, 1, 4, 3, 1, 5, 2, 1, 5, 1, 3, 2, 2, 5, 4]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0 3 5 5 1 1 3 2 2 3 5 5 4 5 3 3 1 4 3 1 5 1 4 3 1 5 2 1 5 1 3 2 2 5 4"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
ObservationString(0) = "1 | 14 14 | 0 1 0 2 0 1 13 0 0 1 2 0"
ObservationString(1) = "1 | 14 14 | 0 1 0 2 0 1 13 0 0 1 2 0"
ObservationTensor(0) = [0.0, 0.02083, 0.0, 0.04167, 0.0, 0.02083, 0.27083, 0.0, 0.0, 0.02083, 0.04167, 0.0, 0.29167, 0.29167]
ObservationTensor(1) = [0.0, 0.02083, 0.0, 0.04167, 0.0, 0.02083, 0.27083, 0.0, 0.0, 0.02083, 0.04167, 0.0, 0.29167, 0.29167]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 3, 4]
StringLegalActions() = ["a", "d", "e"]

# Apply action "e"
action: 4

# State 82
# Player 1 score = 14
#   f  e  d  c  b  a
#   1  0  1  0  0 13
#   1  1  0  2  0  1
#   A  B  C  D  E  F
# Player 0 score = 14 [PLAYING]
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0, 3, 5, 5, 1, 1, 3, 2, 2, 3, 5, 5, 4, 5, 3, 3, 1, 4, 3, 1, 5, 1, 4, 3, 1, 5, 2, 1, 5, 1, 3, 2, 2, 5, 4, 4]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0 3 5 5 1 1 3 2 2 3 5 5 4 5 3 3 1 4 3 1 5 1 4 3 1 5 2 1 5 1 3 2 2 5 4 4"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "0 | 14 14 | 1 1 0 2 0 1 13 0 0 1 0 1"
ObservationString(1) = "0 | 14 14 | 1 1 0 2 0 1 13 0 0 1 0 1"
ObservationTensor(0) = [0.02083, 0.02083, 0.0, 0.04167, 0.0, 0.02083, 0.27083, 0.0, 0.0, 0.02083, 0.0, 0.02083, 0.29167, 0.29167]
ObservationTensor(1) = [0.02083, 0.02083, 0.0, 0.04167, 0.0, 0.02083, 0.27083, 0.0, 0.0, 0.02083, 0.0, 0.02083, 0.29167, 0.29167]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 3, 5]
StringLegalActions() = ["A", "B", "D", "F"]

# Apply action "D"
action: 3

# State 83
# Player 1 score = 14 [PLAYING]
#   f  e  d  c  b  a
#   1  0  1  0  0 13
#   1  1  0  0  1  2
#   A  B  C  D  E  F
# Player 0 score = 14
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0, 3, 5, 5, 1, 1, 3, 2, 2, 3, 5, 5, 4, 5, 3, 3, 1, 4, 3, 1, 5, 1, 4, 3, 1, 5, 2, 1, 5, 1, 3, 2, 2, 5, 4, 4, 3]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0 3 5 5 1 1 3 2 2 3 5 5 4 5 3 3 1 4 3 1 5 1 4 3 1 5 2 1 5 1 3 2 2 5 4 4 3"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
ObservationString(0) = "1 | 14 14 | 1 1 0 0 1 2 13 0 0 1 0 1"
ObservationString(1) = "1 | 14 14 | 1 1 0 0 1 2 13 0 0 1 0 1"
ObservationTensor(0) = [0.02083, 0.02083, 0.0, 0.0, 0.02083, 0.04167, 0.27083, 0.0, 0.0, 0.02083, 0.0, 0.02083, 0.29167, 0.29167]
ObservationTensor(1) = [0.02083, 0.02083, 0.0, 0.0, 0.02083, 0.04167, 0.27083, 0.0, 0.0, 0.02083, 0.0, 0.02083, 0.29167, 0.29167]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 3, 5]
StringLegalActions() = ["a", "d", "f"]

# Apply action "d"
action: 3

# State 84
# Player 1 score = 14
#   f  e  d  c  b  a
#   1  1  0  0  0 13
#   1  1  0  0  1  2
#   A  B  C  D  E  F
# Player 0 score = 14 [PLAYING]
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0, 3, 5, 5, 1, 1, 3, 2, 2, 3, 5, 5, 4, 5, 3, 3, 1, 4, 3, 1, 5, 1, 4, 3, 1, 5, 2, 1, 5, 1, 3, 2, 2, 5, 4, 4, 3, 3]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0 3 5 5 1 1 3 2 2 3 5 5 4 5 3 3 1 4 3 1 5 1 4 3 1 5 2 1 5 1 3 2 2 5 4 4 3 3"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "0 | 14 14 | 1 1 0 0 1 2 13 0 0 0 1 1"
ObservationString(1) = "0 | 14 14 | 1 1 0 0 1 2 13 0 0 0 1 1"
ObservationTensor(0) = [0.02083, 0.02083, 0.0, 0.0, 0.02083, 0.04167, 0.27083, 0.0, 0.0, 0.0, 0.02083, 0.02083, 0.29167, 0.29167]
ObservationTensor(1) = [0.02083, 0.02083, 0.0, 0.0, 0.02083, 0.04167, 0.27083, 0.0, 0.0, 0.0, 0.02083, 0.02083, 0.29167, 0.29167]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 4, 5]
StringLegalActions() = ["A", "B", "E", "F"]

# Apply action "B"
action: 1

# State 85
# Player 1 score = 14 [PLAYING]
#   f  e  d  c  b  a
#   1  1  0  0  0 13
#   1  0  1  0  1  2
#   A  B  C  D  E  F
# Player 0 score = 14
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0, 3, 5, 5, 1, 1, 3, 2, 2, 3, 5, 5, 4, 5, 3, 3, 1, 4, 3, 1, 5, 1, 4, 3, 1, 5, 2, 1, 5, 1, 3, 2, 2, 5, 4, 4, 3, 3, 1]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0 3 5 5 1 1 3 2 2 3 5 5 4 5 3 3 1 4 3 1 5 1 4 3 1 5 2 1 5 1 3 2 2 5 4 4 3 3 1"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
ObservationString(0) = "1 | 14 14 | 1 0 1 0 1 2 13 0 0 0 1 1"
ObservationString(1) = "1 | 14 14 | 1 0 1 0 1 2 13 0 0 0 1 1"
ObservationTensor(0) = [0.02083, 0.0, 0.02083, 0.0, 0.02083, 0.04167, 0.27083, 0.0, 0.0, 0.0, 0.02083, 0.02083, 0.29167, 0.29167]
ObservationTensor(1) = [0.02083, 0.0, 0.02083, 0.0, 0.02083, 0.04167, 0.27083, 0.0, 0.0, 0.0, 0.02083, 0.02083, 0.29167, 0.29167]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 4, 5]
StringLegalActions() = ["a", "e", "f"]

# Apply action "a"
action: 0

# State 86
# Player 1 score = 14
#   f  e  d  c  b  a
#   2  2  1  2  2  0
#   2  1  2  1  2  3
#   A  B  C  D  E  F
# Player 0 score = 14 [PLAYING]
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0, 3, 5, 5, 1, 1, 3, 2, 2, 3, 5, 5, 4, 5, 3, 3, 1, 4, 3, 1, 5, 1, 4, 3, 1, 5, 2, 1, 5, 1, 3, 2, 2, 5, 4, 4, 3, 3, 1, 0]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0 3 5 5 1 1 3 2 2 3 5 5 4 5 3 3 1 4 3 1 5 1 4 3 1 5 2 1 5 1 3 2 2 5 4 4 3 3 1 0"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "0 | 14 14 | 2 1 2 1 2 3 0 2 2 1 2 2"
ObservationString(1) = "0 | 14 14 | 2 1 2 1 2 3 0 2 2 1 2 2"
ObservationTensor(0) = [0.04167, 0.02083, 0.04167, 0.02083, 0.04167, 0.0625, 0.0, 0.04167, 0.04167, 0.02083, 0.04167, 0.04167, 0.29167, 0.29167]
ObservationTensor(1) = [0.04167, 0.02083, 0.04167, 0.02083, 0.04167, 0.0625, 0.0, 0.04167, 0.04167, 0.02083, 0.04167, 0.04167, 0.29167, 0.29167]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 2, 3, 4, 5]
StringLegalActions() = ["A", "B", "C", "D", "E", "F"]

# Apply action "E"
action: 4

# State 87
# Player 1 score = 14 [PLAYING]
#   f  e  d  c  b  a
#   2  2  1  2  2  1
#   2  1  2  1  0  4
#   A  B  C  D  E  F
# Player 0 score = 14
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0, 3, 5, 5, 1, 1, 3, 2, 2, 3, 5, 5, 4, 5, 3, 3, 1, 4, 3, 1, 5, 1, 4, 3, 1, 5, 2, 1, 5, 1, 3, 2, 2, 5, 4, 4, 3, 3, 1, 0, 4]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0 3 5 5 1 1 3 2 2 3 5 5 4 5 3 3 1 4 3 1 5 1 4 3 1 5 2 1 5 1 3 2 2 5 4 4 3 3 1 0 4"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
ObservationString(0) = "1 | 14 14 | 2 1 2 1 0 4 1 2 2 1 2 2"
ObservationString(1) = "1 | 14 14 | 2 1 2 1 0 4 1 2 2 1 2 2"
ObservationTensor(0) = [0.04167, 0.02083, 0.04167, 0.02083, 0.0, 0.08333, 0.02083, 0.04167, 0.04167, 0.02083, 0.04167, 0.04167, 0.29167, 0.29167]
ObservationTensor(1) = [0.04167, 0.02083, 0.04167, 0.02083, 0.0, 0.08333, 0.02083, 0.04167, 0.04167, 0.02083, 0.04167, 0.04167, 0.29167, 0.29167]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 2, 3, 4, 5]
StringLegalActions() = ["a", "b", "c", "d", "e", "f"]

# Apply action "a"
action: 0

# State 88
# Player 1 score = 14
#   f  e  d  c  b  a
#   2  2  1  2  3  0
#   2  1  2  1  0  4
#   A  B  C  D  E  F
# Player 0 score = 14 [PLAYING]
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0, 3, 5, 5, 1, 1, 3, 2, 2, 3, 5, 5, 4, 5, 3, 3, 1, 4, 3, 1, 5, 1, 4, 3, 1, 5, 2, 1, 5, 1, 3, 2, 2, 5, 4, 4, 3, 3, 1, 0, 4, 0]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0 3 5 5 1 1 3 2 2 3 5 5 4 5 3 3 1 4 3 1 5 1 4 3 1 5 2 1 5 1 3 2 2 5 4 4 3 3 1 0 4 0"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "0 | 14 14 | 2 1 2 1 0 4 0 3 2 1 2 2"
ObservationString(1) = "0 | 14 14 | 2 1 2 1 0 4 0 3 2 1 2 2"
ObservationTensor(0) = [0.04167, 0.02083, 0.04167, 0.02083, 0.0, 0.08333, 0.0, 0.0625, 0.04167, 0.02083, 0.04167, 0.04167, 0.29167, 0.29167]
ObservationTensor(1) = [0.04167, 0.02083, 0.04167, 0.02083, 0.0, 0.08333, 0.0, 0.0625, 0.04167, 0.02083, 0.04167, 0.04167, 0.29167, 0.29167]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 2, 3, 5]
StringLegalActions() = ["A", "B", "C", "D", "F"]

# Apply action "C"
action: 2

# State 89
# Player 1 score = 14 [PLAYING]
#   f  e  d  c  b  a
#   2  2  1  2  3  0
#   2  1  0  2  1  4
#   A  B  C  D  E  F
# Player 0 score = 14
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0, 3, 5, 5, 1, 1, 3, 2, 2, 3, 5, 5, 4, 5, 3, 3, 1, 4, 3, 1, 5, 1, 4, 3, 1, 5, 2, 1, 5, 1, 3, 2, 2, 5, 4, 4, 3, 3, 1, 0, 4, 0, 2]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0 3 5 5 1 1 3 2 2 3 5 5 4 5 3 3 1 4 3 1 5 1 4 3 1 5 2 1 5 1 3 2 2 5 4 4 3 3 1 0 4 0 2"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
ObservationString(0) = "1 | 14 14 | 2 1 0 2 1 4 0 3 2 1 2 2"
ObservationString(1) = "1 | 14 14 | 2 1 0 2 1 4 0 3 2 1 2 2"
ObservationTensor(0) = [0.04167, 0.02083, 0.0, 0.04167, 0.02083, 0.08333, 0.0, 0.0625, 0.04167, 0.02083, 0.04167, 0.04167, 0.29167, 0.29167]
ObservationTensor(1) = [0.04167, 0.02083, 0.0, 0.04167, 0.02083, 0.08333, 0.0, 0.0625, 0.04167, 0.02083, 0.04167, 0.04167, 0.29167, 0.29167]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [1, 2, 3, 4, 5]
StringLegalActions() = ["b", "c", "d", "e", "f"]

# Apply action "b"
action: 1

# State 90
# Player 1 score = 14
#   f  e  d  c  b  a
#   2  3  2  3  0  0
#   2  1  0  2  1  4
#   A  B  C  D  E  F
# Player 0 score = 14 [PLAYING]
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0, 3, 5, 5, 1, 1, 3, 2, 2, 3, 5, 5, 4, 5, 3, 3, 1, 4, 3, 1, 5, 1, 4, 3, 1, 5, 2, 1, 5, 1, 3, 2, 2, 5, 4, 4, 3, 3, 1, 0, 4, 0, 2, 1]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0 3 5 5 1 1 3 2 2 3 5 5 4 5 3 3 1 4 3 1 5 1 4 3 1 5 2 1 5 1 3 2 2 5 4 4 3 3 1 0 4 0 2 1"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "0 | 14 14 | 2 1 0 2 1 4 0 0 3 2 3 2"
ObservationString(1) = "0 | 14 14 | 2 1 0 2 1 4 0 0 3 2 3 2"
ObservationTensor(0) = [0.04167, 0.02083, 0.0, 0.04167, 0.02083, 0.08333, 0.0, 0.0, 0.0625, 0.04167, 0.0625, 0.04167, 0.29167, 0.29167]
ObservationTensor(1) = [0.04167, 0.02083, 0.0, 0.04167, 0.02083, 0.08333, 0.0, 0.0, 0.0625, 0.04167, 0.0625, 0.04167, 0.29167, 0.29167]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 3, 4, 5]
StringLegalActions() = ["A", "B", "D", "E", "F"]

# Apply action "F"
action: 5

# State 91
# Player 1 score = 14 [PLAYING]
#   f  e  d  c  b  a
#   2  3  0  4  1  1
#   2  1  0  2  1  0
#   A  B  C  D  E  F
# Player 0 score = 17
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0, 3, 5, 5, 1, 1, 3, 2, 2, 3, 5, 5, 4, 5, 3, 3, 1, 4, 3, 1, 5, 1, 4, 3, 1, 5, 2, 1, 5, 1, 3, 2, 2, 5, 4, 4, 3, 3, 1, 0, 4, 0, 2, 1, 5]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0 3 5 5 1 1 3 2 2 3 5 5 4 5 3 3 1 4 3 1 5 1 4 3 1 5 2 1 5 1 3 2 2 5 4 4 3 3 1 0 4 0 2 1 5"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
ObservationString(0) = "1 | 17 14 | 2 1 0 2 1 0 1 1 4 0 3 2"
ObservationString(1) = "1 | 17 14 | 2 1 0 2 1 0 1 1 4 0 3 2"
ObservationTensor(0) = [0.04167, 0.02083, 0.0, 0.04167, 0.02083, 0.0, 0.02083, 0.02083, 0.08333, 0.0, 0.0625, 0.04167, 0.35417, 0.29167]
ObservationTensor(1) = [0.04167, 0.02083, 0.0, 0.04167, 0.02083, 0.0, 0.02083, 0.02083, 0.08333, 0.0, 0.0625, 0.04167, 0.35417, 0.29167]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 2, 4, 5]
StringLegalActions() = ["a", "b", "c", "e", "f"]

# Apply action "a"
action: 0

# State 92
# Player 1 score = 14
#   f  e  d  c  b  a
#   2  3  0  4  2  0
#   2  1  0  2  1  0
#   A  B  C  D  E  F
# Player 0 score = 17 [PLAYING]
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0, 3, 5, 5, 1, 1, 3, 2, 2, 3, 5, 5, 4, 5, 3, 3, 1, 4, 3, 1, 5, 1, 4, 3, 1, 5, 2, 1, 5, 1, 3, 2, 2, 5, 4, 4, 3, 3, 1, 0, 4, 0, 2, 1, 5, 0]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0 3 5 5 1 1 3 2 2 3 5 5 4 5 3 3 1 4 3 1 5 1 4 3 1 5 2 1 5 1 3 2 2 5 4 4 3 3 1 0 4 0 2 1 5 0"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "0 | 17 14 | 2 1 0 2 1 0 0 2 4 0 3 2"
ObservationString(1) = "0 | 17 14 | 2 1 0 2 1 0 0 2 4 0 3 2"
ObservationTensor(0) = [0.04167, 0.02083, 0.0, 0.04167, 0.02083, 0.0, 0.0, 0.04167, 0.08333, 0.0, 0.0625, 0.04167, 0.35417, 0.29167]
ObservationTensor(1) = [0.04167, 0.02083, 0.0, 0.04167, 0.02083, 0.0, 0.0, 0.04167, 0.08333, 0.0, 0.0625, 0.04167, 0.35417, 0.29167]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 3, 4]
StringLegalActions() = ["A", "B", "D", "E"]

# Apply action "D"
action: 3

# State 93
# Player 1 score = 14 [PLAYING]
#   f  e  d  c  b  a
#   2  3  0  4  2  0
#   2  1  0  0  2  1
#   A  B  C  D  E  F
# Player 0 score = 17
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0, 3, 5, 5, 1, 1, 3, 2, 2, 3, 5, 5, 4, 5, 3, 3, 1, 4, 3, 1, 5, 1, 4, 3, 1, 5, 2, 1, 5, 1, 3, 2, 2, 5, 4, 4, 3, 3, 1, 0, 4, 0, 2, 1, 5, 0, 3]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0 3 5 5 1 1 3 2 2 3 5 5 4 5 3 3 1 4 3 1 5 1 4 3 1 5 2 1 5 1 3 2 2 5 4 4 3 3 1 0 4 0 2 1 5 0 3"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
ObservationString(0) = "1 | 17 14 | 2 1 0 0 2 1 0 2 4 0 3 2"
ObservationString(1) = "1 | 17 14 | 2 1 0 0 2 1 0 2 4 0 3 2"
ObservationTensor(0) = [0.04167, 0.02083, 0.0, 0.0, 0.04167, 0.02083, 0.0, 0.04167, 0.08333, 0.0, 0.0625, 0.04167, 0.35417, 0.29167]
ObservationTensor(1) = [0.04167, 0.02083, 0.0, 0.0, 0.04167, 0.02083, 0.0, 0.04167, 0.08333, 0.0, 0.0625, 0.04167, 0.35417, 0.29167]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [1, 2, 4, 5]
StringLegalActions() = ["b", "c", "e", "f"]

# Apply action "e"
action: 4

# State 94
# Player 1 score = 19
#   f  e  d  c  b  a
#   3  0  0  4  2  0
#   0  0  0  0  2  1
#   A  B  C  D  E  F
# Player 0 score = 17 [PLAYING]
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0, 3, 5, 5, 1, 1, 3, 2, 2, 3, 5, 5, 4, 5, 3, 3, 1, 4, 3, 1, 5, 1, 4, 3, 1, 5, 2, 1, 5, 1, 3, 2, 2, 5, 4, 4, 3, 3, 1, 0, 4, 0, 2, 1, 5, 0, 3, 4]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0 3 5 5 1 1 3 2 2 3 5 5 4 5 3 3 1 4 3 1 5 1 4 3 1 5 2 1 5 1 3 2 2 5 4 4 3 3 1 0 4 0 2 1 5 0 3 4"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "0 | 17 19 | 0 0 0 0 2 1 0 2 4 0 0 3"
ObservationString(1) = "0 | 17 19 | 0 0 0 0 2 1 0 2 4 0 0 3"
ObservationTensor(0) = [0.0, 0.0, 0.0, 0.0, 0.04167, 0.02083, 0.0, 0.04167, 0.08333, 0.0, 0.0, 0.0625, 0.35417, 0.39583]
ObservationTensor(1) = [0.0, 0.0, 0.0, 0.0, 0.04167, 0.02083, 0.0, 0.04167, 0.08333, 0.0, 0.0, 0.0625, 0.35417, 0.39583]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [4, 5]
StringLegalActions() = ["E", "F"]

# Apply action "F"
action: 5

# State 95
# Player 1 score = 19 [PLAYING]
#   f  e  d  c  b  a
#   3  0  0  4  2  1
#   0  0  0  0  2  0
#   A  B  C  D  E  F
# Player 0 score = 17
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0, 3, 5, 5, 1, 1, 3, 2, 2, 3, 5, 5, 4, 5, 3, 3, 1, 4, 3, 1, 5, 1, 4, 3, 1, 5, 2, 1, 5, 1, 3, 2, 2, 5, 4, 4, 3, 3, 1, 0, 4, 0, 2, 1, 5, 0, 3, 4, 5]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0 3 5 5 1 1 3 2 2 3 5 5 4 5 3 3 1 4 3 1 5 1 4 3 1 5 2 1 5 1 3 2 2 5 4 4 3 3 1 0 4 0 2 1 5 0 3 4 5"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
ObservationString(0) = "1 | 17 19 | 0 0 0 0 2 0 1 2 4 0 0 3"
ObservationString(1) = "1 | 17 19 | 0 0 0 0 2 0 1 2 4 0 0 3"
ObservationTensor(0) = [0.0, 0.0, 0.0, 0.0, 0.04167, 0.0, 0.02083, 0.04167, 0.08333, 0.0, 0.0, 0.0625, 0.35417, 0.39583]
ObservationTensor(1) = [0.0, 0.0, 0.0, 0.0, 0.04167, 0.0, 0.02083, 0.04167, 0.08333, 0.0, 0.0, 0.0625, 0.35417, 0.39583]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 2, 5]
StringLegalActions() = ["a", "b", "c", "f"]

# Apply action "f"
action: 5

# State 96
# Player 1 score = 19
#   f  e  d  c  b  a
#   0  0  0  4  2  1
#   1  1  1  0  2  0
#   A  B  C  D  E  F
# Player 0 score = 17 [PLAYING]
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0, 3, 5, 5, 1, 1, 3, 2, 2, 3, 5, 5, 4, 5, 3, 3, 1, 4, 3, 1, 5, 1, 4, 3, 1, 5, 2, 1, 5, 1, 3, 2, 2, 5, 4, 4, 3, 3, 1, 0, 4, 0, 2, 1, 5, 0, 3, 4, 5, 5]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0 3 5 5 1 1 3 2 2 3 5 5 4 5 3 3 1 4 3 1 5 1 4 3 1 5 2 1 5 1 3 2 2 5 4 4 3 3 1 0 4 0 2 1 5 0 3 4 5 5"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "0 | 17 19 | 1 1 1 0 2 0 1 2 4 0 0 0"
ObservationString(1) = "0 | 17 19 | 1 1 1 0 2 0 1 2 4 0 0 0"
ObservationTensor(0) = [0.02083, 0.02083, 0.02083, 0.0, 0.04167, 0.0, 0.02083, 0.04167, 0.08333, 0.0, 0.0, 0.0, 0.35417, 0.39583]
ObservationTensor(1) = [0.02083, 0.02083, 0.02083, 0.0, 0.04167, 0.0, 0.02083, 0.04167, 0.08333, 0.0, 0.0, 0.0, 0.35417, 0.39583]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 2, 4]
StringLegalActions() = ["A", "B", "C", "E"]

# Apply action "B"
action: 1

# State 97
# Player 1 score = 19 [PLAYING]
#   f  e  d  c  b  a
#   0  0  0  4  2  1
#   1  0  2  0  2  0
#   A  B  C  D  E  F
# Player 0 score = 17
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0, 3, 5, 5, 1, 1, 3, 2, 2, 3, 5, 5, 4, 5, 3, 3, 1, 4, 3, 1, 5, 1, 4, 3, 1, 5, 2, 1, 5, 1, 3, 2, 2, 5, 4, 4, 3, 3, 1, 0, 4, 0, 2, 1, 5, 0, 3, 4, 5, 5, 1]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0 3 5 5 1 1 3 2 2 3 5 5 4 5 3 3 1 4 3 1 5 1 4 3 1 5 2 1 5 1 3 2 2 5 4 4 3 3 1 0 4 0 2 1 5 0 3 4 5 5 1"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
ObservationString(0) = "1 | 17 19 | 1 0 2 0 2 0 1 2 4 0 0 0"
ObservationString(1) = "1 | 17 19 | 1 0 2 0 2 0 1 2 4 0 0 0"
ObservationTensor(0) = [0.02083, 0.0, 0.04167, 0.0, 0.04167, 0.0, 0.02083, 0.04167, 0.08333, 0.0, 0.0, 0.0, 0.35417, 0.39583]
ObservationTensor(1) = [0.02083, 0.0, 0.04167, 0.0, 0.04167, 0.0, 0.02083, 0.04167, 0.08333, 0.0, 0.0, 0.0, 0.35417, 0.39583]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 2]
StringLegalActions() = ["a", "b", "c"]

# Apply action "b"
action: 1

# State 98
# Player 1 score = 19
#   f  e  d  c  b  a
#   0  0  1  5  0  1
#   1  0  2  0  2  0
#   A  B  C  D  E  F
# Player 0 score = 17 [PLAYING]
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0, 3, 5, 5, 1, 1, 3, 2, 2, 3, 5, 5, 4, 5, 3, 3, 1, 4, 3, 1, 5, 1, 4, 3, 1, 5, 2, 1, 5, 1, 3, 2, 2, 5, 4, 4, 3, 3, 1, 0, 4, 0, 2, 1, 5, 0, 3, 4, 5, 5, 1, 1]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0 3 5 5 1 1 3 2 2 3 5 5 4 5 3 3 1 4 3 1 5 1 4 3 1 5 2 1 5 1 3 2 2 5 4 4 3 3 1 0 4 0 2 1 5 0 3 4 5 5 1 1"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "0 | 17 19 | 1 0 2 0 2 0 1 0 5 1 0 0"
ObservationString(1) = "0 | 17 19 | 1 0 2 0 2 0 1 0 5 1 0 0"
ObservationTensor(0) = [0.02083, 0.0, 0.04167, 0.0, 0.04167, 0.0, 0.02083, 0.0, 0.10417, 0.02083, 0.0, 0.0, 0.35417, 0.39583]
ObservationTensor(1) = [0.02083, 0.0, 0.04167, 0.0, 0.04167, 0.0, 0.02083, 0.0, 0.10417, 0.02083, 0.0, 0.0, 0.35417, 0.39583]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 4]
StringLegalActions() = ["A", "C", "E"]

# Apply action "A"
action: 0

# State 99
# Player 1 score = 19 [PLAYING]
#   f  e  d  c  b  a
#   0  0  1  5  0  1
#   0  1  2  0  2  0
#   A  B  C  D  E  F
# Player 0 score = 17
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0, 3, 5, 5, 1, 1, 3, 2, 2, 3, 5, 5, 4, 5, 3, 3, 1, 4, 3, 1, 5, 1, 4, 3, 1, 5, 2, 1, 5, 1, 3, 2, 2, 5, 4, 4, 3, 3, 1, 0, 4, 0, 2, 1, 5, 0, 3, 4, 5, 5, 1, 1, 0]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0 3 5 5 1 1 3 2 2 3 5 5 4 5 3 3 1 4 3 1 5 1 4 3 1 5 2 1 5 1 3 2 2 5 4 4 3 3 1 0 4 0 2 1 5 0 3 4 5 5 1 1 0"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
ObservationString(0) = "1 | 17 19 | 0 1 2 0 2 0 1 0 5 1 0 0"
ObservationString(1) = "1 | 17 19 | 0 1 2 0 2 0 1 0 5 1 0 0"
ObservationTensor(0) = [0.0, 0.02083, 0.04167, 0.0, 0.04167, 0.0, 0.02083, 0.0, 0.10417, 0.02083, 0.0, 0.0, 0.35417, 0.39583]
ObservationTensor(1) = [0.0, 0.02083, 0.04167, 0.0, 0.04167, 0.0, 0.02083, 0.0, 0.10417, 0.02083, 0.0, 0.0, 0.35417, 0.39583]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3]
StringLegalActions() = ["a", "c", "d"]

# Apply action "a"
action: 0

# State 100
# Player 1 score = 19
#   f  e  d  c  b  a
#   0  0  1  5  1  0
#   0  1  2  0  2  0
#   A  B  C  D  E  F
# Player 0 score = 17 [PLAYING]
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0, 3, 5, 5, 1, 1, 3, 2, 2, 3, 5, 5, 4, 5, 3, 3, 1, 4, 3, 1, 5, 1, 4, 3, 1, 5, 2, 1, 5, 1, 3, 2, 2, 5, 4, 4, 3, 3, 1, 0, 4, 0, 2, 1, 5, 0, 3, 4, 5, 5, 1, 1, 0, 0]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0 3 5 5 1 1 3 2 2 3 5 5 4 5 3 3 1 4 3 1 5 1 4 3 1 5 2 1 5 1 3 2 2 5 4 4 3 3 1 0 4 0 2 1 5 0 3 4 5 5 1 1 0 0"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "0 | 17 19 | 0 1 2 0 2 0 0 1 5 1 0 0"
ObservationString(1) = "0 | 17 19 | 0 1 2 0 2 0 0 1 5 1 0 0"
ObservationTensor(0) = [0.0, 0.02083, 0.04167, 0.0, 0.04167, 0.0, 0.0, 0.02083, 0.10417, 0.02083, 0.0, 0.0, 0.35417, 0.39583]
ObservationTensor(1) = [0.0, 0.02083, 0.04167, 0.0, 0.04167, 0.0, 0.0, 0.02083, 0.10417, 0.02083, 0.0, 0.0, 0.35417, 0.39583]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [1, 2, 4]
StringLegalActions() = ["B", "C", "E"]

# Apply action "E"
action: 4

# State 101
# Player 1 score = 19 [PLAYING]
#   f  e  d  c  b  a
#   0  0  1  5  1  1
#   0  1  2  0  0  1
#   A  B  C  D  E  F
# Player 0 score = 17
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0, 3, 5, 5, 1, 1, 3, 2, 2, 3, 5, 5, 4, 5, 3, 3, 1, 4, 3, 1, 5, 1, 4, 3, 1, 5, 2, 1, 5, 1, 3, 2, 2, 5, 4, 4, 3, 3, 1, 0, 4, 0, 2, 1, 5, 0, 3, 4, 5, 5, 1, 1, 0, 0, 4]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0 3 5 5 1 1 3 2 2 3 5 5 4 5 3 3 1 4 3 1 5 1 4 3 1 5 2 1 5 1 3 2 2 5 4 4 3 3 1 0 4 0 2 1 5 0 3 4 5 5 1 1 0 0 4"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
ObservationString(0) = "1 | 17 19 | 0 1 2 0 0 1 1 1 5 1 0 0"
ObservationString(1) = "1 | 17 19 | 0 1 2 0 0 1 1 1 5 1 0 0"
ObservationTensor(0) = [0.0, 0.02083, 0.04167, 0.0, 0.0, 0.02083, 0.02083, 0.02083, 0.10417, 0.02083, 0.0, 0.0, 0.35417, 0.39583]
ObservationTensor(1) = [0.0, 0.02083, 0.04167, 0.0, 0.0, 0.02083, 0.02083, 0.02083, 0.10417, 0.02083, 0.0, 0.0, 0.35417, 0.39583]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 2, 3]
StringLegalActions() = ["a", "b", "c", "d"]

# Apply action "c"
action: 2

# State 102
# Player 1 score = 21
#   f  e  d  c  b  a
#   1  1  2  0  1  1
#   1  0  2  0  0  1
#   A  B  C  D  E  F
# Player 0 score = 17 [PLAYING]
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0, 3, 5, 5, 1, 1, 3, 2, 2, 3, 5, 5, 4, 5, 3, 3, 1, 4, 3, 1, 5, 1, 4, 3, 1, 5, 2, 1, 5, 1, 3, 2, 2, 5, 4, 4, 3, 3, 1, 0, 4, 0, 2, 1, 5, 0, 3, 4, 5, 5, 1, 1, 0, 0, 4, 2]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0 3 5 5 1 1 3 2 2 3 5 5 4 5 3 3 1 4 3 1 5 1 4 3 1 5 2 1 5 1 3 2 2 5 4 4 3 3 1 0 4 0 2 1 5 0 3 4 5 5 1 1 0 0 4 2"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "0 | 17 21 | 1 0 2 0 0 1 1 1 0 2 1 1"
ObservationString(1) = "0 | 17 21 | 1 0 2 0 0 1 1 1 0 2 1 1"
ObservationTensor(0) = [0.02083, 0.0, 0.04167, 0.0, 0.0, 0.02083, 0.02083, 0.02083, 0.0, 0.04167, 0.02083, 0.02083, 0.35417, 0.4375]
ObservationTensor(1) = [0.02083, 0.0, 0.04167, 0.0, 0.0, 0.02083, 0.02083, 0.02083, 0.0, 0.04167, 0.02083, 0.02083, 0.35417, 0.4375]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 5]
StringLegalActions() = ["A", "C", "F"]

# Apply action "C"
action: 2

# State 103
# Player 1 score = 21 [PLAYING]
#   f  e  d  c  b  a
#   1  1  2  0  1  1
#   1  0  0  1  1  1
#   A  B  C  D  E  F
# Player 0 score = 17
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0, 3, 5, 5, 1, 1, 3, 2, 2, 3, 5, 5, 4, 5, 3, 3, 1, 4, 3, 1, 5, 1, 4, 3, 1, 5, 2, 1, 5, 1, 3, 2, 2, 5, 4, 4, 3, 3, 1, 0, 4, 0, 2, 1, 5, 0, 3, 4, 5, 5, 1, 1, 0, 0, 4, 2, 2]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0 3 5 5 1 1 3 2 2 3 5 5 4 5 3 3 1 4 3 1 5 1 4 3 1 5 2 1 5 1 3 2 2 5 4 4 3 3 1 0 4 0 2 1 5 0 3 4 5 5 1 1 0 0 4 2 2"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
ObservationString(0) = "1 | 17 21 | 1 0 0 1 1 1 1 1 0 2 1 1"
ObservationString(1) = "1 | 17 21 | 1 0 0 1 1 1 1 1 0 2 1 1"
ObservationTensor(0) = [0.02083, 0.0, 0.0, 0.02083, 0.02083, 0.02083, 0.02083, 0.02083, 0.0, 0.04167, 0.02083, 0.02083, 0.35417, 0.4375]
ObservationTensor(1) = [0.02083, 0.0, 0.0, 0.02083, 0.02083, 0.02083, 0.02083, 0.02083, 0.0, 0.04167, 0.02083, 0.02083, 0.35417, 0.4375]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 3, 4, 5]
StringLegalActions() = ["a", "b", "d", "e", "f"]

# Apply action "e"
action: 4

# State 104
# Player 1 score = 21
#   f  e  d  c  b  a
#   2  0  2  0  1  1
#   1  0  0  1  1  1
#   A  B  C  D  E  F
# Player 0 score = 17 [PLAYING]
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0, 3, 5, 5, 1, 1, 3, 2, 2, 3, 5, 5, 4, 5, 3, 3, 1, 4, 3, 1, 5, 1, 4, 3, 1, 5, 2, 1, 5, 1, 3, 2, 2, 5, 4, 4, 3, 3, 1, 0, 4, 0, 2, 1, 5, 0, 3, 4, 5, 5, 1, 1, 0, 0, 4, 2, 2, 4]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0 3 5 5 1 1 3 2 2 3 5 5 4 5 3 3 1 4 3 1 5 1 4 3 1 5 2 1 5 1 3 2 2 5 4 4 3 3 1 0 4 0 2 1 5 0 3 4 5 5 1 1 0 0 4 2 2 4"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "0 | 17 21 | 1 0 0 1 1 1 1 1 0 2 0 2"
ObservationString(1) = "0 | 17 21 | 1 0 0 1 1 1 1 1 0 2 0 2"
ObservationTensor(0) = [0.02083, 0.0, 0.0, 0.02083, 0.02083, 0.02083, 0.02083, 0.02083, 0.0, 0.04167, 0.0, 0.04167, 0.35417, 0.4375]
ObservationTensor(1) = [0.02083, 0.0, 0.0, 0.02083, 0.02083, 0.02083, 0.02083, 0.02083, 0.0, 0.04167, 0.0, 0.04167, 0.35417, 0.4375]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 3, 4, 5]
StringLegalActions() = ["A", "D", "E", "F"]

# Apply action "A"
action: 0

# State 105
# Player 1 score = 21 [PLAYING]
#   f  e  d  c  b  a
#   2  0  2  0  1  1
#   0  1  0  1  1  1
#   A  B  C  D  E  F
# Player 0 score = 17
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0, 3, 5, 5, 1, 1, 3, 2, 2, 3, 5, 5, 4, 5, 3, 3, 1, 4, 3, 1, 5, 1, 4, 3, 1, 5, 2, 1, 5, 1, 3, 2, 2, 5, 4, 4, 3, 3, 1, 0, 4, 0, 2, 1, 5, 0, 3, 4, 5, 5, 1, 1, 0, 0, 4, 2, 2, 4, 0]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0 3 5 5 1 1 3 2 2 3 5 5 4 5 3 3 1 4 3 1 5 1 4 3 1 5 2 1 5 1 3 2 2 5 4 4 3 3 1 0 4 0 2 1 5 0 3 4 5 5 1 1 0 0 4 2 2 4 0"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
ObservationString(0) = "1 | 17 21 | 0 1 0 1 1 1 1 1 0 2 0 2"
ObservationString(1) = "1 | 17 21 | 0 1 0 1 1 1 1 1 0 2 0 2"
ObservationTensor(0) = [0.0, 0.02083, 0.0, 0.02083, 0.02083, 0.02083, 0.02083, 0.02083, 0.0, 0.04167, 0.0, 0.04167, 0.35417, 0.4375]
ObservationTensor(1) = [0.0, 0.02083, 0.0, 0.02083, 0.02083, 0.02083, 0.02083, 0.02083, 0.0, 0.04167, 0.0, 0.04167, 0.35417, 0.4375]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 3, 5]
StringLegalActions() = ["a", "b", "d", "f"]

# Apply action "f"
action: 5

# State 106
# Player 1 score = 23
#   f  e  d  c  b  a
#   0  0  2  0  1  1
#   1  0  0  1  1  1
#   A  B  C  D  E  F
# Player 0 score = 17 [PLAYING]
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0, 3, 5, 5, 1, 1, 3, 2, 2, 3, 5, 5, 4, 5, 3, 3, 1, 4, 3, 1, 5, 1, 4, 3, 1, 5, 2, 1, 5, 1, 3, 2, 2, 5, 4, 4, 3, 3, 1, 0, 4, 0, 2, 1, 5, 0, 3, 4, 5, 5, 1, 1, 0, 0, 4, 2, 2, 4, 0, 5]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0 3 5 5 1 1 3 2 2 3 5 5 4 5 3 3 1 4 3 1 5 1 4 3 1 5 2 1 5 1 3 2 2 5 4 4 3 3 1 0 4 0 2 1 5 0 3 4 5 5 1 1 0 0 4 2 2 4 0 5"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "0 | 17 23 | 1 0 0 1 1 1 1 1 0 2 0 0"
ObservationString(1) = "0 | 17 23 | 1 0 0 1 1 1 1 1 0 2 0 0"
ObservationTensor(0) = [0.02083, 0.0, 0.0, 0.02083, 0.02083, 0.02083, 0.02083, 0.02083, 0.0, 0.04167, 0.0, 0.0, 0.35417, 0.47917]
ObservationTensor(1) = [0.02083, 0.0, 0.0, 0.02083, 0.02083, 0.02083, 0.02083, 0.02083, 0.0, 0.04167, 0.0, 0.0, 0.35417, 0.47917]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 3, 4, 5]
StringLegalActions() = ["A", "D", "E", "F"]

# Apply action "D"
action: 3

# State 107
# Player 1 score = 23 [PLAYING]
#   f  e  d  c  b  a
#   0  0  2  0  1  1
#   1  0  0  0  2  1
#   A  B  C  D  E  F
# Player 0 score = 17
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0, 3, 5, 5, 1, 1, 3, 2, 2, 3, 5, 5, 4, 5, 3, 3, 1, 4, 3, 1, 5, 1, 4, 3, 1, 5, 2, 1, 5, 1, 3, 2, 2, 5, 4, 4, 3, 3, 1, 0, 4, 0, 2, 1, 5, 0, 3, 4, 5, 5, 1, 1, 0, 0, 4, 2, 2, 4, 0, 5, 3]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0 3 5 5 1 1 3 2 2 3 5 5 4 5 3 3 1 4 3 1 5 1 4 3 1 5 2 1 5 1 3 2 2 5 4 4 3 3 1 0 4 0 2 1 5 0 3 4 5 5 1 1 0 0 4 2 2 4 0 5 3"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
ObservationString(0) = "1 | 17 23 | 1 0 0 0 2 1 1 1 0 2 0 0"
ObservationString(1) = "1 | 17 23 | 1 0 0 0 2 1 1 1 0 2 0 0"
ObservationTensor(0) = [0.02083, 0.0, 0.0, 0.0, 0.04167, 0.02083, 0.02083, 0.02083, 0.0, 0.04167, 0.0, 0.0, 0.35417, 0.47917]
ObservationTensor(1) = [0.02083, 0.0, 0.0, 0.0, 0.04167, 0.02083, 0.02083, 0.02083, 0.0, 0.04167, 0.0, 0.0, 0.35417, 0.47917]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 3]
StringLegalActions() = ["a", "b", "d"]

# Apply action "d"
action: 3

# State 108
# Player 1 score = 23
#   f  e  d  c  b  a
#   1  1  0  0  1  1
#   1  0  0  0  2  1
#   A  B  C  D  E  F
# Player 0 score = 17 [PLAYING]
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0, 3, 5, 5, 1, 1, 3, 2, 2, 3, 5, 5, 4, 5, 3, 3, 1, 4, 3, 1, 5, 1, 4, 3, 1, 5, 2, 1, 5, 1, 3, 2, 2, 5, 4, 4, 3, 3, 1, 0, 4, 0, 2, 1, 5, 0, 3, 4, 5, 5, 1, 1, 0, 0, 4, 2, 2, 4, 0, 5, 3, 3]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0 3 5 5 1 1 3 2 2 3 5 5 4 5 3 3 1 4 3 1 5 1 4 3 1 5 2 1 5 1 3 2 2 5 4 4 3 3 1 0 4 0 2 1 5 0 3 4 5 5 1 1 0 0 4 2 2 4 0 5 3 3"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "0 | 17 23 | 1 0 0 0 2 1 1 1 0 0 1 1"
ObservationString(1) = "0 | 17 23 | 1 0 0 0 2 1 1 1 0 0 1 1"
ObservationTensor(0) = [0.02083, 0.0, 0.0, 0.0, 0.04167, 0.02083, 0.02083, 0.02083, 0.0, 0.0, 0.02083, 0.02083, 0.35417, 0.47917]
ObservationTensor(1) = [0.02083, 0.0, 0.0, 0.0, 0.04167, 0.02083, 0.02083, 0.02083, 0.0, 0.0, 0.02083, 0.02083, 0.35417, 0.47917]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 4, 5]
StringLegalActions() = ["A", "E", "F"]

# Apply action "F"
action: 5

# State 109
# Player 1 score = 23 [PLAYING]
#   f  e  d  c  b  a
#   1  1  0  0  1  0
#   1  0  0  0  2  0
#   A  B  C  D  E  F
# Player 0 score = 19
IsTerminal() = False
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0, 3, 5, 5, 1, 1, 3, 2, 2, 3, 5, 5, 4, 5, 3, 3, 1, 4, 3, 1, 5, 1, 4, 3, 1, 5, 2, 1, 5, 1, 3, 2, 2, 5, 4, 4, 3, 3, 1, 0, 4, 0, 2, 1, 5, 0, 3, 4, 5, 5, 1, 1, 0, 0, 4, 2, 2, 4, 0, 5, 3, 3, 5]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0 3 5 5 1 1 3 2 2 3 5 5 4 5 3 3 1 4 3 1 5 1 4 3 1 5 2 1 5 1 3 2 2 5 4 4 3 3 1 0 4 0 2 1 5 0 3 4 5 5 1 1 0 0 4 2 2 4 0 5 3 3 5"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
ObservationString(0) = "1 | 19 23 | 1 0 0 0 2 0 0 1 0 0 1 1"
ObservationString(1) = "1 | 19 23 | 1 0 0 0 2 0 0 1 0 0 1 1"
ObservationTensor(0) = [0.02083, 0.0, 0.0, 0.0, 0.04167, 0.0, 0.0, 0.02083, 0.0, 0.0, 0.02083, 0.02083, 0.39583, 0.47917]
ObservationTensor(1) = [0.02083, 0.0, 0.0, 0.0, 0.04167, 0.0, 0.0, 0.02083, 0.0, 0.0, 0.02083, 0.02083, 0.39583, 0.47917]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [1, 4, 5]
StringLegalActions() = ["b", "e", "f"]

# Apply action "f"
action: 5

# State 110
# [FINISHED]
# Player 1 score = 27
#   f  e  d  c  b  a
#   0  0  0  0  0  0
#   0  0  0  0  0  0
#   A  B  C  D  E  F
# Player 0 score = 21
IsTerminal() = True
History() = [2, 5, 2, 1, 1, 2, 2, 3, 5, 4, 2, 3, 3, 4, 0, 1, 3, 0, 2, 2, 4, 2, 2, 4, 3, 3, 0, 4, 5, 1, 0, 4, 4, 0, 5, 1, 1, 4, 0, 3, 3, 4, 1, 5, 3, 2, 0, 3, 5, 5, 1, 1, 3, 2, 2, 3, 5, 5, 4, 5, 3, 3, 1, 4, 3, 1, 5, 1, 4, 3, 1, 5, 2, 1, 5, 1, 3, 2, 2, 5, 4, 4, 3, 3, 1, 0, 4, 0, 2, 1, 5, 0, 3, 4, 5, 5, 1, 1, 0, 0, 4, 2, 2, 4, 0, 5, 3, 3, 5, 5]
HistoryString() = "2 5 2 1 1 2 2 3 5 4 2 3 3 4 0 1 3 0 2 2 4 2 2 4 3 3 0 4 5 1 0 4 4 0 5 1 1 4 0 3 3 4 1 5 3 2 0 3 5 5 1 1 3 2 2 3 5 5 4 5 3 3 1 4 3 1 5 1 4 3 1 5 2 1 5 1 3 2 2 5 4 4 3 3 1 0 4 0 2 1 5 0 3 4 5 5 1 1 0 0 4 2 2 4 0 5 3 3 5 5"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = -4
ObservationString(0) = "0 | 21 27 | 0 0 0 0 0 0 0 0 0 0 0 0"
ObservationString(1) = "0 | 21 27 | 0 0 0 0 0 0 0 0 0 0 0 0"
ObservationTensor(0) = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4375, 0.5625]
ObservationTensor(1) = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4375, 0.5625]
Rewards() = [-1.0, 1.0]
Returns() = [-1.0, 1.0]
