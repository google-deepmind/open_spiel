game: pig(players=4,horizon=10,winscore=8)

GameType.chance_mode = ChanceMode.EXPLICIT_STOCHASTIC
GameType.dynamics = Dynamics.SEQUENTIAL
GameType.information = Information.PERFECT_INFORMATION
GameType.long_name = "Pig"
GameType.max_num_players = 10
GameType.min_num_players = 2
GameType.parameter_specification = ["diceoutcomes", "horizon", "piglet", "players", "winscore"]
GameType.provides_information_state_string = False
GameType.provides_information_state_tensor = False
GameType.provides_observation_string = True
GameType.provides_observation_tensor = True
GameType.provides_factored_observation_string = False
GameType.reward_model = RewardModel.TERMINAL
GameType.short_name = "pig"
GameType.utility = Utility.ZERO_SUM

NumDistinctActions() = 2
PolicyTensorShape() = [2]
MaxChanceOutcomes() = 6
GetParameters() = {diceoutcomes=6,horizon=10,piglet=False,players=4,winscore=8}
NumPlayers() = 4
MinUtility() = -1.0
MaxUtility() = 1.0
UtilitySum() = 0.0
ObservationTensorShape() = [5, 9]
ObservationTensorLayout() = TensorLayout.CHW
ObservationTensorSize() = 45
MaxGameLength() = 10
ToString() = "pig(horizon=10,players=4,winscore=8)"

# State 0
# Scores: 0 0 0 0, Turn total: 0
# Current player: 0
IsTerminal() = False
History() = []
HistoryString() = ""
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "Scores: 0 0 0 0, Turn total: 0\nCurrent player: 0\n"
ObservationString(1) = "Scores: 0 0 0 0, Turn total: 0\nCurrent player: 0\n"
ObservationString(2) = "Scores: 0 0 0 0, Turn total: 0\nCurrent player: 0\n"
ObservationString(3) = "Scores: 0 0 0 0, Turn total: 0\nCurrent player: 0\n"
ObservationTensor(0): ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
ObservationTensor(1): ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
ObservationTensor(2): ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
ObservationTensor(3): ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0, 0.0, 0.0]
Returns() = [0.0, 0.0, 0.0, 0.0]
LegalActions() = [0, 1]
StringLegalActions() = ["roll", "stop"]

# Apply action "roll"
action: 0

# State 1
# Scores: 0 0 0 0, Turn total: 0
# Current player: 0 (rolling)
IsTerminal() = False
History() = [0]
HistoryString() = "0"
IsChanceNode() = True
IsSimultaneousNode() = False
CurrentPlayer() = -1
ObservationString(0) = "Scores: 0 0 0 0, Turn total: 0\nCurrent player: 0 (rolling)\n"
ObservationString(1) = "Scores: 0 0 0 0, Turn total: 0\nCurrent player: 0 (rolling)\n"
ObservationString(2) = "Scores: 0 0 0 0, Turn total: 0\nCurrent player: 0 (rolling)\n"
ObservationString(3) = "Scores: 0 0 0 0, Turn total: 0\nCurrent player: 0 (rolling)\n"
ObservationTensor(0): ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
ObservationTensor(1): ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
ObservationTensor(2): ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
ObservationTensor(3): ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
ChanceOutcomes() = [(0, 0.16666666666666666), (1, 0.16666666666666666), (2, 0.16666666666666666), (3, 0.16666666666666666), (4, 0.16666666666666666), (5, 0.16666666666666666)]
LegalActions() = [0, 1, 2, 3, 4, 5]
StringLegalActions() = ["Roll 1", "Roll 2", "Roll 3", "Roll 4", "Roll 5", "Roll 6"]

# Apply action "Roll 2"
action: 1

# State 2
# Scores: 0 0 0 0, Turn total: 2
# Current player: 0
IsTerminal() = False
History() = [0, 1]
HistoryString() = "0, 1"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "Scores: 0 0 0 0, Turn total: 2\nCurrent player: 0\n"
ObservationString(1) = "Scores: 0 0 0 0, Turn total: 2\nCurrent player: 0\n"
ObservationString(2) = "Scores: 0 0 0 0, Turn total: 2\nCurrent player: 0\n"
ObservationString(3) = "Scores: 0 0 0 0, Turn total: 2\nCurrent player: 0\n"
ObservationTensor(0): ◯◯◉◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
ObservationTensor(1): ◯◯◉◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
ObservationTensor(2): ◯◯◉◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
ObservationTensor(3): ◯◯◉◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0, 0.0, 0.0]
Returns() = [0.0, 0.0, 0.0, 0.0]
LegalActions() = [0, 1]
StringLegalActions() = ["roll", "stop"]

# Apply action "roll"
action: 0

# State 3
# Scores: 0 0 0 0, Turn total: 2
# Current player: 0 (rolling)
IsTerminal() = False
History() = [0, 1, 0]
HistoryString() = "0, 1, 0"
IsChanceNode() = True
IsSimultaneousNode() = False
CurrentPlayer() = -1
ObservationString(0) = "Scores: 0 0 0 0, Turn total: 2\nCurrent player: 0 (rolling)\n"
ObservationString(1) = "Scores: 0 0 0 0, Turn total: 2\nCurrent player: 0 (rolling)\n"
ObservationString(2) = "Scores: 0 0 0 0, Turn total: 2\nCurrent player: 0 (rolling)\n"
ObservationString(3) = "Scores: 0 0 0 0, Turn total: 2\nCurrent player: 0 (rolling)\n"
ObservationTensor(0): ◯◯◉◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
ObservationTensor(1): ◯◯◉◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
ObservationTensor(2): ◯◯◉◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
ObservationTensor(3): ◯◯◉◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
ChanceOutcomes() = [(0, 0.16666666666666666), (1, 0.16666666666666666), (2, 0.16666666666666666), (3, 0.16666666666666666), (4, 0.16666666666666666), (5, 0.16666666666666666)]
LegalActions() = [0, 1, 2, 3, 4, 5]
StringLegalActions() = ["Roll 1", "Roll 2", "Roll 3", "Roll 4", "Roll 5", "Roll 6"]

# Apply action "Roll 2"
action: 1

# State 4
# Scores: 0 0 0 0, Turn total: 4
# Current player: 0
IsTerminal() = False
History() = [0, 1, 0, 1]
HistoryString() = "0, 1, 0, 1"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "Scores: 0 0 0 0, Turn total: 4\nCurrent player: 0\n"
ObservationString(1) = "Scores: 0 0 0 0, Turn total: 4\nCurrent player: 0\n"
ObservationString(2) = "Scores: 0 0 0 0, Turn total: 4\nCurrent player: 0\n"
ObservationString(3) = "Scores: 0 0 0 0, Turn total: 4\nCurrent player: 0\n"
ObservationTensor(0): ◯◯◯◯◉◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
ObservationTensor(1): ◯◯◯◯◉◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
ObservationTensor(2): ◯◯◯◯◉◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
ObservationTensor(3): ◯◯◯◯◉◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0, 0.0, 0.0]
Returns() = [0.0, 0.0, 0.0, 0.0]
LegalActions() = [0, 1]
StringLegalActions() = ["roll", "stop"]

# Apply action "stop"
action: 1

# State 5
# Scores: 4 0 0 0, Turn total: 0
# Current player: 1
IsTerminal() = False
History() = [0, 1, 0, 1, 1]
HistoryString() = "0, 1, 0, 1, 1"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
ObservationString(0) = "Scores: 4 0 0 0, Turn total: 0\nCurrent player: 1\n"
ObservationString(1) = "Scores: 4 0 0 0, Turn total: 0\nCurrent player: 1\n"
ObservationString(2) = "Scores: 4 0 0 0, Turn total: 0\nCurrent player: 1\n"
ObservationString(3) = "Scores: 4 0 0 0, Turn total: 0\nCurrent player: 1\n"
ObservationTensor(0): ◉◯◯◯◯◯◯◯◯
                      ◯◯◯◯◉◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
ObservationTensor(1): ◉◯◯◯◯◯◯◯◯
                      ◯◯◯◯◉◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
ObservationTensor(2): ◉◯◯◯◯◯◯◯◯
                      ◯◯◯◯◉◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
ObservationTensor(3): ◉◯◯◯◯◯◯◯◯
                      ◯◯◯◯◉◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0, 0.0, 0.0]
Returns() = [0.0, 0.0, 0.0, 0.0]
LegalActions() = [0, 1]
StringLegalActions() = ["roll", "stop"]

# Apply action "stop"
action: 1

# State 6
# Scores: 4 0 0 0, Turn total: 0
# Current player: 2
IsTerminal() = False
History() = [0, 1, 0, 1, 1, 1]
HistoryString() = "0, 1, 0, 1, 1, 1"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 2
ObservationString(0) = "Scores: 4 0 0 0, Turn total: 0\nCurrent player: 2\n"
ObservationString(1) = "Scores: 4 0 0 0, Turn total: 0\nCurrent player: 2\n"
ObservationString(2) = "Scores: 4 0 0 0, Turn total: 0\nCurrent player: 2\n"
ObservationString(3) = "Scores: 4 0 0 0, Turn total: 0\nCurrent player: 2\n"
ObservationTensor(0): ◉◯◯◯◯◯◯◯◯
                      ◯◯◯◯◉◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
ObservationTensor(1): ◉◯◯◯◯◯◯◯◯
                      ◯◯◯◯◉◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
ObservationTensor(2): ◉◯◯◯◯◯◯◯◯
                      ◯◯◯◯◉◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
ObservationTensor(3): ◉◯◯◯◯◯◯◯◯
                      ◯◯◯◯◉◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0, 0.0, 0.0]
Returns() = [0.0, 0.0, 0.0, 0.0]
LegalActions() = [0, 1]
StringLegalActions() = ["roll", "stop"]

# Apply action "roll"
action: 0

# State 7
# Apply action "Roll 1"
action: 0

# State 8
# Scores: 4 0 0 0, Turn total: 0
# Current player: 3
IsTerminal() = False
History() = [0, 1, 0, 1, 1, 1, 0, 0]
HistoryString() = "0, 1, 0, 1, 1, 1, 0, 0"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 3
ObservationString(0) = "Scores: 4 0 0 0, Turn total: 0\nCurrent player: 3\n"
ObservationString(1) = "Scores: 4 0 0 0, Turn total: 0\nCurrent player: 3\n"
ObservationString(2) = "Scores: 4 0 0 0, Turn total: 0\nCurrent player: 3\n"
ObservationString(3) = "Scores: 4 0 0 0, Turn total: 0\nCurrent player: 3\n"
ObservationTensor(0): ◉◯◯◯◯◯◯◯◯
                      ◯◯◯◯◉◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
ObservationTensor(1): ◉◯◯◯◯◯◯◯◯
                      ◯◯◯◯◉◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
ObservationTensor(2): ◉◯◯◯◯◯◯◯◯
                      ◯◯◯◯◉◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
ObservationTensor(3): ◉◯◯◯◯◯◯◯◯
                      ◯◯◯◯◉◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0, 0.0, 0.0]
Returns() = [0.0, 0.0, 0.0, 0.0]
LegalActions() = [0, 1]
StringLegalActions() = ["roll", "stop"]

# Apply action "stop"
action: 1

# State 9
# Apply action "roll"
action: 0

# State 10
# Apply action "Roll 1"
action: 0

# State 11
# Scores: 4 0 0 0, Turn total: 0
# Current player: 1
IsTerminal() = False
History() = [0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0]
HistoryString() = "0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
ObservationString(0) = "Scores: 4 0 0 0, Turn total: 0\nCurrent player: 1\n"
ObservationString(1) = "Scores: 4 0 0 0, Turn total: 0\nCurrent player: 1\n"
ObservationString(2) = "Scores: 4 0 0 0, Turn total: 0\nCurrent player: 1\n"
ObservationString(3) = "Scores: 4 0 0 0, Turn total: 0\nCurrent player: 1\n"
ObservationTensor(0): ◉◯◯◯◯◯◯◯◯
                      ◯◯◯◯◉◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
ObservationTensor(1): ◉◯◯◯◯◯◯◯◯
                      ◯◯◯◯◉◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
ObservationTensor(2): ◉◯◯◯◯◯◯◯◯
                      ◯◯◯◯◉◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
ObservationTensor(3): ◉◯◯◯◯◯◯◯◯
                      ◯◯◯◯◉◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0, 0.0, 0.0]
Returns() = [0.0, 0.0, 0.0, 0.0]
LegalActions() = [0, 1]
StringLegalActions() = ["roll", "stop"]

# Apply action "roll"
action: 0

# State 12
# Apply action "Roll 4"
action: 3

# State 13
# Scores: 4 0 0 0, Turn total: 4
# Current player: 1
IsTerminal() = False
History() = [0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 3]
HistoryString() = "0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 3"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
ObservationString(0) = "Scores: 4 0 0 0, Turn total: 4\nCurrent player: 1\n"
ObservationString(1) = "Scores: 4 0 0 0, Turn total: 4\nCurrent player: 1\n"
ObservationString(2) = "Scores: 4 0 0 0, Turn total: 4\nCurrent player: 1\n"
ObservationString(3) = "Scores: 4 0 0 0, Turn total: 4\nCurrent player: 1\n"
ObservationTensor(0): ◯◯◯◯◉◯◯◯◯
                      ◯◯◯◯◉◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
ObservationTensor(1): ◯◯◯◯◉◯◯◯◯
                      ◯◯◯◯◉◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
ObservationTensor(2): ◯◯◯◯◉◯◯◯◯
                      ◯◯◯◯◉◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
ObservationTensor(3): ◯◯◯◯◉◯◯◯◯
                      ◯◯◯◯◉◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0, 0.0, 0.0]
Returns() = [0.0, 0.0, 0.0, 0.0]
LegalActions() = [0, 1]
StringLegalActions() = ["roll", "stop"]

# Apply action "roll"
action: 0

# State 14
# Apply action "Roll 4"
action: 3

# State 15
# Apply action "stop"
action: 1

# State 16
# Scores: 4 8 0 0, Turn total: 0
# Current player: 2
IsTerminal() = True
History() = [0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 3, 0, 3, 1]
HistoryString() = "0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 3, 0, 3, 1"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = -4
ObservationString(0) = "Scores: 4 8 0 0, Turn total: 0\nCurrent player: 2\n"
ObservationString(1) = "Scores: 4 8 0 0, Turn total: 0\nCurrent player: 2\n"
ObservationString(2) = "Scores: 4 8 0 0, Turn total: 0\nCurrent player: 2\n"
ObservationString(3) = "Scores: 4 8 0 0, Turn total: 0\nCurrent player: 2\n"
ObservationTensor(0): ◉◯◯◯◯◯◯◯◯
                      ◯◯◯◯◉◯◯◯◯
                      ◯◯◯◯◯◯◯◯◉
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
ObservationTensor(1): ◉◯◯◯◯◯◯◯◯
                      ◯◯◯◯◉◯◯◯◯
                      ◯◯◯◯◯◯◯◯◉
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
ObservationTensor(2): ◉◯◯◯◯◯◯◯◯
                      ◯◯◯◯◉◯◯◯◯
                      ◯◯◯◯◯◯◯◯◉
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
ObservationTensor(3): ◉◯◯◯◯◯◯◯◯
                      ◯◯◯◯◉◯◯◯◯
                      ◯◯◯◯◯◯◯◯◉
                      ◉◯◯◯◯◯◯◯◯
                      ◉◯◯◯◯◯◯◯◯
Rewards() = [-0.3333333333333333, 1.0, -0.3333333333333333, -0.3333333333333333]
Returns() = [-0.3333333333333333, 1.0, -0.3333333333333333, -0.3333333333333333]
