game: universal_poker

GameType.chance_mode = ChanceMode.EXPLICIT_STOCHASTIC
GameType.dynamics = Dynamics.SEQUENTIAL
GameType.information = Information.IMPERFECT_INFORMATION
GameType.long_name = "Universal Poker"
GameType.max_num_players = 10
GameType.min_num_players = 2
GameType.parameter_specification = ["betting", "bettingAbstraction", "blind", "boardCards", "firstPlayer", "gamedef", "handReaches", "maxRaises", "numBoardCards", "numHoleCards", "numPlayers", "numRanks", "numRounds", "numSuits", "potSize", "raiseSize", "stack"]
GameType.provides_information_state_string = True
GameType.provides_information_state_tensor = True
GameType.provides_observation_string = True
GameType.provides_observation_tensor = True
GameType.provides_factored_observation_string = False
GameType.reward_model = RewardModel.TERMINAL
GameType.short_name = "universal_poker"
GameType.utility = Utility.ZERO_SUM

NumDistinctActions() = 4
PolicyTensorShape() = [4]
MaxChanceOutcomes() = 24
GetParameters() = {betting=nolimit,bettingAbstraction=fcpa,blind=100 100,boardCards=,firstPlayer=1 1,handReaches=,maxRaises=,numBoardCards=0 1,numHoleCards=1,numPlayers=2,numRanks=6,numRounds=2,numSuits=4,potSize=0,stack=1200 1200}
NumPlayers() = 2
MinUtility() = -1200.0
MaxUtility() = 1200.0
UtilitySum() = 0.0
InformationStateTensorShape() = [72]
InformationStateTensorLayout() = TensorLayout.CHW
InformationStateTensorSize() = 72
ObservationTensorShape() = [52]
ObservationTensorLayout() = TensorLayout.CHW
ObservationTensorSize() = 52
MaxGameLength() = 11
ToString() = "universal_poker()"

# State 0
# BettingAbstration: FCPA
# P0 Cards:
# P1 Cards:
# BoardCards
# PossibleCardsToDeal 7s7h7d7c6s6h6d6c5s5h5d5c4s4h4d4c3s3h3d3c2s2h2d2c
# Node type?: Chance node
# PossibleActions (1): [ ACTION_DEAL ]
# Round: 0
# ACPC State: STATE:0::2c|2c
# Spent: [P0: 100  P1: 100  ]
#
# Action Sequence:
IsTerminal() = False
History() = []
HistoryString() = ""
IsChanceNode() = True
IsSimultaneousNode() = False
CurrentPlayer() = -1
InformationStateString(0) = "[Round 0][Player: -1][Pot: 200][Money: 1100 1100][Private: ][Public: ][Sequences: ]"
InformationStateString(1) = "[Round 0][Player: -1][Pot: 200][Money: 1100 1100][Private: ][Public: ][Sequences: ]"
InformationStateTensor(0): ◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
InformationStateTensor(1): ◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
ObservationString(0) = "[Round 0][Player: -1][Pot: 200][Money: 1100 1100[Private: ][Ante: 100 100]"
ObservationString(1) = "[Round 0][Player: -1][Pot: 200][Money: 1100 1100[Private: ][Ante: 100 100]"
ObservationTensor(0) = [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 100.0]
ObservationTensor(1) = [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 100.0]
ChanceOutcomes() = [(0,0.0416667), (1,0.0416667), (2,0.0416667), (3,0.0416667), (4,0.0416667), (5,0.0416667), (6,0.0416667), (7,0.0416667), (8,0.0416667), (9,0.0416667), (10,0.0416667), (11,0.0416667), (12,0.0416667), (13,0.0416667), (14,0.0416667), (15,0.0416667), (16,0.0416667), (17,0.0416667), (18,0.0416667), (19,0.0416667), (20,0.0416667), (21,0.0416667), (22,0.0416667), (23,0.0416667)]
LegalActions() = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]
StringLegalActions() = ["player=-1 move=Deal(0)", "player=-1 move=Deal(1)", "player=-1 move=Deal(2)", "player=-1 move=Deal(3)", "player=-1 move=Deal(4)", "player=-1 move=Deal(5)", "player=-1 move=Deal(6)", "player=-1 move=Deal(7)", "player=-1 move=Deal(8)", "player=-1 move=Deal(9)", "player=-1 move=Deal(10)", "player=-1 move=Deal(11)", "player=-1 move=Deal(12)", "player=-1 move=Deal(13)", "player=-1 move=Deal(14)", "player=-1 move=Deal(15)", "player=-1 move=Deal(16)", "player=-1 move=Deal(17)", "player=-1 move=Deal(18)", "player=-1 move=Deal(19)", "player=-1 move=Deal(20)", "player=-1 move=Deal(21)", "player=-1 move=Deal(22)", "player=-1 move=Deal(23)"]

# Apply action "player=-1 move=Deal(12)"
action: 12

# State 1
# BettingAbstration: FCPA
# P0 Cards: 5c
# P1 Cards:
# BoardCards
# PossibleCardsToDeal 7s7h7d7c6s6h6d6c5s5h5d4s4h4d4c3s3h3d3c2s2h2d2c
# Node type?: Chance node
# PossibleActions (1): [ ACTION_DEAL ]
# Round: 0
# ACPC State: STATE:0::5c|2c
# Spent: [P0: 100  P1: 100  ]
#
# Action Sequence: d
IsTerminal() = False
History() = [12]
HistoryString() = "12"
IsChanceNode() = True
IsSimultaneousNode() = False
CurrentPlayer() = -1
InformationStateString(0) = "[Round 0][Player: -1][Pot: 200][Money: 1100 1100][Private: 5c][Public: ][Sequences: ]"
InformationStateString(1) = "[Round 0][Player: -1][Pot: 200][Money: 1100 1100][Private: ][Public: ][Sequences: ]"
InformationStateTensor(0): ◉◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
InformationStateTensor(1): ◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
ObservationString(0) = "[Round 0][Player: -1][Pot: 200][Money: 1100 1100[Private: 5c][Ante: 100 100]"
ObservationString(1) = "[Round 0][Player: -1][Pot: 200][Money: 1100 1100[Private: ][Ante: 100 100]"
ObservationTensor(0) = [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 100.0]
ObservationTensor(1) = [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 100.0]
ChanceOutcomes() = [(0,0.0434783), (1,0.0434783), (2,0.0434783), (3,0.0434783), (4,0.0434783), (5,0.0434783), (6,0.0434783), (7,0.0434783), (8,0.0434783), (9,0.0434783), (10,0.0434783), (11,0.0434783), (13,0.0434783), (14,0.0434783), (15,0.0434783), (16,0.0434783), (17,0.0434783), (18,0.0434783), (19,0.0434783), (20,0.0434783), (21,0.0434783), (22,0.0434783), (23,0.0434783)]
LegalActions() = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]
StringLegalActions() = ["player=-1 move=Deal(0)", "player=-1 move=Deal(1)", "player=-1 move=Deal(2)", "player=-1 move=Deal(3)", "player=-1 move=Deal(4)", "player=-1 move=Deal(5)", "player=-1 move=Deal(6)", "player=-1 move=Deal(7)", "player=-1 move=Deal(8)", "player=-1 move=Deal(9)", "player=-1 move=Deal(10)", "player=-1 move=Deal(11)", "player=-1 move=Deal(13)", "player=-1 move=Deal(14)", "player=-1 move=Deal(15)", "player=-1 move=Deal(16)", "player=-1 move=Deal(17)", "player=-1 move=Deal(18)", "player=-1 move=Deal(19)", "player=-1 move=Deal(20)", "player=-1 move=Deal(21)", "player=-1 move=Deal(22)", "player=-1 move=Deal(23)"]

# Apply action "player=-1 move=Deal(13)"
action: 13

# State 2
# BettingAbstration: FCPA
# P0 Cards: 5c
# P1 Cards: 5d
# BoardCards
# Node type?: Player node for player 0
# PossibleActions (3): [ ACTION_CHECK_CALL  ACTION_BET  ACTION_ALL_IN ]
# Round: 0
# ACPC State: STATE:0::5c|5d
# Spent: [P0: 100  P1: 100  ]
#
# Action Sequence: dd
IsTerminal() = False
History() = [12, 13]
HistoryString() = "12, 13"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "[Round 0][Player: 0][Pot: 200][Money: 1100 1100][Private: 5c][Public: ][Sequences: ]"
InformationStateString(1) = "[Round 0][Player: 0][Pot: 200][Money: 1100 1100][Private: 5d][Public: ][Sequences: ]"
InformationStateTensor(0): ◉◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
InformationStateTensor(1): ◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
ObservationString(0) = "[Round 0][Player: 0][Pot: 200][Money: 1100 1100[Private: 5c][Ante: 100 100]"
ObservationString(1) = "[Round 0][Player: 0][Pot: 200][Money: 1100 1100[Private: 5d][Ante: 100 100]"
ObservationTensor(0) = [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 100.0]
ObservationTensor(1) = [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 100.0]
Rewards() = [0, 0]
Returns() = [0, 0]
LegalActions() = [1, 2, 3]
StringLegalActions() = ["player=0 move=Call", "player=0 move=Bet", "player=0 move=AllIn"]

# Apply action "player=0 move=Call"
action: 1

# State 3
# BettingAbstration: FCPA
# P0 Cards: 5c
# P1 Cards: 5d
# BoardCards
# Node type?: Player node for player 1
# PossibleActions (3): [ ACTION_CHECK_CALL  ACTION_BET  ACTION_ALL_IN ]
# Round: 0
# ACPC State: STATE:0:c:5c|5d
# Spent: [P0: 100  P1: 100  ]
#
# Action Sequence: ddc
IsTerminal() = False
History() = [12, 13, 1]
HistoryString() = "12, 13, 1"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "[Round 0][Player: 1][Pot: 200][Money: 1100 1100][Private: 5c][Public: ][Sequences: c]"
InformationStateString(1) = "[Round 0][Player: 1][Pot: 200][Money: 1100 1100][Private: 5d][Public: ][Sequences: c]"
InformationStateTensor(0): ◉◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
InformationStateTensor(1): ◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
ObservationString(0) = "[Round 0][Player: 1][Pot: 200][Money: 1100 1100[Private: 5c][Ante: 100 100]"
ObservationString(1) = "[Round 0][Player: 1][Pot: 200][Money: 1100 1100[Private: 5d][Ante: 100 100]"
ObservationTensor(0) = [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 100.0]
ObservationTensor(1) = [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 100.0]
Rewards() = [0, 0]
Returns() = [0, 0]
LegalActions() = [1, 2, 3]
StringLegalActions() = ["player=1 move=Call", "player=1 move=Bet", "player=1 move=AllIn"]

# Apply action "player=1 move=Bet"
action: 2

# State 4
# BettingAbstration: FCPA
# P0 Cards: 5c
# P1 Cards: 5d
# BoardCards
# Node type?: Player node for player 0
# PossibleActions (4): [ ACTION_FOLD  ACTION_CHECK_CALL  ACTION_BET  ACTION_ALL_IN ]
# Round: 0
# ACPC State: STATE:0:cr300:5c|5d
# Spent: [P0: 100  P1: 300  ]
#
# Action Sequence: ddcp
IsTerminal() = False
History() = [12, 13, 1, 2]
HistoryString() = "12, 13, 1, 2"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "[Round 0][Player: 0][Pot: 600][Money: 1100 900][Private: 5c][Public: ][Sequences: cr300]"
InformationStateString(1) = "[Round 0][Player: 0][Pot: 600][Money: 1100 900][Private: 5d][Public: ][Sequences: cr300]"
InformationStateTensor(0): ◉◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯
InformationStateTensor(1): ◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯
ObservationString(0) = "[Round 0][Player: 0][Pot: 600][Money: 1100 900[Private: 5c][Ante: 100 300]"
ObservationString(1) = "[Round 0][Player: 0][Pot: 600][Money: 1100 900[Private: 5d][Ante: 100 300]"
ObservationTensor(0) = [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 300.0]
ObservationTensor(1) = [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 300.0]
Rewards() = [0, 0]
Returns() = [0, 0]
LegalActions() = [0, 1, 2, 3]
StringLegalActions() = ["player=0 move=Fold", "player=0 move=Call", "player=0 move=Bet", "player=0 move=AllIn"]

# Apply action "player=0 move=Fold"
action: 0

# State 5
# BettingAbstration: FCPA
# P0 Cards: 5c
# P1 Cards: 5d
# BoardCards
# P0 Reward: -100
# P1 Reward: 100
# Node type?: Terminal Node!
# PossibleActions (0): []
# Round: 0
# ACPC State: STATE:0:cr300f:5c|5d
# Spent: [P0: 100  P1: 300  ]
#
# Action Sequence: ddcpf
IsTerminal() = True
History() = [12, 13, 1, 2, 0]
HistoryString() = "12, 13, 1, 2, 0"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = -4
InformationStateString(0) = "[Round 0][Player: -4][Pot: 300][Money: 1100 900][Private: 5c][Public: ][Sequences: cr300f]"
InformationStateString(1) = "[Round 0][Player: -4][Pot: 300][Money: 1100 900][Private: 5d][Public: ][Sequences: cr300f]"
InformationStateTensor(0): ◉◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯
InformationStateTensor(1): ◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯
ObservationString(0) = "[Round 0][Player: -4][Pot: 300][Money: 1100 900[Private: 5c][Ante: 100 300]"
ObservationString(1) = "[Round 0][Player: -4][Pot: 300][Money: 1100 900[Private: 5d][Ante: 100 300]"
ObservationTensor(0) = [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 300.0]
ObservationTensor(1) = [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0, 300.0]
Rewards() = [-100, 100]
Returns() = [-100, 100]
