game: 2048

GameType.chance_mode = ChanceMode.EXPLICIT_STOCHASTIC
GameType.dynamics = Dynamics.SEQUENTIAL
GameType.information = Information.PERFECT_INFORMATION
GameType.long_name = "2048"
GameType.max_num_players = 1
GameType.min_num_players = 1
GameType.parameter_specification = ["max_tile"]
GameType.provides_information_state_string = False
GameType.provides_information_state_tensor = False
GameType.provides_observation_string = True
GameType.provides_observation_tensor = True
GameType.provides_factored_observation_string = False
GameType.reward_model = RewardModel.REWARDS
GameType.short_name = "2048"
GameType.utility = Utility.GENERAL_SUM

NumDistinctActions() = 4
PolicyTensorShape() = [4]
MaxChanceOutcomes() = 33
GetParameters() = {max_tile=2048}
NumPlayers() = 1
MinUtility() = 0.0
MaxUtility() = 2.048e+04
UtilitySum() = None
ObservationTensorShape() = [4, 4]
ObservationTensorLayout() = TensorLayout.CHW
ObservationTensorSize() = 16
MaxGameLength() = 8192
ToString() = "2048()"

# State 0
#     0    0    0    0
#     0    0    0    0
#     0    0    0    0
#     0    0    0    0
IsTerminal() = False
History() = []
HistoryString() = ""
IsChanceNode() = True
IsSimultaneousNode() = False
CurrentPlayer() = -1
ObservationString(0) = "    0    0    0    0\n    0    0    0    0\n    0    0    0    0\n    0    0    0    0\n"
ObservationTensor(0): ◯◯◯◯
                      ◯◯◯◯
                      ◯◯◯◯
                      ◯◯◯◯
ChanceOutcomes() = [(0,0.05625), (1,0.00625), (2,0.05625), (3,0.00625), (4,0.05625), (5,0.00625), (6,0.05625), (7,0.00625), (8,0.05625), (9,0.00625), (10,0.05625), (11,0.00625), (12,0.05625), (13,0.00625), (14,0.05625), (15,0.00625), (16,0.05625), (17,0.00625), (18,0.05625), (19,0.00625), (20,0.05625), (21,0.00625), (22,0.05625), (23,0.00625), (24,0.05625), (25,0.00625), (26,0.05625), (27,0.00625), (28,0.05625), (29,0.00625), (30,0.05625), (31,0.00625)]
LegalActions() = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]
StringLegalActions() = ["2 added to row 1, column 1", "4 added to row 1, column 1", "2 added to row 1, column 2", "4 added to row 1, column 2", "2 added to row 1, column 3", "4 added to row 1, column 3", "2 added to row 1, column 4", "4 added to row 1, column 4", "2 added to row 2, column 1", "4 added to row 2, column 1", "2 added to row 2, column 2", "4 added to row 2, column 2", "2 added to row 2, column 3", "4 added to row 2, column 3", "2 added to row 2, column 4", "4 added to row 2, column 4", "2 added to row 3, column 1", "4 added to row 3, column 1", "2 added to row 3, column 2", "4 added to row 3, column 2", "2 added to row 3, column 3", "4 added to row 3, column 3", "2 added to row 3, column 4", "4 added to row 3, column 4", "2 added to row 4, column 1", "4 added to row 4, column 1", "2 added to row 4, column 2", "4 added to row 4, column 2", "2 added to row 4, column 3", "4 added to row 4, column 3", "2 added to row 4, column 4", "4 added to row 4, column 4"]

# Apply action "2 added to row 3, column 3"
action: 20

# State 1
#     0    0    0    0
#     0    0    0    0
#     0    0    2    0
#     0    0    0    0
IsTerminal() = False
History() = [20]
HistoryString() = "20"
IsChanceNode() = True
IsSimultaneousNode() = False
CurrentPlayer() = -1
ObservationString(0) = "    0    0    0    0\n    0    0    0    0\n    0    0    2    0\n    0    0    0    0\n"
ObservationTensor(0) = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0]
ChanceOutcomes() = [(0,0.06), (1,0.00666667), (2,0.06), (3,0.00666667), (4,0.06), (5,0.00666667), (6,0.06), (7,0.00666667), (8,0.06), (9,0.00666667), (10,0.06), (11,0.00666667), (12,0.06), (13,0.00666667), (14,0.06), (15,0.00666667), (16,0.06), (17,0.00666667), (18,0.06), (19,0.00666667), (22,0.06), (23,0.00666667), (24,0.06), (25,0.00666667), (26,0.06), (27,0.00666667), (28,0.06), (29,0.00666667), (30,0.06), (31,0.00666667)]
LegalActions() = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]
StringLegalActions() = ["2 added to row 1, column 1", "4 added to row 1, column 1", "2 added to row 1, column 2", "4 added to row 1, column 2", "2 added to row 1, column 3", "4 added to row 1, column 3", "2 added to row 1, column 4", "4 added to row 1, column 4", "2 added to row 2, column 1", "4 added to row 2, column 1", "2 added to row 2, column 2", "4 added to row 2, column 2", "2 added to row 2, column 3", "4 added to row 2, column 3", "2 added to row 2, column 4", "4 added to row 2, column 4", "2 added to row 3, column 1", "4 added to row 3, column 1", "2 added to row 3, column 2", "4 added to row 3, column 2", "2 added to row 3, column 4", "4 added to row 3, column 4", "2 added to row 4, column 1", "4 added to row 4, column 1", "2 added to row 4, column 2", "4 added to row 4, column 2", "2 added to row 4, column 3", "4 added to row 4, column 3", "2 added to row 4, column 4", "4 added to row 4, column 4"]

# Apply action "2 added to row 2, column 2"
action: 10

# State 2
#     0    0    0    0
#     0    2    0    0
#     0    0    2    0
#     0    0    0    0
IsTerminal() = False
History() = [20, 10]
HistoryString() = "20, 10"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "    0    0    0    0\n    0    2    0    0\n    0    0    2    0\n    0    0    0    0\n"
ObservationTensor(0) = [0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Rewards() = [0]
Returns() = [0]
LegalActions() = [0, 1, 2, 3]
StringLegalActions() = ["Up", "Right", "Down", "Left"]

# Apply action "Left"
action: 3

# State 3
# Apply action "2 added to row 3, column 3"
action: 20

# State 4
#     0    0    0    0
#     2    0    0    0
#     2    0    2    0
#     0    0    0    0
IsTerminal() = False
History() = [20, 10, 3, 20]
HistoryString() = "20, 10, 3, 20"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "    0    0    0    0\n    2    0    0    0\n    2    0    2    0\n    0    0    0    0\n"
ObservationTensor(0) = [0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Rewards() = [0]
Returns() = [0]
LegalActions() = [0, 1, 2, 3]
StringLegalActions() = ["Up", "Right", "Down", "Left"]

# Apply action "Up"
action: 0

# State 5
# Apply action "4 added to row 2, column 3"
action: 13

# State 6
#     4    0    2    0
#     0    0    4    0
#     0    0    0    0
#     0    0    0    0
IsTerminal() = False
History() = [20, 10, 3, 20, 0, 13]
HistoryString() = "20, 10, 3, 20, 0, 13"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "    4    0    2    0\n    0    0    4    0\n    0    0    0    0\n    0    0    0    0\n"
ObservationTensor(0) = [4.0, 0.0, 2.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Rewards() = [4]
Returns() = [4]
LegalActions() = [1, 2, 3]
StringLegalActions() = ["Right", "Down", "Left"]

# Apply action "Left"
action: 3

# State 7
# Apply action "2 added to row 3, column 3"
action: 20

# State 8
# Apply action "Left"
action: 3

# State 9
# Apply action "4 added to row 3, column 2"
action: 19

# State 10
# Apply action "Down"
action: 2

# State 11
# Apply action "2 added to row 2, column 1"
action: 8

# State 12
# Apply action "Up"
action: 0

# State 13
# Apply action "4 added to row 4, column 2"
action: 27

# State 14
# Apply action "Right"
action: 1

# State 15
# Apply action "4 added to row 3, column 2"
action: 19

# State 16
# Apply action "Down"
action: 2

# State 17
# Apply action "4 added to row 1, column 2"
action: 3

# State 18
# Apply action "Right"
action: 1

# State 19
# Apply action "4 added to row 2, column 3"
action: 13

# State 20
# Apply action "Left"
action: 3

# State 21
# Apply action "4 added to row 1, column 4"
action: 7

# State 22
#     4    0    0    4
#     4    8    0    0
#     2    0    0    0
#     4    8    4    0
IsTerminal() = False
History() = [20, 10, 3, 20, 0, 13, 3, 20, 3, 19, 2, 8, 0, 27, 1, 19, 2, 3, 1, 13, 3, 7]
HistoryString() = "20, 10, 3, 20, 0, 13, 3, 20, 3, 19, 2, 8, 0, 27, 1, 19, 2, 3, 1, 13, 3, 7"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "    4    0    0    4\n    4    8    0    0\n    2    0    0    0\n    4    8    4    0\n"
ObservationTensor(0) = [4.0, 0.0, 0.0, 4.0, 4.0, 8.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 4.0, 8.0, 4.0, 0.0]
Rewards() = [0]
Returns() = [24]
LegalActions() = [0, 1, 2, 3]
StringLegalActions() = ["Up", "Right", "Down", "Left"]

# Apply action "Up"
action: 0

# State 23
# Apply action "4 added to row 4, column 2"
action: 27

# State 24
# Apply action "Up"
action: 0

# State 25
# Apply action "2 added to row 3, column 4"
action: 22

# State 26
# Apply action "Left"
action: 3

# State 27
# Apply action "4 added to row 4, column 1"
action: 25

# State 28
# Apply action "Right"
action: 1

# State 29
# Apply action "4 added to row 3, column 2"
action: 19

# State 30
# Apply action "Down"
action: 2

# State 31
# Apply action "4 added to row 1, column 2"
action: 3

# State 32
# Apply action "Down"
action: 2

# State 33
# Apply action "2 added to row 1, column 2"
action: 2

# State 34
# Apply action "Left"
action: 3

# State 35
# Apply action "2 added to row 2, column 4"
action: 14

# State 36
# Apply action "Up"
action: 0

# State 37
# Apply action "4 added to row 4, column 3"
action: 29

# State 38
# Apply action "Up"
action: 0

# State 39
# Apply action "4 added to row 2, column 4"
action: 15

# State 40
# Apply action "Right"
action: 1

# State 41
# Apply action "4 added to row 2, column 1"
action: 9

# State 42
#     0    2   16    2
#     4    4   16    4
#     0    0   16    8
#     0    0    0    0
IsTerminal() = False
History() = [20, 10, 3, 20, 0, 13, 3, 20, 3, 19, 2, 8, 0, 27, 1, 19, 2, 3, 1, 13, 3, 7, 0, 27, 0, 22, 3, 25, 1, 19, 2, 3, 2, 2, 3, 14, 0, 29, 0, 15, 1, 9]
HistoryString() = "20, 10, 3, 20, 0, 13, 3, 20, 3, 19, 2, 8, 0, 27, 1, 19, 2, 3, 1, 13, 3, 7, 0, 27, 0, 22, 3, 25, 1, 19, 2, 3, 2, 2, 3, 14, 0, 29, 0, 15, 1, 9"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "    0    2   16    2\n    4    4   16    4\n    0    0   16    8\n    0    0    0    0\n"
ObservationTensor(0) = [0.0, 2.0, 16.0, 2.0, 4.0, 4.0, 16.0, 4.0, 0.0, 0.0, 16.0, 8.0, 0.0, 0.0, 0.0, 0.0]
Rewards() = [16]
Returns() = [116]
LegalActions() = [0, 1, 2, 3]
StringLegalActions() = ["Up", "Right", "Down", "Left"]

# Apply action "Right"
action: 1

# State 43
# Apply action "2 added to row 4, column 3"
action: 28

# State 44
# Apply action "Right"
action: 1

# State 45
# Apply action "2 added to row 4, column 3"
action: 28

# State 46
# Apply action "Down"
action: 2

# State 47
# Apply action "2 added to row 4, column 1"
action: 24

# State 48
# Apply action "Up"
action: 0

# State 49
# Apply action "2 added to row 4, column 1"
action: 24

# State 50
# Apply action "Up"
action: 0

# State 51
# Apply action "4 added to row 3, column 1"
action: 17

# State 52
# Apply action "Right"
action: 1

# State 53
# Apply action "2 added to row 4, column 3"
action: 28

# State 54
# Apply action "Left"
action: 3

# State 55
# Apply action "4 added to row 4, column 2"
action: 27

# State 56
# Apply action "Right"
action: 1

# State 57
# Apply action "4 added to row 4, column 3"
action: 29

# State 58
# Apply action "Up"
action: 0

# State 59
# Apply action "2 added to row 2, column 1"
action: 8

# State 60
# Apply action "Right"
action: 1

# State 61
# Apply action "2 added to row 4, column 3"
action: 28

# State 62
#     4    2   16    2
#     2    8   32    4
#     0    4    2   16
#     0    0    2    4
IsTerminal() = False
History() = [20, 10, 3, 20, 0, 13, 3, 20, 3, 19, 2, 8, 0, 27, 1, 19, 2, 3, 1, 13, 3, 7, 0, 27, 0, 22, 3, 25, 1, 19, 2, 3, 2, 2, 3, 14, 0, 29, 0, 15, 1, 9, 1, 28, 1, 28, 2, 24, 0, 24, 0, 17, 1, 28, 3, 27, 1, 29, 0, 8, 1, 28]
HistoryString() = "20, 10, 3, 20, 0, 13, 3, 20, 3, 19, 2, 8, 0, 27, 1, 19, 2, 3, 1, 13, 3, 7, 0, 27, 0, 22, 3, 25, 1, 19, 2, 3, 2, 2, 3, 14, 0, 29, 0, 15, 1, 9, 1, 28, 1, 28, 2, 24, 0, 24, 0, 17, 1, 28, 3, 27, 1, 29, 0, 8, 1, 28"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "    4    2   16    2\n    2    8   32    4\n    0    4    2   16\n    0    0    2    4\n"
ObservationTensor(0) = [4.0, 2.0, 16.0, 2.0, 2.0, 8.0, 32.0, 4.0, 0.0, 4.0, 2.0, 16.0, 0.0, 0.0, 2.0, 4.0]
Rewards() = [0]
Returns() = [188]
LegalActions() = [0, 2, 3]
StringLegalActions() = ["Up", "Down", "Left"]

# Apply action "Down"
action: 2

# State 63
# Apply action "2 added to row 1, column 2"
action: 2

# State 64
# Apply action "Left"
action: 3

# State 65
# Apply action "4 added to row 1, column 3"
action: 5

# State 66
# Apply action "Up"
action: 0

# State 67
# Apply action "2 added to row 4, column 2"
action: 26

# State 68
# Apply action "Down"
action: 2

# State 69
# Apply action "2 added to row 1, column 4"
action: 6

# State 70
# Apply action "Right"
action: 1

# State 71
# Apply action "2 added to row 1, column 2"
action: 2

# State 72
# Apply action "Up"
action: 0

# State 73
# Apply action "2 added to row 3, column 1"
action: 16

# State 74
# Apply action "Right"
action: 1

# State 75
# Apply action "4 added to row 3, column 1"
action: 17

# State 76
# Apply action "Left"
action: 3

# State 77
# Apply action "4 added to row 4, column 2"
action: 27

# State 78
# Apply action "Down"
action: 2

# State 79
# Apply action "2 added to row 1, column 2"
action: 2

# State 80
# Apply action "Right"
action: 1

# State 81
# Apply action "2 added to row 1, column 3"
action: 4

# State 82
#     0    0    2    2
#     0    0    2    4
#     0    8    4    2
#    16    4   16   64
IsTerminal() = False
History() = [20, 10, 3, 20, 0, 13, 3, 20, 3, 19, 2, 8, 0, 27, 1, 19, 2, 3, 1, 13, 3, 7, 0, 27, 0, 22, 3, 25, 1, 19, 2, 3, 2, 2, 3, 14, 0, 29, 0, 15, 1, 9, 1, 28, 1, 28, 2, 24, 0, 24, 0, 17, 1, 28, 3, 27, 1, 29, 0, 8, 1, 28, 2, 2, 3, 5, 0, 26, 2, 6, 1, 2, 0, 16, 1, 17, 3, 27, 2, 2, 1, 4]
HistoryString() = "20, 10, 3, 20, 0, 13, 3, 20, 3, 19, 2, 8, 0, 27, 1, 19, 2, 3, 1, 13, 3, 7, 0, 27, 0, 22, 3, 25, 1, 19, 2, 3, 2, 2, 3, 14, 0, 29, 0, 15, 1, 9, 1, 28, 1, 28, 2, 24, 0, 24, 0, 17, 1, 28, 3, 27, 1, 29, 0, 8, 1, 28, 2, 2, 3, 5, 0, 26, 2, 6, 1, 2, 0, 16, 1, 17, 3, 27, 2, 2, 1, 4"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "    0    0    2    2\n    0    0    2    4\n    0    8    4    2\n   16    4   16   64\n"
ObservationTensor(0) = [0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 2.0, 4.0, 0.0, 8.0, 4.0, 2.0, 16.0, 4.0, 16.0, 64.0]
Rewards() = [0]
Returns() = [364]
LegalActions() = [0, 1, 2, 3]
StringLegalActions() = ["Up", "Right", "Down", "Left"]

# Apply action "Down"
action: 2

# State 83
# Apply action "4 added to row 2, column 1"
action: 9

# State 84
# Apply action "Up"
action: 0

# State 85
# Apply action "2 added to row 4, column 3"
action: 28

# State 86
# Apply action "Left"
action: 3

# State 87
# Apply action "2 added to row 4, column 3"
action: 28

# State 88
# Apply action "Right"
action: 1

# State 89
# Apply action "4 added to row 3, column 1"
action: 17

# State 90
# Apply action "Down"
action: 2

# State 91
# Apply action "4 added to row 2, column 2"
action: 11

# State 92
# Apply action "Up"
action: 0

# State 93
# Apply action "2 added to row 3, column 4"
action: 22

# State 94
# Apply action "Right"
action: 1

# State 95
# Apply action "4 added to row 4, column 3"
action: 29

# State 96
# Apply action "Down"
action: 2

# State 97
# Apply action "2 added to row 2, column 1"
action: 8

# State 98
# Apply action "Up"
action: 0

# State 99
# Apply action "2 added to row 4, column 3"
action: 28

# State 100
# Apply action "Left"
action: 3

# State 101
# Apply action "4 added to row 3, column 4"
action: 23

# State 102
#     2    4   32    2
#    16    8   64    8
#     8    4    0    4
#     2    0    0    0
IsTerminal() = False
History() = [20, 10, 3, 20, 0, 13, 3, 20, 3, 19, 2, 8, 0, 27, 1, 19, 2, 3, 1, 13, 3, 7, 0, 27, 0, 22, 3, 25, 1, 19, 2, 3, 2, 2, 3, 14, 0, 29, 0, 15, 1, 9, 1, 28, 1, 28, 2, 24, 0, 24, 0, 17, 1, 28, 3, 27, 1, 29, 0, 8, 1, 28, 2, 2, 3, 5, 0, 26, 2, 6, 1, 2, 0, 16, 1, 17, 3, 27, 2, 2, 1, 4, 2, 9, 0, 28, 3, 28, 1, 17, 2, 11, 0, 22, 1, 29, 2, 8, 0, 28, 3, 23]
HistoryString() = "20, 10, 3, 20, 0, 13, 3, 20, 3, 19, 2, 8, 0, 27, 1, 19, 2, 3, 1, 13, 3, 7, 0, 27, 0, 22, 3, 25, 1, 19, 2, 3, 2, 2, 3, 14, 0, 29, 0, 15, 1, 9, 1, 28, 1, 28, 2, 24, 0, 24, 0, 17, 1, 28, 3, 27, 1, 29, 0, 8, 1, 28, 2, 2, 3, 5, 0, 26, 2, 6, 1, 2, 0, 16, 1, 17, 3, 27, 2, 2, 1, 4, 2, 9, 0, 28, 3, 28, 1, 17, 2, 11, 0, 22, 1, 29, 2, 8, 0, 28, 3, 23"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
ObservationString(0) = "    2    4   32    2\n   16    8   64    8\n    8    4    0    4\n    2    0    0    0\n"
ObservationTensor(0) = [2.0, 4.0, 32.0, 2.0, 16.0, 8.0, 64.0, 8.0, 8.0, 4.0, 0.0, 4.0, 2.0, 0.0, 0.0, 0.0]
Rewards() = [8]
Returns() = [456]
LegalActions() = [1, 2, 3]
StringLegalActions() = ["Right", "Down", "Left"]

# Apply action "Right"
action: 1

# State 103
# Apply action "2 added to row 4, column 2"
action: 26

# State 104
# Apply action "Down"
action: 2

# State 105
# Apply action "4 added to row 1, column 2"
action: 3

# State 106
# Apply action "Down"
action: 2

# State 107
# Apply action "4 added to row 1, column 1"
action: 1

# State 108
# Apply action "Left"
action: 3

# State 109
# Apply action "4 added to row 2, column 4"
action: 15

# State 110
# Apply action "Right"
action: 1

# State 111
# Apply action "4 added to row 1, column 2"
action: 3

# State 112
# Apply action "Right"
action: 1

# State 113
# Apply action "2 added to row 1, column 2"
action: 2

# State 114
# Apply action "Left"
action: 3

# State 115
# Apply action "2 added to row 1, column 3"
action: 4

# State 116
# Apply action "Right"
action: 1

# State 117
# Apply action "4 added to row 1, column 1"
action: 1

# State 118
#     4    2    8    2
#     8   32    2    4
#     2    8   64   16
#    16    2    8    2
IsTerminal() = True
History() = [20, 10, 3, 20, 0, 13, 3, 20, 3, 19, 2, 8, 0, 27, 1, 19, 2, 3, 1, 13, 3, 7, 0, 27, 0, 22, 3, 25, 1, 19, 2, 3, 2, 2, 3, 14, 0, 29, 0, 15, 1, 9, 1, 28, 1, 28, 2, 24, 0, 24, 0, 17, 1, 28, 3, 27, 1, 29, 0, 8, 1, 28, 2, 2, 3, 5, 0, 26, 2, 6, 1, 2, 0, 16, 1, 17, 3, 27, 2, 2, 1, 4, 2, 9, 0, 28, 3, 28, 1, 17, 2, 11, 0, 22, 1, 29, 2, 8, 0, 28, 3, 23, 1, 26, 2, 3, 2, 1, 3, 15, 1, 3, 1, 2, 3, 4, 1, 1]
HistoryString() = "20, 10, 3, 20, 0, 13, 3, 20, 3, 19, 2, 8, 0, 27, 1, 19, 2, 3, 1, 13, 3, 7, 0, 27, 0, 22, 3, 25, 1, 19, 2, 3, 2, 2, 3, 14, 0, 29, 0, 15, 1, 9, 1, 28, 1, 28, 2, 24, 0, 24, 0, 17, 1, 28, 3, 27, 1, 29, 0, 8, 1, 28, 2, 2, 3, 5, 0, 26, 2, 6, 1, 2, 0, 16, 1, 17, 3, 27, 2, 2, 1, 4, 2, 9, 0, 28, 3, 28, 1, 17, 2, 11, 0, 22, 1, 29, 2, 8, 0, 28, 3, 23, 1, 26, 2, 3, 2, 1, 3, 15, 1, 3, 1, 2, 3, 4, 1, 1"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = -4
ObservationString(0) = "    4    2    8    2\n    8   32    2    4\n    2    8   64   16\n   16    2    8    2\n"
ObservationTensor(0) = [4.0, 2.0, 8.0, 2.0, 8.0, 32.0, 2.0, 4.0, 2.0, 8.0, 64.0, 16.0, 16.0, 2.0, 8.0, 2.0]
Rewards() = [0]
Returns() = [496]
