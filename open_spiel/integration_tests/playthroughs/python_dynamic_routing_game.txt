game: python_dynamic_routing_game

GameType.chance_mode = ChanceMode.EXPLICIT_STOCHASTIC
GameType.dynamics = Dynamics.SIMULTANEOUS
GameType.information = Information.PERFECT_INFORMATION
GameType.long_name = "Python Dynamic Routing Game"
GameType.max_num_players = 100
GameType.min_num_players = 0
GameType.parameter_specification = ["players"]
GameType.provides_information_state_string = True
GameType.provides_information_state_tensor = True
GameType.provides_observation_string = True
GameType.provides_observation_tensor = True
GameType.provides_factored_observation_string = True
GameType.reward_model = RewardModel.TERMINAL
GameType.short_name = "python_dynamic_routing_game"
GameType.utility = Utility.GENERAL_SUM

NumDistinctActions() = 5
PolicyTensorShape() = [5]
MaxChanceOutcomes() = 4
GetParameters() = {players=-1}
NumPlayers() = 2
MinUtility() = -3.0
MaxUtility() = 0.0
UtilitySum() = 0.0
InformationStateTensorShape() = [3, 3]
InformationStateTensorLayout() = TensorLayout.CHW
InformationStateTensorSize() = 9
ObservationTensorShape() = [3, 3]
ObservationTensorLayout() = TensorLayout.CHW
ObservationTensorSize() = 9
MaxGameLength() = 2
ToString() = "python_dynamic_routing_game(players=-1)"

# State 0
# Vehicle locations: ['bef_O->O', 'bef_O->O'], time: 0.
IsTerminal() = False
History() = []
HistoryString() = ""
IsChanceNode() = False
IsSimultaneousNode() = True
CurrentPlayer() = PlayerId.SIMULTANEOUS
InformationStateString(0) = ""
InformationStateString(1) = ""
InformationStateTensor(0).observation: ◉◉◉
                                       ◯◯◯
                                       ◯◯◯
InformationStateTensor(1).observation: ◉◉◉
                                       ◯◯◯
                                       ◯◯◯
ObservationString(0) = ""
ObservationString(1) = ""
PublicObservationString() = ""
PrivateObservationString(0) = ""
PrivateObservationString(1) = ""
ObservationTensor(0): ◉◉◉
                      ◯◯◯
                      ◯◯◯
ObservationTensor(1): ◉◉◉
                      ◯◯◯
                      ◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0, 0]
LegalActions(0) = [2]
LegalActions(1) = [2]
StringLegalActions(0) = ["Vehicle 0 would like to move to O->A."]
StringLegalActions(1) = ["Vehicle 1 would like to move to O->A."]

# Apply joint action ["Vehicle 0 would like to move to O->A.", "Vehicle 1 would like to move to O->A."]
actions: [2, 2]

# State 1
# Vehicle locations: ['O->A', 'O->A'], time: 1.
IsTerminal() = False
History() = [2, 2]
HistoryString() = "2, 2"
IsChanceNode() = True
IsSimultaneousNode() = False
CurrentPlayer() = PlayerId.CHANCE
InformationStateString(0) = "2, 2"
InformationStateString(1) = "2, 2"
InformationStateTensor(0).observation = [1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 0.0, 0.0, 0.0]
InformationStateTensor(1).observation = [1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 0.0, 0.0, 0.0]
ObservationString(0) = "2, 2"
ObservationString(1) = "2, 2"
PublicObservationString() = "2, 2"
PrivateObservationString(0) = "2, 2"
PrivateObservationString(1) = "2, 2"
ObservationTensor(0) = [1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 0.0, 0.0, 0.0]
ObservationTensor(1) = [1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 0.0, 0.0, 0.0]
ChanceOutcomes() = [(0, 0.44444444444444453), (1, 0.22222222222222224), (2, 0.22222222222222224), (3, 0.1111111111111111)]
LegalActions() = [0, 1, 2, 3]
StringLegalActions() = ["Change node 0. I will convert it later to human readable chance outcome.", "Change node 1. I will convert it later to human readable chance outcome.", "Change node 2. I will convert it later to human readable chance outcome.", "Change node 3. I will convert it later to human readable chance outcome."]

# Apply action "Change node 0. I will convert it later to human readable chance outcome."
action: 0

# State 2
# Vehicle locations: ['O->A', 'O->A'], time: 1.
IsTerminal() = False
History() = [2, 2, 0]
HistoryString() = "2, 2, 0"
IsChanceNode() = False
IsSimultaneousNode() = True
CurrentPlayer() = PlayerId.SIMULTANEOUS
InformationStateString(0) = "2, 2, 0"
InformationStateString(1) = "2, 2, 0"
InformationStateTensor(0).observation = [1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 0.0, 0.0, 0.0]
InformationStateTensor(1).observation = [1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 0.0, 0.0, 0.0]
ObservationString(0) = "2, 2, 0"
ObservationString(1) = "2, 2, 0"
PublicObservationString() = "2, 2, 0"
PrivateObservationString(0) = "2, 2, 0"
PrivateObservationString(1) = "2, 2, 0"
ObservationTensor(0) = [1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 0.0, 0.0, 0.0]
ObservationTensor(1) = [1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 0.0, 0.0, 0.0]
Rewards() = [0.0, 0.0]
Returns() = [0, 0]
LegalActions(0) = [3]
LegalActions(1) = [3]
StringLegalActions(0) = ["Vehicle 0 would like to move to A->D."]
StringLegalActions(1) = ["Vehicle 1 would like to move to A->D."]

# Apply joint action ["Vehicle 0 would like to move to A->D.", "Vehicle 1 would like to move to A->D."]
actions: [3, 3]

# State 3
# Vehicle locations: ['O->A', 'O->A'], time: 2.
IsTerminal() = True
History() = [2, 2, 0, 3, 3]
HistoryString() = "2, 2, 0, 3, 3"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = PlayerId.TERMINAL
InformationStateString(0) = "2, 2, 0, 3, 3"
InformationStateString(1) = "2, 2, 0, 3, 3"
InformationStateTensor(0).observation = [1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0]
InformationStateTensor(1).observation = [1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0]
ObservationString(0) = "2, 2, 0, 3, 3"
ObservationString(1) = "2, 2, 0, 3, 3"
PublicObservationString() = "2, 2, 0, 3, 3"
PrivateObservationString(0) = "2, 2, 0, 3, 3"
PrivateObservationString(1) = "2, 2, 0, 3, 3"
ObservationTensor(0) = [1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0]
ObservationTensor(1) = [1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0]
Rewards() = [-3.0, -3.0]
Returns() = [-3.0, -3.0]
