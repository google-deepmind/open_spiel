game: tiny_bridge_2p

GameType.chance_mode = ChanceMode.EXPLICIT_STOCHASTIC
GameType.dynamics = Dynamics.SEQUENTIAL
GameType.information = Information.IMPERFECT_INFORMATION
GameType.long_name = "Tiny Bridge (Uncontested)"
GameType.max_num_players = 2
GameType.min_num_players = 2
GameType.parameter_specification = ["abstracted"]
GameType.provides_information_state_string = True
GameType.provides_information_state_tensor = True
GameType.provides_observation_string = True
GameType.provides_observation_tensor = True
GameType.provides_factored_observation_string = False
GameType.reward_model = RewardModel.TERMINAL
GameType.short_name = "tiny_bridge_2p"
GameType.utility = Utility.IDENTICAL

NumDistinctActions() = 7
PolicyTensorShape() = [7]
MaxChanceOutcomes() = 28
GetParameters() = {abstracted=False}
NumPlayers() = 2
MinUtility() = -40.0
MaxUtility() = 35.0
UtilitySum() = None
InformationStateTensorShape() = [22]
InformationStateTensorLayout() = TensorLayout.CHW
InformationStateTensorSize() = 22
ObservationTensorShape() = [15]
ObservationTensorLayout() = TensorLayout.CHW
ObservationTensorSize() = 15
MaxGameLength() = 8
ToString() = "tiny_bridge_2p()"

# State 0
# W:?? E:??
IsTerminal() = False
History() = []
HistoryString() = ""
IsChanceNode() = True
IsSimultaneousNode() = False
CurrentPlayer() = -1
InformationStateString(0) = "??"
InformationStateString(1) = "??"
InformationStateTensor(0): ◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
InformationStateTensor(1): ◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
ObservationString(0) = "??"
ObservationString(1) = "??"
ObservationTensor(0): ◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
ObservationTensor(1): ◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
ChanceOutcomes() = [(0,0.0357143), (1,0.0357143), (3,0.0357143), (6,0.0357143), (10,0.0357143), (15,0.0357143), (21,0.0357143), (2,0.0357143), (4,0.0357143), (7,0.0357143), (11,0.0357143), (16,0.0357143), (22,0.0357143), (5,0.0357143), (8,0.0357143), (12,0.0357143), (17,0.0357143), (23,0.0357143), (9,0.0357143), (13,0.0357143), (18,0.0357143), (24,0.0357143), (14,0.0357143), (19,0.0357143), (25,0.0357143), (20,0.0357143), (26,0.0357143), (27,0.0357143)]
LegalActions() = [0, 1, 3, 6, 10, 15, 21, 2, 4, 7, 11, 16, 22, 5, 8, 12, 17, 23, 9, 13, 18, 24, 14, 19, 25, 20, 26, 27]
StringLegalActions() = ["HQHJ", "HKHJ", "HAHJ", "SJHJ", "SQHJ", "SKHJ", "SAHJ", "HKHQ", "HAHQ", "SJHQ", "SQHQ", "SKHQ", "SAHQ", "HAHK", "SJHK", "SQHK", "SKHK", "SAHK", "SJHA", "SQHA", "SKHA", "SAHA", "SQSJ", "SKSJ", "SASJ", "SKSQ", "SASQ", "SASK"]

# Apply action "HAHK"
action: 5

# State 1
# W:HAHK E:??
IsTerminal() = False
History() = [5]
HistoryString() = "5"
IsChanceNode() = True
IsSimultaneousNode() = False
CurrentPlayer() = -1
InformationStateString(0) = "HAHK"
InformationStateString(1) = "??"
InformationStateTensor(0): ◯◯◉◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
InformationStateTensor(1): ◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
ObservationString(0) = "HAHK"
ObservationString(1) = "??"
ObservationTensor(0): ◯◯◉◉◯◯◯◯◯◯◯◯◯◯◯
ObservationTensor(1): ◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
ChanceOutcomes() = [(0,0.0666667), (6,0.0666667), (10,0.0666667), (15,0.0666667), (21,0.0666667), (7,0.0666667), (11,0.0666667), (16,0.0666667), (22,0.0666667), (14,0.0666667), (19,0.0666667), (25,0.0666667), (20,0.0666667), (26,0.0666667), (27,0.0666667)]
LegalActions() = [0, 6, 10, 15, 21, 7, 11, 16, 22, 14, 19, 25, 20, 26, 27]
StringLegalActions() = ["HQHJ", "SJHJ", "SQHJ", "SKHJ", "SAHJ", "SJHQ", "SQHQ", "SKHQ", "SAHQ", "SQSJ", "SKSJ", "SASJ", "SKSQ", "SASQ", "SASK"]

# Apply action "SASJ"
action: 25

# State 2
# W:HAHK E:SASJ
IsTerminal() = False
History() = [5, 25]
HistoryString() = "5, 25"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "HAHK"
InformationStateString(1) = "SASJ"
InformationStateTensor(0): ◯◯◉◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
InformationStateTensor(1): ◯◯◯◯◉◯◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯
ObservationString(0) = "HAHK"
ObservationString(1) = "SASJ"
ObservationTensor(0): ◯◯◉◉◯◯◯◯◯◯◯◯◯◯◯
ObservationTensor(1): ◯◯◯◯◉◯◯◉◯◯◯◯◯◯◯
Rewards() = [0, 0]
Returns() = [0, 0]
LegalActions() = [0, 1, 2, 3, 4, 5, 6]
StringLegalActions() = ["Pass", "1H", "1S", "1NT", "2H", "2S", "2NT"]

# Apply action "2S"
action: 5

# State 3
# W:HAHK E:SASJ 2S
IsTerminal() = False
History() = [5, 25, 5]
HistoryString() = "5, 25, 5"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "HAHK Us 2S"
InformationStateString(1) = "SASJ Pd 2S"
InformationStateTensor(0): ◯◯◉◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◯
InformationStateTensor(1): ◯◯◯◯◉◯◯◉◯◯◯◯◯◯◯◯◯◯◯◉◯◯
ObservationString(0) = "HAHK 2S:Us"
ObservationString(1) = "SASJ 2S:Pd"
ObservationTensor(0): ◯◯◉◉◯◯◯◯◯◯◯◯◯◉◯
ObservationTensor(1): ◯◯◯◯◉◯◯◉◯◯◯◯◯◉◯
Rewards() = [0, 0]
Returns() = [0, 0]
LegalActions() = [0, 6]
StringLegalActions() = ["Pass", "2NT"]

# Apply action "2NT"
action: 6

# State 4
# W:HAHK E:SASJ 2S-2NT
IsTerminal() = False
History() = [5, 25, 5, 6]
HistoryString() = "5, 25, 5, 6"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "HAHK Us 2S-2NT"
InformationStateString(1) = "SASJ Pd 2S-2NT"
InformationStateTensor(0): ◯◯◉◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◉◯◯◉
InformationStateTensor(1): ◯◯◯◯◉◯◯◉◯◯◯◯◯◯◯◯◯◯◯◉◉◯
ObservationString(0) = "HAHK 2NT:Pd"
ObservationString(1) = "SASJ 2NT:Us"
ObservationTensor(0): ◯◯◉◉◯◯◯◯◯◯◯◯◯◯◉
ObservationTensor(1): ◯◯◯◯◉◯◯◉◯◯◯◯◯◯◉
Rewards() = [0, 0]
Returns() = [0, 0]
LegalActions() = [0]
StringLegalActions() = ["Pass"]

# Apply action "Pass"
action: 0

# State 5
# W:HAHK E:SASJ 2S-2NT-Pass
IsTerminal() = True
History() = [5, 25, 5, 6, 0]
HistoryString() = "5, 25, 5, 6, 0"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = -4
InformationStateString(0) = "HAHK Us 2S-2NT-Pass"
InformationStateString(1) = "SASJ Pd 2S-2NT-Pass"
InformationStateTensor(0): ◯◯◉◉◯◯◯◯◉◯◯◯◯◯◯◯◯◯◉◯◯◉
InformationStateTensor(1): ◯◯◯◯◉◯◯◉◯◉◯◯◯◯◯◯◯◯◯◉◉◯
ObservationString(0) = "HAHK 2NT:Pd"
ObservationString(1) = "SASJ 2NT:Us"
ObservationTensor(0): ◯◯◉◉◯◯◯◯◉◯◯◯◯◯◯
ObservationTensor(1): ◯◯◯◯◉◯◯◉◉◯◯◯◯◯◯
Rewards() = [25.8333, 25.8333]
Returns() = [25.8333, 25.8333]
