game: first_sealed_auction

GameType.chance_mode = ChanceMode.EXPLICIT_STOCHASTIC
GameType.dynamics = Dynamics.SEQUENTIAL
GameType.information = Information.IMPERFECT_INFORMATION
GameType.long_name = "First-Price Sealed-Bid Auction"
GameType.max_num_players = 10
GameType.min_num_players = 2
GameType.parameter_specification = ["max_value", "players"]
GameType.provides_information_state_string = True
GameType.provides_information_state_tensor = True
GameType.provides_observation_string = True
GameType.provides_observation_tensor = True
GameType.provides_factored_observation_string = False
GameType.reward_model = RewardModel.TERMINAL
GameType.short_name = "first_sealed_auction"
GameType.utility = Utility.GENERAL_SUM

NumDistinctActions() = 10
PolicyTensorShape() = [10]
MaxChanceOutcomes() = 11
GetParameters() = {max_value=10,players=2}
NumPlayers() = 2
MinUtility() = 0.0
MaxUtility() = 10.0
UtilitySum() = None
InformationStateTensorShape() = [22]
InformationStateTensorLayout() = TensorLayout.CHW
InformationStateTensorSize() = 22
ObservationTensorShape() = [10]
ObservationTensorLayout() = TensorLayout.CHW
ObservationTensorSize() = 10
MaxGameLength() = 2
ToString() = "first_sealed_auction()"

# State 0
# ;
IsTerminal() = False
History() = []
HistoryString() = ""
IsChanceNode() = True
IsSimultaneousNode() = False
CurrentPlayer() = -1
InformationStateString(0) = "p0"
InformationStateString(1) = "p1"
InformationStateTensor(0): ◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
InformationStateTensor(1): ◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
ObservationString(0) = ""
ObservationString(1) = ""
ObservationTensor(0): ◯◯◯◯◯◯◯◯◯◯
ObservationTensor(1): ◯◯◯◯◯◯◯◯◯◯
ChanceOutcomes() = [(1,0.1), (2,0.1), (3,0.1), (4,0.1), (5,0.1), (6,0.1), (7,0.1), (8,0.1), (9,0.1), (10,0.1)]
LegalActions() = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
StringLegalActions() = ["Player 0 value: 1", "Player 0 value: 2", "Player 0 value: 3", "Player 0 value: 4", "Player 0 value: 5", "Player 0 value: 6", "Player 0 value: 7", "Player 0 value: 8", "Player 0 value: 9", "Player 0 value: 10"]

# Apply action "Player 0 value: 9"
action: 9

# State 1
# 9;
IsTerminal() = False
History() = [9]
HistoryString() = "9"
IsChanceNode() = True
IsSimultaneousNode() = False
CurrentPlayer() = -1
InformationStateString(0) = "p0 val 9"
InformationStateString(1) = "p1"
InformationStateTensor(0): ◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯
InformationStateTensor(1): ◯◉◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯◯
ObservationString(0) = "9"
ObservationString(1) = ""
ObservationTensor(0): ◯◯◯◯◯◯◯◯◉◯
ObservationTensor(1): ◯◯◯◯◯◯◯◯◯◯
ChanceOutcomes() = [(1,0.1), (2,0.1), (3,0.1), (4,0.1), (5,0.1), (6,0.1), (7,0.1), (8,0.1), (9,0.1), (10,0.1)]
LegalActions() = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
StringLegalActions() = ["Player 1 value: 1", "Player 1 value: 2", "Player 1 value: 3", "Player 1 value: 4", "Player 1 value: 5", "Player 1 value: 6", "Player 1 value: 7", "Player 1 value: 8", "Player 1 value: 9", "Player 1 value: 10"]

# Apply action "Player 1 value: 10"
action: 10

# State 2
# 9,10;
IsTerminal() = False
History() = [9, 10]
HistoryString() = "9, 10"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "p0 val 9"
InformationStateString(1) = "p1 val 10"
InformationStateTensor(0): ◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯◯
InformationStateTensor(1): ◯◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯
ObservationString(0) = "9"
ObservationString(1) = "10"
ObservationTensor(0): ◯◯◯◯◯◯◯◯◉◯
ObservationTensor(1): ◯◯◯◯◯◯◯◯◯◉
Rewards() = [0, 0]
Returns() = [0, 0]
LegalActions() = [0, 1, 2, 3, 4, 5, 6, 7, 8]
StringLegalActions() = ["Player 0 bid: 0", "Player 0 bid: 1", "Player 0 bid: 2", "Player 0 bid: 3", "Player 0 bid: 4", "Player 0 bid: 5", "Player 0 bid: 6", "Player 0 bid: 7", "Player 0 bid: 8"]

# Apply action "Player 0 bid: 3"
action: 3

# State 3
# 9,10;3
IsTerminal() = False
History() = [9, 10, 3]
HistoryString() = "9, 10, 3"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "p0 val 9 bid 3"
InformationStateString(1) = "p1 val 10"
InformationStateTensor(0): ◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◉◯◯◯◯◯◯
InformationStateTensor(1): ◯◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◯◯◯◯◯
ObservationString(0) = "9"
ObservationString(1) = "10"
ObservationTensor(0): ◯◯◯◯◯◯◯◯◉◯
ObservationTensor(1): ◯◯◯◯◯◯◯◯◯◉
Rewards() = [0, 0]
Returns() = [0, 0]
LegalActions() = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
StringLegalActions() = ["Player 1 bid: 0", "Player 1 bid: 1", "Player 1 bid: 2", "Player 1 bid: 3", "Player 1 bid: 4", "Player 1 bid: 5", "Player 1 bid: 6", "Player 1 bid: 7", "Player 1 bid: 8", "Player 1 bid: 9"]

# Apply action "Player 1 bid: 5"
action: 5

# State 4
# Apply action "Chose winner 1"
action: 1

# State 5
# 9,10;3,5;1
IsTerminal() = True
History() = [9, 10, 3, 5, 1]
HistoryString() = "9, 10, 3, 5, 1"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = -4
InformationStateString(0) = "p0 val 9 bid 3"
InformationStateString(1) = "p1 val 10 bid 5"
InformationStateTensor(0): ◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◉◯◯◯◯◯◯
InformationStateTensor(1): ◯◉◯◯◯◯◯◯◯◯◯◉◯◯◯◯◯◉◯◯◯◯
ObservationString(0) = "9"
ObservationString(1) = "10"
ObservationTensor(0): ◯◯◯◯◯◯◯◯◉◯
ObservationTensor(1): ◯◯◯◯◯◯◯◯◯◉
Rewards() = [0, 5]
Returns() = [0, 5]
