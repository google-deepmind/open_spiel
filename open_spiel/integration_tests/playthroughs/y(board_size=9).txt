game: y(board_size=9)

GameType.chance_mode = ChanceMode.DETERMINISTIC
GameType.dynamics = Dynamics.SEQUENTIAL
GameType.information = Information.PERFECT_INFORMATION
GameType.long_name = "Y Connection Game"
GameType.max_num_players = 2
GameType.min_num_players = 2
GameType.parameter_specification = ["ansi_color_output", "board_size"]
GameType.provides_information_state_string = True
GameType.provides_information_state_tensor = False
GameType.provides_observation_string = True
GameType.provides_observation_tensor = True
GameType.provides_factored_observation_string = False
GameType.reward_model = RewardModel.TERMINAL
GameType.short_name = "y"
GameType.utility = Utility.ZERO_SUM

NumDistinctActions() = 81
PolicyTensorShape() = [81]
MaxChanceOutcomes() = 0
GetParameters() = {ansi_color_output=False,board_size=9}
NumPlayers() = 2
MinUtility() = -1.0
MaxUtility() = 1.0
UtilitySum() = 0.0
ObservationTensorShape() = [3, 9, 9]
ObservationTensorLayout() = TensorLayout.CHW
ObservationTensorSize() = 243
MaxGameLength() = 45
ToString() = "y(board_size=9)"

# State 0
#   a b c d e f g h i
#  1 . . . . . . . . .
#   2 . . . . . . . .
#    3 . . . . . . .
#     4 . . . . . .
#      5 . . . . .
#       6 . . . .
#        7 . . .
#         8 . .
#          9 .
IsTerminal() = False
History() = []
HistoryString() = ""
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = ""
InformationStateString(1) = ""
ObservationString(0) = "  a b c d e f g h i\n 1 . . . . . . . . .\n  2 . . . . . . . .\n   3 . . . . . . .\n    4 . . . . . .\n     5 . . . . .\n      6 . . . .\n       7 . . .\n        8 . .\n         9 .\n"
ObservationString(1) = "  a b c d e f g h i\n 1 . . . . . . . . .\n  2 . . . . . . . .\n   3 . . . . . . .\n    4 . . . . . .\n     5 . . . . .\n      6 . . . .\n       7 . . .\n        8 . .\n         9 .\n"
ObservationTensor(0):
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◉
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◉
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 36, 37, 38, 39, 40, 45, 46, 47, 48, 54, 55, 56, 63, 64, 72]
StringLegalActions() = ["a1", "b1", "c1", "d1", "e1", "f1", "g1", "h1", "i1", "a2", "b2", "c2", "d2", "e2", "f2", "g2", "h2", "a3", "b3", "c3", "d3", "e3", "f3", "g3", "a4", "b4", "c4", "d4", "e4", "f4", "a5", "b5", "c5", "d5", "e5", "a6", "b6", "c6", "d6", "a7", "b7", "c7", "a8", "b8", "a9"]

# Apply action "b1"
action: 1

# State 1
#   a b c d e f g h i
#  1 .[O]. . . . . . .
#   2 . . . . . . . .
#    3 . . . . . . .
#     4 . . . . . .
#      5 . . . . .
#       6 . . . .
#        7 . . .
#         8 . .
#          9 .
IsTerminal() = False
History() = [1]
HistoryString() = "1"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "1"
InformationStateString(1) = "1"
ObservationString(0) = "  a b c d e f g h i\n 1 .[O]. . . . . . .\n  2 . . . . . . . .\n   3 . . . . . . .\n    4 . . . . . .\n     5 . . . . .\n      6 . . . .\n       7 . . .\n        8 . .\n         9 .\n"
ObservationString(1) = "  a b c d e f g h i\n 1 .[O]. . . . . . .\n  2 . . . . . . . .\n   3 . . . . . . .\n    4 . . . . . .\n     5 . . . . .\n      6 . . . .\n       7 . . .\n        8 . .\n         9 .\n"
ObservationTensor(0):
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◉◉◉◉◉◉◉
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◉◉◉◉◉◉◉
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 36, 37, 38, 39, 40, 45, 46, 47, 48, 54, 55, 56, 63, 64, 72]
StringLegalActions() = ["a1", "c1", "d1", "e1", "f1", "g1", "h1", "i1", "a2", "b2", "c2", "d2", "e2", "f2", "g2", "h2", "a3", "b3", "c3", "d3", "e3", "f3", "g3", "a4", "b4", "c4", "d4", "e4", "f4", "a5", "b5", "c5", "d5", "e5", "a6", "b6", "c6", "d6", "a7", "b7", "c7", "a8", "b8", "a9"]

# Apply action "f4"
action: 32

# State 2
#   a b c d e f g h i
#  1 . O . . . . . . .
#   2 . . . . . . . .
#    3 . . . . . . .
#     4 . . . . .[@]
#      5 . . . . .
#       6 . . . .
#        7 . . .
#         8 . .
#          9 .
IsTerminal() = False
History() = [1, 32]
HistoryString() = "1, 32"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "1, 32"
InformationStateString(1) = "1, 32"
ObservationString(0) = "  a b c d e f g h i\n 1 . O . . . . . . .\n  2 . . . . . . . .\n   3 . . . . . . .\n    4 . . . . .[@]\n     5 . . . . .\n      6 . . . .\n       7 . . .\n        8 . .\n         9 .\n"
ObservationString(1) = "  a b c d e f g h i\n 1 . O . . . . . . .\n  2 . . . . . . . .\n   3 . . . . . . .\n    4 . . . . .[@]\n     5 . . . . .\n      6 . . . .\n       7 . . .\n        8 . .\n         9 .\n"
ObservationTensor(0):
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◉◉◉◉◉◉◉
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯◯  ◉◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◉◉◉◉◉◉◉
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◯◯
◯◯◯◯◯◉◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 36, 37, 38, 39, 40, 45, 46, 47, 48, 54, 55, 56, 63, 64, 72]
StringLegalActions() = ["a1", "c1", "d1", "e1", "f1", "g1", "h1", "i1", "a2", "b2", "c2", "d2", "e2", "f2", "g2", "h2", "a3", "b3", "c3", "d3", "e3", "f3", "g3", "a4", "b4", "c4", "d4", "e4", "a5", "b5", "c5", "d5", "e5", "a6", "b6", "c6", "d6", "a7", "b7", "c7", "a8", "b8", "a9"]

# Apply action "g1"
action: 6

# State 3
#   a b c d e f g h i
#  1 . O . . . .[O]. .
#   2 . . . . . . . .
#    3 . . . . . . .
#     4 . . . . . @
#      5 . . . . .
#       6 . . . .
#        7 . . .
#         8 . .
#          9 .
IsTerminal() = False
History() = [1, 32, 6]
HistoryString() = "1, 32, 6"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "1, 32, 6"
InformationStateString(1) = "1, 32, 6"
ObservationString(0) = "  a b c d e f g h i\n 1 . O . . . .[O]. .\n  2 . . . . . . . .\n   3 . . . . . . .\n    4 . . . . . @\n     5 . . . . .\n      6 . . . .\n       7 . . .\n        8 . .\n         9 .\n"
ObservationString(1) = "  a b c d e f g h i\n 1 . O . . . .[O]. .\n  2 . . . . . . . .\n   3 . . . . . . .\n    4 . . . . . @\n     5 . . . . .\n      6 . . . .\n       7 . . .\n        8 . .\n         9 .\n"
ObservationTensor(0):
◯◉◯◯◯◯◉◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◉◉◉◉◯◉◉
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯◯  ◉◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◉◯◯  ◉◯◉◉◉◉◯◉◉
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◯◯
◯◯◯◯◯◉◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 36, 37, 38, 39, 40, 45, 46, 47, 48, 54, 55, 56, 63, 64, 72]
StringLegalActions() = ["a1", "c1", "d1", "e1", "f1", "h1", "i1", "a2", "b2", "c2", "d2", "e2", "f2", "g2", "h2", "a3", "b3", "c3", "d3", "e3", "f3", "g3", "a4", "b4", "c4", "d4", "e4", "a5", "b5", "c5", "d5", "e5", "a6", "b6", "c6", "d6", "a7", "b7", "c7", "a8", "b8", "a9"]

# Apply action "f1"
action: 5

# State 4
#   a b c d e f g h i
#  1 . O . . .[@]O . .
#   2 . . . . . . . .
#    3 . . . . . . .
#     4 . . . . . @
#      5 . . . . .
#       6 . . . .
#        7 . . .
#         8 . .
#          9 .
IsTerminal() = False
History() = [1, 32, 6, 5]
HistoryString() = "1, 32, 6, 5"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "1, 32, 6, 5"
InformationStateString(1) = "1, 32, 6, 5"
ObservationString(0) = "  a b c d e f g h i\n 1 . O . . .[@]O . .\n  2 . . . . . . . .\n   3 . . . . . . .\n    4 . . . . . @\n     5 . . . . .\n      6 . . . .\n       7 . . .\n        8 . .\n         9 .\n"
ObservationString(1) = "  a b c d e f g h i\n 1 . O . . .[@]O . .\n  2 . . . . . . . .\n   3 . . . . . . .\n    4 . . . . . @\n     5 . . . . .\n      6 . . . .\n       7 . . .\n        8 . .\n         9 .\n"
ObservationTensor(0):
◯◉◯◯◯◯◉◯◯  ◯◯◯◯◯◉◯◯◯  ◉◯◉◉◉◯◯◉◉
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯◯  ◉◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◉◯◯◯  ◯◉◯◯◯◯◉◯◯  ◉◯◉◉◉◯◯◉◉
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◯◯
◯◯◯◯◯◉◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 36, 37, 38, 39, 40, 45, 46, 47, 48, 54, 55, 56, 63, 64, 72]
StringLegalActions() = ["a1", "c1", "d1", "e1", "h1", "i1", "a2", "b2", "c2", "d2", "e2", "f2", "g2", "h2", "a3", "b3", "c3", "d3", "e3", "f3", "g3", "a4", "b4", "c4", "d4", "e4", "a5", "b5", "c5", "d5", "e5", "a6", "b6", "c6", "d6", "a7", "b7", "c7", "a8", "b8", "a9"]

# Apply action "h1"
action: 7

# State 5
#   a b c d e f g h i
#  1 . O . . . @ O[O].
#   2 . . . . . . . .
#    3 . . . . . . .
#     4 . . . . . @
#      5 . . . . .
#       6 . . . .
#        7 . . .
#         8 . .
#          9 .
IsTerminal() = False
History() = [1, 32, 6, 5, 7]
HistoryString() = "1, 32, 6, 5, 7"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "1, 32, 6, 5, 7"
InformationStateString(1) = "1, 32, 6, 5, 7"
ObservationString(0) = "  a b c d e f g h i\n 1 . O . . . @ O[O].\n  2 . . . . . . . .\n   3 . . . . . . .\n    4 . . . . . @\n     5 . . . . .\n      6 . . . .\n       7 . . .\n        8 . .\n         9 .\n"
ObservationString(1) = "  a b c d e f g h i\n 1 . O . . . @ O[O].\n  2 . . . . . . . .\n   3 . . . . . . .\n    4 . . . . . @\n     5 . . . . .\n      6 . . . .\n       7 . . .\n        8 . .\n         9 .\n"
ObservationTensor(0):
◯◉◯◯◯◯◉◉◯  ◯◯◯◯◯◉◯◯◯  ◉◯◉◉◉◯◯◯◉
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◉◯◯◯  ◉◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◉◯◯◯  ◯◉◯◯◯◯◉◉◯  ◉◯◉◉◉◯◯◯◉
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◯◯
◯◯◯◯◯◉◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 36, 37, 38, 39, 40, 45, 46, 47, 48, 54, 55, 56, 63, 64, 72]
StringLegalActions() = ["a1", "c1", "d1", "e1", "i1", "a2", "b2", "c2", "d2", "e2", "f2", "g2", "h2", "a3", "b3", "c3", "d3", "e3", "f3", "g3", "a4", "b4", "c4", "d4", "e4", "a5", "b5", "c5", "d5", "e5", "a6", "b6", "c6", "d6", "a7", "b7", "c7", "a8", "b8", "a9"]

# Apply action "c2"
action: 11

# State 6
# Apply action "a3"
action: 18

# State 7
# Apply action "b8"
action: 64

# State 8
# Apply action "g3"
action: 24

# State 9
# Apply action "b5"
action: 37

# State 10
# Apply action "d4"
action: 30

# State 11
# Apply action "a2"
action: 9

# State 12
# Apply action "e4"
action: 31

# State 13
# Apply action "b6"
action: 46

# State 14
# Apply action "a5"
action: 36

# State 15
# Apply action "b7"
action: 55

# State 16
# Apply action "b4"
action: 28

# State 17
# Apply action "i1"
action: 8

# State 18
# Apply action "e5"
action: 40

# State 19
# Apply action "h2"
action: 16

# State 20
#   a b c d e f g h i
#  1 . O . . . @ O O @
#   2 @ . @ . . . .[@]
#    3 O . . . . . O
#     4 . O . O O @
#      5 O @ . . O
#       6 . @ . .
#        7 . @ .
#         8 . @
#          9 .
IsTerminal() = False
History() = [1, 32, 6, 5, 7, 11, 18, 64, 24, 37, 30, 9, 31, 46, 36, 55, 28, 8, 40, 16]
HistoryString() = "1, 32, 6, 5, 7, 11, 18, 64, 24, 37, 30, 9, 31, 46, 36, 55, 28, 8, 40, 16"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "1, 32, 6, 5, 7, 11, 18, 64, 24, 37, 30, 9, 31, 46, 36, 55, 28, 8, 40, 16"
InformationStateString(1) = "1, 32, 6, 5, 7, 11, 18, 64, 24, 37, 30, 9, 31, 46, 36, 55, 28, 8, 40, 16"
ObservationString(0) = "  a b c d e f g h i\n 1 . O . . . @ O O @\n  2 @ . @ . . . .[@]\n   3 O . . . . . O\n    4 . O . O O @\n     5 O @ . . O\n      6 . @ . .\n       7 . @ .\n        8 . @\n         9 .\n"
ObservationString(1) = "  a b c d e f g h i\n 1 . O . . . @ O O @\n  2 @ . @ . . . .[@]\n   3 O . . . . . O\n    4 . O . O O @\n     5 O @ . . O\n      6 . @ . .\n       7 . @ .\n        8 . @\n         9 .\n"
ObservationTensor(0):
◯◉◯◯◯◯◉◉◯  ◯◯◯◯◯◉◯◯◉  ◉◯◉◉◉◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◉◯◉◯◯◯◯◉◯  ◯◉◯◉◉◉◉◯◯
◉◯◯◯◯◯◉◯◯  ◯◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◯◯◯
◯◉◯◉◉◯◯◯◯  ◯◯◯◯◯◉◯◯◯  ◉◯◉◯◯◯◯◯◯
◉◯◯◯◉◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◯◯◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◉◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◉◯◯◉  ◯◉◯◯◯◯◉◉◯  ◉◯◉◉◉◯◯◯◯
◉◯◉◯◯◯◯◉◯  ◯◯◯◯◯◯◯◯◯  ◯◉◯◉◉◉◉◯◯
◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◉◯◯  ◯◉◉◉◉◉◯◯◯
◯◯◯◯◯◉◯◯◯  ◯◉◯◉◉◯◯◯◯  ◉◯◉◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◉◯◯◯◉◯◯◯◯  ◯◯◉◉◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◉◉◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◉◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 4, 10, 12, 13, 14, 15, 19, 20, 21, 22, 23, 27, 29, 38, 39, 45, 47, 48, 54, 56, 63, 72]
StringLegalActions() = ["a1", "c1", "d1", "e1", "b2", "d2", "e2", "f2", "g2", "b3", "c3", "d3", "e3", "f3", "a4", "c4", "c5", "d5", "a6", "c6", "d6", "a7", "c7", "a8", "a9"]

# Apply action "e1"
action: 4

# State 21
#   a b c d e f g h i
#  1 . O . .[O]@ O O @
#   2 @ . @ . . . . @
#    3 O . . . . . O
#     4 . O . O O @
#      5 O @ . . O
#       6 . @ . .
#        7 . @ .
#         8 . @
#          9 .
IsTerminal() = False
History() = [1, 32, 6, 5, 7, 11, 18, 64, 24, 37, 30, 9, 31, 46, 36, 55, 28, 8, 40, 16, 4]
HistoryString() = "1, 32, 6, 5, 7, 11, 18, 64, 24, 37, 30, 9, 31, 46, 36, 55, 28, 8, 40, 16, 4"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "1, 32, 6, 5, 7, 11, 18, 64, 24, 37, 30, 9, 31, 46, 36, 55, 28, 8, 40, 16, 4"
InformationStateString(1) = "1, 32, 6, 5, 7, 11, 18, 64, 24, 37, 30, 9, 31, 46, 36, 55, 28, 8, 40, 16, 4"
ObservationString(0) = "  a b c d e f g h i\n 1 . O . .[O]@ O O @\n  2 @ . @ . . . . @\n   3 O . . . . . O\n    4 . O . O O @\n     5 O @ . . O\n      6 . @ . .\n       7 . @ .\n        8 . @\n         9 .\n"
ObservationString(1) = "  a b c d e f g h i\n 1 . O . .[O]@ O O @\n  2 @ . @ . . . . @\n   3 O . . . . . O\n    4 . O . O O @\n     5 O @ . . O\n      6 . @ . .\n       7 . @ .\n        8 . @\n         9 .\n"
ObservationTensor(0):
◯◉◯◯◉◯◉◉◯  ◯◯◯◯◯◉◯◯◉  ◉◯◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◉◯◉◯◯◯◯◉◯  ◯◉◯◉◉◉◉◯◯
◉◯◯◯◯◯◉◯◯  ◯◯◯◯◯◯◯◯◯  ◯◉◉◉◉◉◯◯◯
◯◉◯◉◉◯◯◯◯  ◯◯◯◯◯◉◯◯◯  ◉◯◉◯◯◯◯◯◯
◉◯◯◯◉◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◯◯◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◉◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◉◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◉◯◯◉  ◯◉◯◯◉◯◉◉◯  ◉◯◉◉◯◯◯◯◯
◉◯◉◯◯◯◯◉◯  ◯◯◯◯◯◯◯◯◯  ◯◉◯◉◉◉◉◯◯
◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◉◯◯  ◯◉◉◉◉◉◯◯◯
◯◯◯◯◯◉◯◯◯  ◯◉◯◉◉◯◯◯◯  ◉◯◉◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◉◯◯◯◉◯◯◯◯  ◯◯◉◉◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◉◉◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◉◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 2, 3, 10, 12, 13, 14, 15, 19, 20, 21, 22, 23, 27, 29, 38, 39, 45, 47, 48, 54, 56, 63, 72]
StringLegalActions() = ["a1", "c1", "d1", "b2", "d2", "e2", "f2", "g2", "b3", "c3", "d3", "e3", "f3", "a4", "c4", "c5", "d5", "a6", "c6", "d6", "a7", "c7", "a8", "a9"]

# Apply action "e3"
action: 22

# State 22
# Apply action "c4"
action: 29

# State 23
# Apply action "a9"
action: 72

# State 24
# Apply action "a8"
action: 63

# State 25
# Apply action "d2"
action: 12

# State 26
# Apply action "d3"
action: 21

# State 27
# Apply action "g2"
action: 15

# State 28
# Apply action "c5"
action: 38

# State 29
# Apply action "a4"
action: 27

# State 30
# Apply action "f2"
action: 14

# State 31
# Apply action "a6"
action: 45

# State 32
# Apply action "c1"
action: 2

# State 33
# Apply action "a7"
action: 54

# State 34
# Apply action "d1"
action: 3

# State 35
# Apply action "c7"
action: 56

# State 36
# Apply action "b2"
action: 10

# State 37
# Apply action "b3"
action: 19

# State 38
# Apply action "c6"
action: 47

# State 39
# Apply action "a1"
action: 0

# State 40
#   a b c d e f g h i
#  1[@]O O O O @ O O @
#   2 @ O @ @ . O @ @
#    3 O @ . O @ . O
#     4 @ O O O O @
#      5 O @ O . O
#       6 @ @ O .
#        7 @ @ @
#         8 O @
#          9 @
IsTerminal() = False
History() = [1, 32, 6, 5, 7, 11, 18, 64, 24, 37, 30, 9, 31, 46, 36, 55, 28, 8, 40, 16, 4, 22, 29, 72, 63, 12, 21, 15, 38, 27, 14, 45, 2, 54, 3, 56, 10, 19, 47, 0]
HistoryString() = "1, 32, 6, 5, 7, 11, 18, 64, 24, 37, 30, 9, 31, 46, 36, 55, 28, 8, 40, 16, 4, 22, 29, 72, 63, 12, 21, 15, 38, 27, 14, 45, 2, 54, 3, 56, 10, 19, 47, 0"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "1, 32, 6, 5, 7, 11, 18, 64, 24, 37, 30, 9, 31, 46, 36, 55, 28, 8, 40, 16, 4, 22, 29, 72, 63, 12, 21, 15, 38, 27, 14, 45, 2, 54, 3, 56, 10, 19, 47, 0"
InformationStateString(1) = "1, 32, 6, 5, 7, 11, 18, 64, 24, 37, 30, 9, 31, 46, 36, 55, 28, 8, 40, 16, 4, 22, 29, 72, 63, 12, 21, 15, 38, 27, 14, 45, 2, 54, 3, 56, 10, 19, 47, 0"
ObservationString(0) = "  a b c d e f g h i\n 1[@]O O O O @ O O @\n  2 @ O @ @ . O @ @\n   3 O @ . O @ . O\n    4 @ O O O O @\n     5 O @ O . O\n      6 @ @ O .\n       7 @ @ @\n        8 O @\n         9 @\n"
ObservationString(1) = "  a b c d e f g h i\n 1[@]O O O O @ O O @\n  2 @ O @ @ . O @ @\n   3 O @ . O @ . O\n    4 @ O O O O @\n     5 O @ O . O\n      6 @ @ O .\n       7 @ @ @\n        8 O @\n         9 @\n"
ObservationTensor(0):
◯◉◉◉◉◯◉◉◯  ◉◯◯◯◯◉◯◯◉  ◯◯◯◯◯◯◯◯◯
◯◉◯◯◯◉◯◯◯  ◉◯◉◉◯◯◉◉◯  ◯◯◯◯◉◯◯◯◯
◉◯◯◉◯◯◉◯◯  ◯◉◯◯◉◯◯◯◯  ◯◯◉◯◯◉◯◯◯
◯◉◉◉◉◯◯◯◯  ◉◯◯◯◯◉◯◯◯  ◯◯◯◯◯◯◯◯◯
◉◯◉◯◉◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◯◯◯◉◯◯◯◯◯
◯◯◉◯◯◯◯◯◯  ◉◉◯◯◯◯◯◯◯  ◯◯◯◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◉◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◯◯◯◯◉◯◯◉  ◯◉◉◉◉◯◉◉◯  ◯◯◯◯◯◯◯◯◯
◉◯◉◉◯◯◉◉◯  ◯◉◯◯◯◉◯◯◯  ◯◯◯◯◉◯◯◯◯
◯◉◯◯◉◯◯◯◯  ◉◯◯◉◯◯◉◯◯  ◯◯◉◯◯◉◯◯◯
◉◯◯◯◯◉◯◯◯  ◯◉◉◉◉◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◉◯◉◯◉◯◯◯◯  ◯◯◯◉◯◯◯◯◯
◉◉◯◯◯◯◯◯◯  ◯◯◉◯◯◯◯◯◯  ◯◯◯◉◯◯◯◯◯
◉◉◉◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [13, 20, 23, 39, 48]
StringLegalActions() = ["e2", "c3", "f3", "d5", "d6"]

# Apply action "f3"
action: 23

# State 41
#   a b c d e f g h i
#  1 @ O O O O @ O O @
#   2 @ O @ @ . O @ @
#    3 O @ . O @[O]O
#     4 @ O O O O @
#      5 O @ O . O
#       6 @ @ O .
#        7 @ @ @
#         8 O @
#          9 @
IsTerminal() = True
History() = [1, 32, 6, 5, 7, 11, 18, 64, 24, 37, 30, 9, 31, 46, 36, 55, 28, 8, 40, 16, 4, 22, 29, 72, 63, 12, 21, 15, 38, 27, 14, 45, 2, 54, 3, 56, 10, 19, 47, 0, 23]
HistoryString() = "1, 32, 6, 5, 7, 11, 18, 64, 24, 37, 30, 9, 31, 46, 36, 55, 28, 8, 40, 16, 4, 22, 29, 72, 63, 12, 21, 15, 38, 27, 14, 45, 2, 54, 3, 56, 10, 19, 47, 0, 23"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = -4
InformationStateString(0) = "1, 32, 6, 5, 7, 11, 18, 64, 24, 37, 30, 9, 31, 46, 36, 55, 28, 8, 40, 16, 4, 22, 29, 72, 63, 12, 21, 15, 38, 27, 14, 45, 2, 54, 3, 56, 10, 19, 47, 0, 23"
InformationStateString(1) = "1, 32, 6, 5, 7, 11, 18, 64, 24, 37, 30, 9, 31, 46, 36, 55, 28, 8, 40, 16, 4, 22, 29, 72, 63, 12, 21, 15, 38, 27, 14, 45, 2, 54, 3, 56, 10, 19, 47, 0, 23"
ObservationString(0) = "  a b c d e f g h i\n 1 @ O O O O @ O O @\n  2 @ O @ @ . O @ @\n   3 O @ . O @[O]O\n    4 @ O O O O @\n     5 O @ O . O\n      6 @ @ O .\n       7 @ @ @\n        8 O @\n         9 @\n"
ObservationString(1) = "  a b c d e f g h i\n 1 @ O O O O @ O O @\n  2 @ O @ @ . O @ @\n   3 O @ . O @[O]O\n    4 @ O O O O @\n     5 O @ O . O\n      6 @ @ O .\n       7 @ @ @\n        8 O @\n         9 @\n"
ObservationTensor(0):
◯◉◉◉◉◯◉◉◯  ◉◯◯◯◯◉◯◯◉  ◯◯◯◯◯◯◯◯◯
◯◉◯◯◯◉◯◯◯  ◉◯◉◉◯◯◉◉◯  ◯◯◯◯◉◯◯◯◯
◉◯◯◉◯◉◉◯◯  ◯◉◯◯◉◯◯◯◯  ◯◯◉◯◯◯◯◯◯
◯◉◉◉◉◯◯◯◯  ◉◯◯◯◯◉◯◯◯  ◯◯◯◯◯◯◯◯◯
◉◯◉◯◉◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◯◯◯◉◯◯◯◯◯
◯◯◉◯◯◯◯◯◯  ◉◉◯◯◯◯◯◯◯  ◯◯◯◉◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◉◉◉◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◉◯◯◯◯◯◯◯◯  ◯◉◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
ObservationTensor(1):
◉◯◯◯◯◉◯◯◉  ◯◉◉◉◉◯◉◉◯  ◯◯◯◯◯◯◯◯◯
◉◯◉◉◯◯◉◉◯  ◯◉◯◯◯◉◯◯◯  ◯◯◯◯◉◯◯◯◯
◯◉◯◯◉◯◯◯◯  ◉◯◯◉◯◉◉◯◯  ◯◯◉◯◯◯◯◯◯
◉◯◯◯◯◉◯◯◯  ◯◉◉◉◉◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◉◯◉◯◉◯◯◯◯  ◯◯◯◉◯◯◯◯◯
◉◉◯◯◯◯◯◯◯  ◯◯◉◯◯◯◯◯◯  ◯◯◯◉◯◯◯◯◯
◉◉◉◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◉◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
Rewards() = [1.0, -1.0]
Returns() = [1.0, -1.0]
