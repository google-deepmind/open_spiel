game: quoridor(board_size=5)

GameType.chance_mode = ChanceMode.DETERMINISTIC
GameType.dynamics = Dynamics.SEQUENTIAL
GameType.information = Information.PERFECT_INFORMATION
GameType.long_name = "Quoridor"
GameType.max_num_players = 4
GameType.min_num_players = 2
GameType.parameter_specification = ["ansi_color_output", "board_size", "players", "wall_count"]
GameType.provides_information_state_string = True
GameType.provides_information_state_tensor = False
GameType.provides_observation_string = True
GameType.provides_observation_tensor = True
GameType.provides_factored_observation_string = False
GameType.reward_model = RewardModel.TERMINAL
GameType.short_name = "quoridor"
GameType.utility = Utility.ZERO_SUM

NumDistinctActions() = 81
PolicyTensorShape() = [81]
MaxChanceOutcomes() = 0
GetParameters() = {ansi_color_output=False,board_size=5,players=2,wall_count=3}
NumPlayers() = 2
MinUtility() = -1.0
MaxUtility() = 1.0
UtilitySum() = 0.0
ObservationTensorShape() = [5, 9, 9]
ObservationTensorLayout() = TensorLayout.CHW
ObservationTensorSize() = 405
MaxGameLength() = 100
ToString() = "quoridor(board_size=5)"

# State 0
# Board size: 5, walls: 3, 3
#    a   b   c   d   e
#  1 .   .   @   .   .  1
#
#  2 .   .   .   .   .  2
#
#  3 .   .   .   .   .  3
#
#  4 .   .   .   .   .  4
#
#  5 .   .   0   .   .  5
#    a   b   c   d   e
IsTerminal() = False
History() = []
HistoryString() = ""
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = ""
InformationStateString(1) = ""
ObservationString(0) = "Board size: 5, walls: 3, 3\n   a   b   c   d   e\n 1 .   .   @   .   .  1\n                       \n 2 .   .   .   .   .  2\n                       \n 3 .   .   .   .   .  3\n                       \n 4 .   .   .   .   .  4\n                       \n 5 .   .   0   .   .  5\n   a   b   c   d   e\n"
ObservationString(1) = "Board size: 5, walls: 3, 3\n   a   b   c   d   e\n 1 .   .   @   .   .  1\n                       \n 2 .   .   .   .   .  2\n                       \n 3 .   .   .   .   .  3\n                       \n 4 .   .   .   .   .  4\n                       \n 5 .   .   0   .   .  5\n   a   b   c   d   e\n"
ObservationTensor(0) = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0]
ObservationTensor(1) = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [1, 3, 5, 7, 9, 11, 13, 15, 19, 21, 23, 25, 27, 29, 31, 33, 37, 39, 41, 43, 45, 47, 49, 51, 55, 57, 58, 59, 61, 63, 65, 67, 69, 74, 78]
StringLegalActions() = ["a1v", "b1v", "c1v", "d1v", "a1h", "b1h", "c1h", "d1h", "a2v", "b2v", "c2v", "d2v", "a2h", "b2h", "c2h", "d2h", "a3v", "b3v", "c3v", "d3v", "a3h", "b3h", "c3h", "d3h", "a4v", "b4v", "c4", "c4v", "d4v", "a4h", "b4h", "c4h", "d4h", "b5", "d5"]

# Apply action "a4h"
action: 63

# State 1
# Board size: 5, walls: 2, 3
#    a   b   c   d   e
#  1 .   .   @   .   .  1
#
#  2 .   .   .   .   .  2
#
#  3 .   .   .   .   .  3
#
#  4 .   .   .   .   .  4
#   ---+---
#  5 .   .   0   .   .  5
#    a   b   c   d   e
IsTerminal() = False
History() = [63]
HistoryString() = "63"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "63"
InformationStateString(1) = "63"
ObservationString(0) = "Board size: 5, walls: 2, 3\n   a   b   c   d   e\n 1 .   .   @   .   .  1\n                       \n 2 .   .   .   .   .  2\n                       \n 3 .   .   .   .   .  3\n                       \n 4 .   .   .   .   .  4\n  ---+---              \n 5 .   .   0   .   .  5\n   a   b   c   d   e\n"
ObservationString(1) = "Board size: 5, walls: 2, 3\n   a   b   c   d   e\n 1 .   .   @   .   .  1\n                       \n 2 .   .   .   .   .  2\n                       \n 3 .   .   .   .   .  3\n                       \n 4 .   .   .   .   .  4\n  ---+---              \n 5 .   .   0   .   .  5\n   a   b   c   d   e\n"
ObservationTensor(0) = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0]
ObservationTensor(1) = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [1, 2, 3, 5, 6, 7, 9, 11, 13, 15, 19, 21, 22, 23, 25, 27, 29, 31, 33, 37, 39, 41, 43, 45, 47, 49, 51, 57, 59, 61, 67, 69]
StringLegalActions() = ["a1v", "b1", "b1v", "c1v", "d1", "d1v", "a1h", "b1h", "c1h", "d1h", "a2v", "b2v", "c2", "c2v", "d2v", "a2h", "b2h", "c2h", "d2h", "a3v", "b3v", "c3v", "d3v", "a3h", "b3h", "c3h", "d3h", "b4v", "c4v", "d4v", "c4h", "d4h"]

# Apply action "c4v"
action: 59

# State 2
# Board size: 5, walls: 2, 2
#    a   b   c   d   e
#  1 .   .   @   .   .  1
#
#  2 .   .   .   .   .  2
#
#  3 .   .   .   .   .  3
#
#  4 .   .   . | .   .  4
#   ---+---    +
#  5 .   .   0 | .   .  5
#    a   b   c   d   e
IsTerminal() = False
History() = [63, 59]
HistoryString() = "63, 59"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "63, 59"
InformationStateString(1) = "63, 59"
ObservationString(0) = "Board size: 5, walls: 2, 2\n   a   b   c   d   e\n 1 .   .   @   .   .  1\n                       \n 2 .   .   .   .   .  2\n                       \n 3 .   .   .   .   .  3\n                       \n 4 .   .   . | .   .  4\n  ---+---    +         \n 5 .   .   0 | .   .  5\n   a   b   c   d   e\n"
ObservationString(1) = "Board size: 5, walls: 2, 2\n   a   b   c   d   e\n 1 .   .   @   .   .  1\n                       \n 2 .   .   .   .   .  2\n                       \n 3 .   .   .   .   .  3\n                       \n 4 .   .   . | .   .  4\n  ---+---    +         \n 5 .   .   0 | .   .  5\n   a   b   c   d   e\n"
ObservationTensor(0) = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0]
ObservationTensor(1) = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [1, 3, 5, 7, 9, 11, 13, 15, 19, 21, 23, 25, 27, 29, 31, 33, 37, 39, 43, 45, 47, 49, 51, 57, 58, 61, 69, 74]
StringLegalActions() = ["a1v", "b1v", "c1v", "d1v", "a1h", "b1h", "c1h", "d1h", "a2v", "b2v", "c2v", "d2v", "a2h", "b2h", "c2h", "d2h", "a3v", "b3v", "d3v", "a3h", "b3h", "c3h", "d3h", "b4v", "c4", "d4v", "d4h", "b5"]

# Apply action "d1v"
action: 7

# State 3
# Board size: 5, walls: 1, 2
#    a   b   c   d   e
#  1 .   .   @   . | .  1
#                  +
#  2 .   .   .   . | .  2
#
#  3 .   .   .   .   .  3
#
#  4 .   .   . | .   .  4
#   ---+---    +
#  5 .   .   0 | .   .  5
#    a   b   c   d   e
IsTerminal() = False
History() = [63, 59, 7]
HistoryString() = "63, 59, 7"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "63, 59, 7"
InformationStateString(1) = "63, 59, 7"
ObservationString(0) = "Board size: 5, walls: 1, 2\n   a   b   c   d   e\n 1 .   .   @   . | .  1\n                 +     \n 2 .   .   .   . | .  2\n                       \n 3 .   .   .   .   .  3\n                       \n 4 .   .   . | .   .  4\n  ---+---    +         \n 5 .   .   0 | .   .  5\n   a   b   c   d   e\n"
ObservationString(1) = "Board size: 5, walls: 1, 2\n   a   b   c   d   e\n 1 .   .   @   . | .  1\n                 +     \n 2 .   .   .   . | .  2\n                       \n 3 .   .   .   .   .  3\n                       \n 4 .   .   . | .   .  4\n  ---+---    +         \n 5 .   .   0 | .   .  5\n   a   b   c   d   e\n"
ObservationTensor(0) = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0]
ObservationTensor(1) = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0]
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [1, 2, 3, 5, 6, 9, 11, 13, 19, 21, 22, 23, 27, 29, 31, 33, 37, 39, 43, 45, 47, 49, 51, 57, 61, 69]
StringLegalActions() = ["a1v", "b1", "b1v", "c1v", "d1", "a1h", "b1h", "c1h", "a2v", "b2v", "c2", "c2v", "a2h", "b2h", "c2h", "d2h", "a3v", "b3v", "d3v", "a3h", "b3h", "c3h", "d3h", "b4v", "d4v", "d4h"]

# Apply action "c3h"
action: 49

# State 4
# Board size: 5, walls: 1, 1
#    a   b   c   d   e
#  1 .   .   @   . | .  1
#                  +
#  2 .   .   .   . | .  2
#
#  3 .   .   .   .   .  3
#           ---+---
#  4 .   .   . | .   .  4
#   ---+---    +
#  5 .   .   0 | .   .  5
#    a   b   c   d   e
IsTerminal() = False
History() = [63, 59, 7, 49]
HistoryString() = "63, 59, 7, 49"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "63, 59, 7, 49"
InformationStateString(1) = "63, 59, 7, 49"
ObservationString(0) = "Board size: 5, walls: 1, 1\n   a   b   c   d   e\n 1 .   .   @   . | .  1\n                 +     \n 2 .   .   .   . | .  2\n                       \n 3 .   .   .   .   .  3\n          ---+---      \n 4 .   .   . | .   .  4\n  ---+---    +         \n 5 .   .   0 | .   .  5\n   a   b   c   d   e\n"
ObservationString(1) = "Board size: 5, walls: 1, 1\n   a   b   c   d   e\n 1 .   .   @   . | .  1\n                 +     \n 2 .   .   .   . | .  2\n                       \n 3 .   .   .   .   .  3\n          ---+---      \n 4 .   .   . | .   .  4\n  ---+---    +         \n 5 .   .   0 | .   .  5\n   a   b   c   d   e\n"
ObservationTensor(0):
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◉◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◉  ◉◉◉◉◉◉◉◉◉
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◉  ◉◉◉◉◉◉◉◉◉
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◉  ◉◉◉◉◉◉◉◉◉
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◉  ◉◉◉◉◉◉◉◉◉
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◉  ◉◉◉◉◉◉◉◉◉
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◉  ◉◉◉◉◉◉◉◉◉
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◉  ◉◉◉◉◉◉◉◉◉
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◉  ◉◉◉◉◉◉◉◉◉
◯◯◯◯◉◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◉  ◉◉◉◉◉◉◉◉◉
ObservationTensor(1):
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◉◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◉  ◉◉◉◉◉◉◉◉◉
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◉  ◉◉◉◉◉◉◉◉◉
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◉  ◉◉◉◉◉◉◉◉◉
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◉  ◉◉◉◉◉◉◉◉◉
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◉  ◉◉◉◉◉◉◉◉◉
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◉  ◉◉◉◉◉◉◉◉◉
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◉  ◉◉◉◉◉◉◉◉◉
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◉  ◉◉◉◉◉◉◉◉◉
◯◯◯◯◉◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◉  ◉◉◉◉◉◉◉◉◉
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [1, 3, 5, 9, 11, 13, 19, 21, 23, 27, 29, 31, 33, 37, 43, 58, 61, 69, 74]
StringLegalActions() = ["a1v", "b1v", "c1v", "a1h", "b1h", "c1h", "a2v", "b2v", "c2v", "a2h", "b2h", "c2h", "d2h", "a3v", "d3v", "c4", "d4v", "d4h", "b5"]

# Apply action "d4v"
action: 61

# State 5
# Board size: 5, walls: 0, 1
#    a   b   c   d   e
#  1 .   .   @   . | .  1
#                  +
#  2 .   .   .   . | .  2
#
#  3 .   .   .   .   .  3
#           ---+---
#  4 .   .   . | . | .  4
#   ---+---    +   +
#  5 .   .   0 | . | .  5
#    a   b   c   d   e
IsTerminal() = False
History() = [63, 59, 7, 49, 61]
HistoryString() = "63, 59, 7, 49, 61"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "63, 59, 7, 49, 61"
InformationStateString(1) = "63, 59, 7, 49, 61"
ObservationString(0) = "Board size: 5, walls: 0, 1\n   a   b   c   d   e\n 1 .   .   @   . | .  1\n                 +     \n 2 .   .   .   . | .  2\n                       \n 3 .   .   .   .   .  3\n          ---+---      \n 4 .   .   . | . | .  4\n  ---+---    +   +     \n 5 .   .   0 | . | .  5\n   a   b   c   d   e\n"
ObservationString(1) = "Board size: 5, walls: 0, 1\n   a   b   c   d   e\n 1 .   .   @   . | .  1\n                 +     \n 2 .   .   .   . | .  2\n                       \n 3 .   .   .   .   .  3\n          ---+---      \n 4 .   .   . | . | .  4\n  ---+---    +   +     \n 5 .   .   0 | . | .  5\n   a   b   c   d   e\n"
ObservationTensor(0):
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◉◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◉
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◉
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◉
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◉
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◉
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◉
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◉
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◉
◯◯◯◯◉◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◉
ObservationTensor(1):
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◉◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◉
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◉
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◉
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◉
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◉
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◉
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◉
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◉
◯◯◯◯◉◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◉◉◉◉◉◉◉◉◉
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [1, 2, 3, 5, 6, 9, 11, 13, 19, 21, 22, 23, 27, 29, 31, 33, 37]
StringLegalActions() = ["a1v", "b1", "b1v", "c1v", "d1", "a1h", "b1h", "c1h", "a2v", "b2v", "c2", "c2v", "a2h", "b2h", "c2h", "d2h", "a3v"]

# Apply action "c2h"
action: 31

# State 6
# Apply action "b5"
action: 74

# State 7
# Apply action "b1"
action: 2

# State 8
# Apply action "c5"
action: 76

# State 9
# Apply action "a1"
action: 0

# State 10
# Apply action "c4"
action: 58

# State 11
# Apply action "b1"
action: 2

# State 12
# Apply action "c5"
action: 76

# State 13
# Apply action "c1"
action: 4

# State 14
# Apply action "c4"
action: 58

# State 15
# Apply action "b1"
action: 2

# State 16
# Apply action "c5"
action: 76

# State 17
# Apply action "a1"
action: 0

# State 18
# Apply action "b5"
action: 74

# State 19
# Apply action "a2"
action: 18

# State 20
# Board size: 5, walls: 0, 0
#    a   b   c   d   e
#  1 .   .   .   . | .  1
#                  +
#  2 @   .   .   . | .  2
#           ---+---
#  3 .   .   .   .   .  3
#           ---+---
#  4 .   .   . | . | .  4
#   ---+---    +   +
#  5 .   0   . | . | .  5
#    a   b   c   d   e
IsTerminal() = False
History() = [63, 59, 7, 49, 61, 31, 74, 2, 76, 0, 58, 2, 76, 4, 58, 2, 76, 0, 74, 18]
HistoryString() = "63, 59, 7, 49, 61, 31, 74, 2, 76, 0, 58, 2, 76, 4, 58, 2, 76, 0, 74, 18"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "63, 59, 7, 49, 61, 31, 74, 2, 76, 0, 58, 2, 76, 4, 58, 2, 76, 0, 74, 18"
InformationStateString(1) = "63, 59, 7, 49, 61, 31, 74, 2, 76, 0, 58, 2, 76, 4, 58, 2, 76, 0, 74, 18"
ObservationString(0) = "Board size: 5, walls: 0, 0\n   a   b   c   d   e\n 1 .   .   .   . | .  1\n                 +     \n 2 @   .   .   . | .  2\n          ---+---      \n 3 .   .   .   .   .  3\n          ---+---      \n 4 .   .   . | . | .  4\n  ---+---    +   +     \n 5 .   0   . | . | .  5\n   a   b   c   d   e\n"
ObservationString(1) = "Board size: 5, walls: 0, 0\n   a   b   c   d   e\n 1 .   .   .   . | .  1\n                 +     \n 2 @   .   .   . | .  2\n          ---+---      \n 3 .   .   .   .   .  3\n          ---+---      \n 4 .   .   . | . | .  4\n  ---+---    +   +     \n 5 .   0   . | . | .  5\n   a   b   c   d   e\n"
ObservationTensor(0):
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◉◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◉◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [72, 76]
StringLegalActions() = ["a5", "c5"]

# Apply action "a5"
action: 72

# State 21
# Board size: 5, walls: 0, 0
#    a   b   c   d   e
#  1 .   .   .   . | .  1
#                  +
#  2 @   .   .   . | .  2
#           ---+---
#  3 .   .   .   .   .  3
#           ---+---
#  4 .   .   . | . | .  4
#   ---+---    +   +
#  5 0   .   . | . | .  5
#    a   b   c   d   e
IsTerminal() = False
History() = [63, 59, 7, 49, 61, 31, 74, 2, 76, 0, 58, 2, 76, 4, 58, 2, 76, 0, 74, 18, 72]
HistoryString() = "63, 59, 7, 49, 61, 31, 74, 2, 76, 0, 58, 2, 76, 4, 58, 2, 76, 0, 74, 18, 72"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "63, 59, 7, 49, 61, 31, 74, 2, 76, 0, 58, 2, 76, 4, 58, 2, 76, 0, 74, 18, 72"
InformationStateString(1) = "63, 59, 7, 49, 61, 31, 74, 2, 76, 0, 58, 2, 76, 4, 58, 2, 76, 0, 74, 18, 72"
ObservationString(0) = "Board size: 5, walls: 0, 0\n   a   b   c   d   e\n 1 .   .   .   . | .  1\n                 +     \n 2 @   .   .   . | .  2\n          ---+---      \n 3 .   .   .   .   .  3\n          ---+---      \n 4 .   .   . | . | .  4\n  ---+---    +   +     \n 5 0   .   . | . | .  5\n   a   b   c   d   e\n"
ObservationString(1) = "Board size: 5, walls: 0, 0\n   a   b   c   d   e\n 1 .   .   .   . | .  1\n                 +     \n 2 @   .   .   . | .  2\n          ---+---      \n 3 .   .   .   .   .  3\n          ---+---      \n 4 .   .   . | . | .  4\n  ---+---    +   +     \n 5 0   .   . | . | .  5\n   a   b   c   d   e\n"
ObservationTensor(0):
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 20, 36]
StringLegalActions() = ["a1", "b2", "a3"]

# Apply action "b2"
action: 20

# State 22
# Apply action "b5"
action: 74

# State 23
# Apply action "c2"
action: 22

# State 24
# Apply action "a5"
action: 72

# State 25
# Apply action "d2"
action: 24

# State 26
# Apply action "b5"
action: 74

# State 27
# Apply action "c2"
action: 22

# State 28
# Apply action "c5"
action: 76

# State 29
# Apply action "b2"
action: 20

# State 30
# Apply action "b5"
action: 74

# State 31
# Apply action "b3"
action: 38

# State 32
# Apply action "a5"
action: 72

# State 33
# Apply action "c3"
action: 40

# State 34
# Apply action "b5"
action: 74

# State 35
# Apply action "d3"
action: 42

# State 36
# Apply action "c5"
action: 76

# State 37
# Apply action "e3"
action: 44

# State 38
# Apply action "b5"
action: 74

# State 39
# Apply action "e4"
action: 62

# State 40
# Board size: 5, walls: 0, 0
#    a   b   c   d   e
#  1 .   .   .   . | .  1
#                  +
#  2 .   .   .   . | .  2
#           ---+---
#  3 .   .   .   .   .  3
#           ---+---
#  4 .   .   . | . | @  4
#   ---+---    +   +
#  5 .   0   . | . | .  5
#    a   b   c   d   e
IsTerminal() = False
History() = [63, 59, 7, 49, 61, 31, 74, 2, 76, 0, 58, 2, 76, 4, 58, 2, 76, 0, 74, 18, 72, 20, 74, 22, 72, 24, 74, 22, 76, 20, 74, 38, 72, 40, 74, 42, 76, 44, 74, 62]
HistoryString() = "63, 59, 7, 49, 61, 31, 74, 2, 76, 0, 58, 2, 76, 4, 58, 2, 76, 0, 74, 18, 72, 20, 74, 22, 72, 24, 74, 22, 76, 20, 74, 38, 72, 40, 74, 42, 76, 44, 74, 62"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "63, 59, 7, 49, 61, 31, 74, 2, 76, 0, 58, 2, 76, 4, 58, 2, 76, 0, 74, 18, 72, 20, 74, 22, 72, 24, 74, 22, 76, 20, 74, 38, 72, 40, 74, 42, 76, 44, 74, 62"
InformationStateString(1) = "63, 59, 7, 49, 61, 31, 74, 2, 76, 0, 58, 2, 76, 4, 58, 2, 76, 0, 74, 18, 72, 20, 74, 22, 72, 24, 74, 22, 76, 20, 74, 38, 72, 40, 74, 42, 76, 44, 74, 62"
ObservationString(0) = "Board size: 5, walls: 0, 0\n   a   b   c   d   e\n 1 .   .   .   . | .  1\n                 +     \n 2 .   .   .   . | .  2\n          ---+---      \n 3 .   .   .   .   .  3\n          ---+---      \n 4 .   .   . | . | @  4\n  ---+---    +   +     \n 5 .   0   . | . | .  5\n   a   b   c   d   e\n"
ObservationString(1) = "Board size: 5, walls: 0, 0\n   a   b   c   d   e\n 1 .   .   .   . | .  1\n                 +     \n 2 .   .   .   . | .  2\n          ---+---      \n 3 .   .   .   .   .  3\n          ---+---      \n 4 .   .   . | . | @  4\n  ---+---    +   +     \n 5 .   0   . | . | .  5\n   a   b   c   d   e\n"
ObservationTensor(0):
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◉  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◉◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◉  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◉◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [72, 76]
StringLegalActions() = ["a5", "c5"]

# Apply action "a5"
action: 72

# State 41
# Board size: 5, walls: 0, 0
#    a   b   c   d   e
#  1 .   .   .   . | .  1
#                  +
#  2 .   .   .   . | .  2
#           ---+---
#  3 .   .   .   .   .  3
#           ---+---
#  4 .   .   . | . | @  4
#   ---+---    +   +
#  5 0   .   . | . | .  5
#    a   b   c   d   e
IsTerminal() = False
History() = [63, 59, 7, 49, 61, 31, 74, 2, 76, 0, 58, 2, 76, 4, 58, 2, 76, 0, 74, 18, 72, 20, 74, 22, 72, 24, 74, 22, 76, 20, 74, 38, 72, 40, 74, 42, 76, 44, 74, 62, 72]
HistoryString() = "63, 59, 7, 49, 61, 31, 74, 2, 76, 0, 58, 2, 76, 4, 58, 2, 76, 0, 74, 18, 72, 20, 74, 22, 72, 24, 74, 22, 76, 20, 74, 38, 72, 40, 74, 42, 76, 44, 74, 62, 72"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "63, 59, 7, 49, 61, 31, 74, 2, 76, 0, 58, 2, 76, 4, 58, 2, 76, 0, 74, 18, 72, 20, 74, 22, 72, 24, 74, 22, 76, 20, 74, 38, 72, 40, 74, 42, 76, 44, 74, 62, 72"
InformationStateString(1) = "63, 59, 7, 49, 61, 31, 74, 2, 76, 0, 58, 2, 76, 4, 58, 2, 76, 0, 74, 18, 72, 20, 74, 22, 72, 24, 74, 22, 76, 20, 74, 38, 72, 40, 74, 42, 76, 44, 74, 62, 72"
ObservationString(0) = "Board size: 5, walls: 0, 0\n   a   b   c   d   e\n 1 .   .   .   . | .  1\n                 +     \n 2 .   .   .   . | .  2\n          ---+---      \n 3 .   .   .   .   .  3\n          ---+---      \n 4 .   .   . | . | @  4\n  ---+---    +   +     \n 5 0   .   . | . | .  5\n   a   b   c   d   e\n"
ObservationString(1) = "Board size: 5, walls: 0, 0\n   a   b   c   d   e\n 1 .   .   .   . | .  1\n                 +     \n 2 .   .   .   . | .  2\n          ---+---      \n 3 .   .   .   .   .  3\n          ---+---      \n 4 .   .   . | . | @  4\n  ---+---    +   +     \n 5 0   .   . | . | .  5\n   a   b   c   d   e\n"
ObservationTensor(0):
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◉  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◉  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◉◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [44, 80]
StringLegalActions() = ["e3", "e5"]

# Apply action "e3"
action: 44

# State 42
# Apply action "b5"
action: 74

# State 43
# Apply action "e2"
action: 26

# State 44
# Apply action "c5"
action: 76

# State 45
# Apply action "e1"
action: 8

# State 46
# Apply action "c4"
action: 58

# State 47
# Apply action "e2"
action: 26

# State 48
# Apply action "c5"
action: 76

# State 49
# Apply action "e1"
action: 8

# State 50
# Apply action "b5"
action: 74

# State 51
# Apply action "e2"
action: 26

# State 52
# Apply action "a5"
action: 72

# State 53
# Apply action "e3"
action: 44

# State 54
# Apply action "b5"
action: 74

# State 55
# Apply action "d3"
action: 42

# State 56
# Apply action "c5"
action: 76

# State 57
# Apply action "e3"
action: 44

# State 58
# Apply action "b5"
action: 74

# State 59
# Apply action "d3"
action: 42

# State 60
# Board size: 5, walls: 0, 0
#    a   b   c   d   e
#  1 .   .   .   . | .  1
#                  +
#  2 .   .   .   . | .  2
#           ---+---
#  3 .   .   .   @   .  3
#           ---+---
#  4 .   .   . | . | .  4
#   ---+---    +   +
#  5 .   0   . | . | .  5
#    a   b   c   d   e
IsTerminal() = False
History() = [63, 59, 7, 49, 61, 31, 74, 2, 76, 0, 58, 2, 76, 4, 58, 2, 76, 0, 74, 18, 72, 20, 74, 22, 72, 24, 74, 22, 76, 20, 74, 38, 72, 40, 74, 42, 76, 44, 74, 62, 72, 44, 74, 26, 76, 8, 58, 26, 76, 8, 74, 26, 72, 44, 74, 42, 76, 44, 74, 42]
HistoryString() = "63, 59, 7, 49, 61, 31, 74, 2, 76, 0, 58, 2, 76, 4, 58, 2, 76, 0, 74, 18, 72, 20, 74, 22, 72, 24, 74, 22, 76, 20, 74, 38, 72, 40, 74, 42, 76, 44, 74, 62, 72, 44, 74, 26, 76, 8, 58, 26, 76, 8, 74, 26, 72, 44, 74, 42, 76, 44, 74, 42"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "63, 59, 7, 49, 61, 31, 74, 2, 76, 0, 58, 2, 76, 4, 58, 2, 76, 0, 74, 18, 72, 20, 74, 22, 72, 24, 74, 22, 76, 20, 74, 38, 72, 40, 74, 42, 76, 44, 74, 62, 72, 44, 74, 26, 76, 8, 58, 26, 76, 8, 74, 26, 72, 44, 74, 42, 76, 44, 74, 42"
InformationStateString(1) = "63, 59, 7, 49, 61, 31, 74, 2, 76, 0, 58, 2, 76, 4, 58, 2, 76, 0, 74, 18, 72, 20, 74, 22, 72, 24, 74, 22, 76, 20, 74, 38, 72, 40, 74, 42, 76, 44, 74, 62, 72, 44, 74, 26, 76, 8, 58, 26, 76, 8, 74, 26, 72, 44, 74, 42, 76, 44, 74, 42"
ObservationString(0) = "Board size: 5, walls: 0, 0\n   a   b   c   d   e\n 1 .   .   .   . | .  1\n                 +     \n 2 .   .   .   . | .  2\n          ---+---      \n 3 .   .   .   @   .  3\n          ---+---      \n 4 .   .   . | . | .  4\n  ---+---    +   +     \n 5 .   0   . | . | .  5\n   a   b   c   d   e\n"
ObservationString(1) = "Board size: 5, walls: 0, 0\n   a   b   c   d   e\n 1 .   .   .   . | .  1\n                 +     \n 2 .   .   .   . | .  2\n          ---+---      \n 3 .   .   .   @   .  3\n          ---+---      \n 4 .   .   . | . | .  4\n  ---+---    +   +     \n 5 .   0   . | . | .  5\n   a   b   c   d   e\n"
ObservationTensor(0):
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◉◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◉◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◉◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◉◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [72, 76]
StringLegalActions() = ["a5", "c5"]

# Apply action "c5"
action: 76

# State 61
# Board size: 5, walls: 0, 0
#    a   b   c   d   e
#  1 .   .   .   . | .  1
#                  +
#  2 .   .   .   . | .  2
#           ---+---
#  3 .   .   .   @   .  3
#           ---+---
#  4 .   .   . | . | .  4
#   ---+---    +   +
#  5 .   .   0 | . | .  5
#    a   b   c   d   e
IsTerminal() = False
History() = [63, 59, 7, 49, 61, 31, 74, 2, 76, 0, 58, 2, 76, 4, 58, 2, 76, 0, 74, 18, 72, 20, 74, 22, 72, 24, 74, 22, 76, 20, 74, 38, 72, 40, 74, 42, 76, 44, 74, 62, 72, 44, 74, 26, 76, 8, 58, 26, 76, 8, 74, 26, 72, 44, 74, 42, 76, 44, 74, 42, 76]
HistoryString() = "63, 59, 7, 49, 61, 31, 74, 2, 76, 0, 58, 2, 76, 4, 58, 2, 76, 0, 74, 18, 72, 20, 74, 22, 72, 24, 74, 22, 76, 20, 74, 38, 72, 40, 74, 42, 76, 44, 74, 62, 72, 44, 74, 26, 76, 8, 58, 26, 76, 8, 74, 26, 72, 44, 74, 42, 76, 44, 74, 42, 76"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "63, 59, 7, 49, 61, 31, 74, 2, 76, 0, 58, 2, 76, 4, 58, 2, 76, 0, 74, 18, 72, 20, 74, 22, 72, 24, 74, 22, 76, 20, 74, 38, 72, 40, 74, 42, 76, 44, 74, 62, 72, 44, 74, 26, 76, 8, 58, 26, 76, 8, 74, 26, 72, 44, 74, 42, 76, 44, 74, 42, 76"
InformationStateString(1) = "63, 59, 7, 49, 61, 31, 74, 2, 76, 0, 58, 2, 76, 4, 58, 2, 76, 0, 74, 18, 72, 20, 74, 22, 72, 24, 74, 22, 76, 20, 74, 38, 72, 40, 74, 42, 76, 44, 74, 62, 72, 44, 74, 26, 76, 8, 58, 26, 76, 8, 74, 26, 72, 44, 74, 42, 76, 44, 74, 42, 76"
ObservationString(0) = "Board size: 5, walls: 0, 0\n   a   b   c   d   e\n 1 .   .   .   . | .  1\n                 +     \n 2 .   .   .   . | .  2\n          ---+---      \n 3 .   .   .   @   .  3\n          ---+---      \n 4 .   .   . | . | .  4\n  ---+---    +   +     \n 5 .   .   0 | . | .  5\n   a   b   c   d   e\n"
ObservationString(1) = "Board size: 5, walls: 0, 0\n   a   b   c   d   e\n 1 .   .   .   . | .  1\n                 +     \n 2 .   .   .   . | .  2\n          ---+---      \n 3 .   .   .   @   .  3\n          ---+---      \n 4 .   .   . | . | .  4\n  ---+---    +   +     \n 5 .   .   0 | . | .  5\n   a   b   c   d   e\n"
ObservationTensor(0):
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◉◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◉◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◉◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◉◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [40, 44]
StringLegalActions() = ["c3", "e3"]

# Apply action "c3"
action: 40

# State 62
# Apply action "b5"
action: 74

# State 63
# Apply action "b3"
action: 38

# State 64
# Apply action "a5"
action: 72

# State 65
# Apply action "a3"
action: 36

# State 66
# Apply action "b5"
action: 74

# State 67
# Apply action "a4"
action: 54

# State 68
# Apply action "a5"
action: 72

# State 69
# Apply action "a3"
action: 36

# State 70
# Apply action "b5"
action: 74

# State 71
# Apply action "b3"
action: 38

# State 72
# Apply action "c5"
action: 76

# State 73
# Apply action "b2"
action: 20

# State 74
# Apply action "b5"
action: 74

# State 75
# Apply action "c2"
action: 22

# State 76
# Apply action "a5"
action: 72

# State 77
# Apply action "c1"
action: 4

# State 78
# Apply action "b5"
action: 74

# State 79
# Apply action "b1"
action: 2

# State 80
# Board size: 5, walls: 0, 0
#    a   b   c   d   e
#  1 .   @   .   . | .  1
#                  +
#  2 .   .   .   . | .  2
#           ---+---
#  3 .   .   .   .   .  3
#           ---+---
#  4 .   .   . | . | .  4
#   ---+---    +   +
#  5 .   0   . | . | .  5
#    a   b   c   d   e
IsTerminal() = False
History() = [63, 59, 7, 49, 61, 31, 74, 2, 76, 0, 58, 2, 76, 4, 58, 2, 76, 0, 74, 18, 72, 20, 74, 22, 72, 24, 74, 22, 76, 20, 74, 38, 72, 40, 74, 42, 76, 44, 74, 62, 72, 44, 74, 26, 76, 8, 58, 26, 76, 8, 74, 26, 72, 44, 74, 42, 76, 44, 74, 42, 76, 40, 74, 38, 72, 36, 74, 54, 72, 36, 74, 38, 76, 20, 74, 22, 72, 4, 74, 2]
HistoryString() = "63, 59, 7, 49, 61, 31, 74, 2, 76, 0, 58, 2, 76, 4, 58, 2, 76, 0, 74, 18, 72, 20, 74, 22, 72, 24, 74, 22, 76, 20, 74, 38, 72, 40, 74, 42, 76, 44, 74, 62, 72, 44, 74, 26, 76, 8, 58, 26, 76, 8, 74, 26, 72, 44, 74, 42, 76, 44, 74, 42, 76, 40, 74, 38, 72, 36, 74, 54, 72, 36, 74, 38, 76, 20, 74, 22, 72, 4, 74, 2"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "63, 59, 7, 49, 61, 31, 74, 2, 76, 0, 58, 2, 76, 4, 58, 2, 76, 0, 74, 18, 72, 20, 74, 22, 72, 24, 74, 22, 76, 20, 74, 38, 72, 40, 74, 42, 76, 44, 74, 62, 72, 44, 74, 26, 76, 8, 58, 26, 76, 8, 74, 26, 72, 44, 74, 42, 76, 44, 74, 42, 76, 40, 74, 38, 72, 36, 74, 54, 72, 36, 74, 38, 76, 20, 74, 22, 72, 4, 74, 2"
InformationStateString(1) = "63, 59, 7, 49, 61, 31, 74, 2, 76, 0, 58, 2, 76, 4, 58, 2, 76, 0, 74, 18, 72, 20, 74, 22, 72, 24, 74, 22, 76, 20, 74, 38, 72, 40, 74, 42, 76, 44, 74, 62, 72, 44, 74, 26, 76, 8, 58, 26, 76, 8, 74, 26, 72, 44, 74, 42, 76, 44, 74, 42, 76, 40, 74, 38, 72, 36, 74, 54, 72, 36, 74, 38, 76, 20, 74, 22, 72, 4, 74, 2"
ObservationString(0) = "Board size: 5, walls: 0, 0\n   a   b   c   d   e\n 1 .   @   .   . | .  1\n                 +     \n 2 .   .   .   . | .  2\n          ---+---      \n 3 .   .   .   .   .  3\n          ---+---      \n 4 .   .   . | . | .  4\n  ---+---    +   +     \n 5 .   0   . | . | .  5\n   a   b   c   d   e\n"
ObservationString(1) = "Board size: 5, walls: 0, 0\n   a   b   c   d   e\n 1 .   @   .   . | .  1\n                 +     \n 2 .   .   .   . | .  2\n          ---+---      \n 3 .   .   .   .   .  3\n          ---+---      \n 4 .   .   . | . | .  4\n  ---+---    +   +     \n 5 .   0   . | . | .  5\n   a   b   c   d   e\n"
ObservationTensor(0):
◯◯◯◯◯◯◯◯◯  ◯◯◉◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◉◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◯◯◯◯  ◯◯◉◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◉◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [72, 76]
StringLegalActions() = ["a5", "c5"]

# Apply action "c5"
action: 76

# State 81
# Board size: 5, walls: 0, 0
#    a   b   c   d   e
#  1 .   @   .   . | .  1
#                  +
#  2 .   .   .   . | .  2
#           ---+---
#  3 .   .   .   .   .  3
#           ---+---
#  4 .   .   . | . | .  4
#   ---+---    +   +
#  5 .   .   0 | . | .  5
#    a   b   c   d   e
IsTerminal() = False
History() = [63, 59, 7, 49, 61, 31, 74, 2, 76, 0, 58, 2, 76, 4, 58, 2, 76, 0, 74, 18, 72, 20, 74, 22, 72, 24, 74, 22, 76, 20, 74, 38, 72, 40, 74, 42, 76, 44, 74, 62, 72, 44, 74, 26, 76, 8, 58, 26, 76, 8, 74, 26, 72, 44, 74, 42, 76, 44, 74, 42, 76, 40, 74, 38, 72, 36, 74, 54, 72, 36, 74, 38, 76, 20, 74, 22, 72, 4, 74, 2, 76]
HistoryString() = "63, 59, 7, 49, 61, 31, 74, 2, 76, 0, 58, 2, 76, 4, 58, 2, 76, 0, 74, 18, 72, 20, 74, 22, 72, 24, 74, 22, 76, 20, 74, 38, 72, 40, 74, 42, 76, 44, 74, 62, 72, 44, 74, 26, 76, 8, 58, 26, 76, 8, 74, 26, 72, 44, 74, 42, 76, 44, 74, 42, 76, 40, 74, 38, 72, 36, 74, 54, 72, 36, 74, 38, 76, 20, 74, 22, 72, 4, 74, 2, 76"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 1
InformationStateString(0) = "63, 59, 7, 49, 61, 31, 74, 2, 76, 0, 58, 2, 76, 4, 58, 2, 76, 0, 74, 18, 72, 20, 74, 22, 72, 24, 74, 22, 76, 20, 74, 38, 72, 40, 74, 42, 76, 44, 74, 62, 72, 44, 74, 26, 76, 8, 58, 26, 76, 8, 74, 26, 72, 44, 74, 42, 76, 44, 74, 42, 76, 40, 74, 38, 72, 36, 74, 54, 72, 36, 74, 38, 76, 20, 74, 22, 72, 4, 74, 2, 76"
InformationStateString(1) = "63, 59, 7, 49, 61, 31, 74, 2, 76, 0, 58, 2, 76, 4, 58, 2, 76, 0, 74, 18, 72, 20, 74, 22, 72, 24, 74, 22, 76, 20, 74, 38, 72, 40, 74, 42, 76, 44, 74, 62, 72, 44, 74, 26, 76, 8, 58, 26, 76, 8, 74, 26, 72, 44, 74, 42, 76, 44, 74, 42, 76, 40, 74, 38, 72, 36, 74, 54, 72, 36, 74, 38, 76, 20, 74, 22, 72, 4, 74, 2, 76"
ObservationString(0) = "Board size: 5, walls: 0, 0\n   a   b   c   d   e\n 1 .   @   .   . | .  1\n                 +     \n 2 .   .   .   . | .  2\n          ---+---      \n 3 .   .   .   .   .  3\n          ---+---      \n 4 .   .   . | . | .  4\n  ---+---    +   +     \n 5 .   .   0 | . | .  5\n   a   b   c   d   e\n"
ObservationString(1) = "Board size: 5, walls: 0, 0\n   a   b   c   d   e\n 1 .   @   .   . | .  1\n                 +     \n 2 .   .   .   . | .  2\n          ---+---      \n 3 .   .   .   .   .  3\n          ---+---      \n 4 .   .   . | . | .  4\n  ---+---    +   +     \n 5 .   .   0 | . | .  5\n   a   b   c   d   e\n"
ObservationTensor(0):
◯◯◯◯◯◯◯◯◯  ◯◯◉◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◉◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◯◯◯◯  ◯◯◉◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◉◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
LegalActions() = [0, 4, 20]
StringLegalActions() = ["a1", "c1", "b2"]

# Apply action "a1"
action: 0

# State 82
# Apply action "b5"
action: 74

# State 83
# Apply action "a2"
action: 18

# State 84
# Apply action "a5"
action: 72

# State 85
# Apply action "a1"
action: 0

# State 86
# Apply action "b5"
action: 74

# State 87
# Apply action "a2"
action: 18

# State 88
# Apply action "a5"
action: 72

# State 89
# Apply action "b2"
action: 20

# State 90
# Apply action "b5"
action: 74

# State 91
# Apply action "a2"
action: 18

# State 92
# Apply action "c5"
action: 76

# State 93
# Apply action "a3"
action: 36

# State 94
# Apply action "c4"
action: 58

# State 95
# Apply action "a4"
action: 54

# State 96
# Apply action "b4"
action: 56

# State 97
# Apply action "a3"
action: 36

# State 98
# Apply action "c4"
action: 58

# State 99
# Apply action "b3"
action: 38

# State 100
# Board size: 5, walls: 0, 0
#    a   b   c   d   e
#  1 .   .   .   . | .  1
#                  +
#  2 .   .   .   . | .  2
#           ---+---
#  3 .   @   .   .   .  3
#           ---+---
#  4 .   .   0 | . | .  4
#   ---+---    +   +
#  5 .   .   . | . | .  5
#    a   b   c   d   e
IsTerminal() = True
History() = [63, 59, 7, 49, 61, 31, 74, 2, 76, 0, 58, 2, 76, 4, 58, 2, 76, 0, 74, 18, 72, 20, 74, 22, 72, 24, 74, 22, 76, 20, 74, 38, 72, 40, 74, 42, 76, 44, 74, 62, 72, 44, 74, 26, 76, 8, 58, 26, 76, 8, 74, 26, 72, 44, 74, 42, 76, 44, 74, 42, 76, 40, 74, 38, 72, 36, 74, 54, 72, 36, 74, 38, 76, 20, 74, 22, 72, 4, 74, 2, 76, 0, 74, 18, 72, 0, 74, 18, 72, 20, 74, 18, 76, 36, 58, 54, 56, 36, 58, 38]
HistoryString() = "63, 59, 7, 49, 61, 31, 74, 2, 76, 0, 58, 2, 76, 4, 58, 2, 76, 0, 74, 18, 72, 20, 74, 22, 72, 24, 74, 22, 76, 20, 74, 38, 72, 40, 74, 42, 76, 44, 74, 62, 72, 44, 74, 26, 76, 8, 58, 26, 76, 8, 74, 26, 72, 44, 74, 42, 76, 44, 74, 42, 76, 40, 74, 38, 72, 36, 74, 54, 72, 36, 74, 38, 76, 20, 74, 22, 72, 4, 74, 2, 76, 0, 74, 18, 72, 0, 74, 18, 72, 20, 74, 18, 76, 36, 58, 54, 56, 36, 58, 38"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = -4
InformationStateString(0) = "63, 59, 7, 49, 61, 31, 74, 2, 76, 0, 58, 2, 76, 4, 58, 2, 76, 0, 74, 18, 72, 20, 74, 22, 72, 24, 74, 22, 76, 20, 74, 38, 72, 40, 74, 42, 76, 44, 74, 62, 72, 44, 74, 26, 76, 8, 58, 26, 76, 8, 74, 26, 72, 44, 74, 42, 76, 44, 74, 42, 76, 40, 74, 38, 72, 36, 74, 54, 72, 36, 74, 38, 76, 20, 74, 22, 72, 4, 74, 2, 76, 0, 74, 18, 72, 0, 74, 18, 72, 20, 74, 18, 76, 36, 58, 54, 56, 36, 58, 38"
InformationStateString(1) = "63, 59, 7, 49, 61, 31, 74, 2, 76, 0, 58, 2, 76, 4, 58, 2, 76, 0, 74, 18, 72, 20, 74, 22, 72, 24, 74, 22, 76, 20, 74, 38, 72, 40, 74, 42, 76, 44, 74, 62, 72, 44, 74, 26, 76, 8, 58, 26, 76, 8, 74, 26, 72, 44, 74, 42, 76, 44, 74, 42, 76, 40, 74, 38, 72, 36, 74, 54, 72, 36, 74, 38, 76, 20, 74, 22, 72, 4, 74, 2, 76, 0, 74, 18, 72, 0, 74, 18, 72, 20, 74, 18, 76, 36, 58, 54, 56, 36, 58, 38"
ObservationString(0) = "Board size: 5, walls: 0, 0\n   a   b   c   d   e\n 1 .   .   .   . | .  1\n                 +     \n 2 .   .   .   . | .  2\n          ---+---      \n 3 .   @   .   .   .  3\n          ---+---      \n 4 .   .   0 | . | .  4\n  ---+---    +   +     \n 5 .   .   . | . | .  5\n   a   b   c   d   e\n"
ObservationString(1) = "Board size: 5, walls: 0, 0\n   a   b   c   d   e\n 1 .   .   .   . | .  1\n                 +     \n 2 .   .   .   . | .  2\n          ---+---      \n 3 .   @   .   .   .  3\n          ---+---      \n 4 .   .   0 | . | .  4\n  ---+---    +   +     \n 5 .   .   . | . | .  5\n   a   b   c   d   e\n"
ObservationTensor(0):
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◉◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◉◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
ObservationTensor(1):
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◉◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◉◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯  ◯◯◯◯◯◯◯◯◯
Rewards() = [0.0, 0.0]
Returns() = [0.0, 0.0]
