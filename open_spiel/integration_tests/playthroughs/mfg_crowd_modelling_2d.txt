game: mfg_crowd_modelling_2d

GameType.chance_mode = ChanceMode.EXPLICIT_STOCHASTIC
GameType.dynamics = Dynamics.MEAN_FIELD
GameType.information = Information.PERFECT_INFORMATION
GameType.long_name = "Mean Field Crowd Modelling 2D"
GameType.max_num_players = 1
GameType.min_num_players = 1
GameType.parameter_specification = ["forbidden_states", "horizon", "initial_distribution", "initial_distribution_value", "only_distribution_reward", "size"]
GameType.provides_information_state_string = True
GameType.provides_information_state_tensor = False
GameType.provides_observation_string = True
GameType.provides_observation_tensor = True
GameType.provides_factored_observation_string = False
GameType.reward_model = RewardModel.REWARDS
GameType.short_name = "mfg_crowd_modelling_2d"
GameType.utility = Utility.GENERAL_SUM

NumDistinctActions() = 5
PolicyTensorShape() = [5]
MaxChanceOutcomes() = 10
GetParameters() = {forbidden_states=[],horizon=10,initial_distribution=[],initial_distribution_value=[],only_distribution_reward=False,size=10}
NumPlayers() = 1
MinUtility() = -inf
MaxUtility() = inf
UtilitySum() = 0.0
MaxGameLength() = 10
ToString() = "mfg_crowd_modelling_2d()"

# State 0
# initial
IsTerminal() = False
History() = []
HistoryString() = ""
IsChanceNode() = True
IsSimultaneousNode() = False
CurrentPlayer() = -1
InformationStateString(0) = ""
ChanceOutcomes() = [(0, 0.01), (1, 0.01), (2, 0.01), (3, 0.01), (4, 0.01), (5, 0.01), (6, 0.01), (7, 0.01), (8, 0.01), (9, 0.01), (10, 0.01), (11, 0.01), (12, 0.01), (13, 0.01), (14, 0.01), (15, 0.01), (16, 0.01), (17, 0.01), (18, 0.01), (19, 0.01), (20, 0.01), (21, 0.01), (22, 0.01), (23, 0.01), (24, 0.01), (25, 0.01), (26, 0.01), (27, 0.01), (28, 0.01), (29, 0.01), (30, 0.01), (31, 0.01), (32, 0.01), (33, 0.01), (34, 0.01), (35, 0.01), (36, 0.01), (37, 0.01), (38, 0.01), (39, 0.01), (40, 0.01), (41, 0.01), (42, 0.01), (43, 0.01), (44, 0.01), (45, 0.01), (46, 0.01), (47, 0.01), (48, 0.01), (49, 0.01), (50, 0.01), (51, 0.01), (52, 0.01), (53, 0.01), (54, 0.01), (55, 0.01), (56, 0.01), (57, 0.01), (58, 0.01), (59, 0.01), (60, 0.01), (61, 0.01), (62, 0.01), (63, 0.01), (64, 0.01), (65, 0.01), (66, 0.01), (67, 0.01), (68, 0.01), (69, 0.01), (70, 0.01), (71, 0.01), (72, 0.01), (73, 0.01), (74, 0.01), (75, 0.01), (76, 0.01), (77, 0.01), (78, 0.01), (79, 0.01), (80, 0.01), (81, 0.01), (82, 0.01), (83, 0.01), (84, 0.01), (85, 0.01), (86, 0.01), (87, 0.01), (88, 0.01), (89, 0.01), (90, 0.01), (91, 0.01), (92, 0.01), (93, 0.01), (94, 0.01), (95, 0.01), (96, 0.01), (97, 0.01), (98, 0.01), (99, 0.01)]
LegalActions() = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]
StringLegalActions() = ["init_state=0", "init_state=1", "init_state=2", "init_state=3", "init_state=4", "init_state=5", "init_state=6", "init_state=7", "init_state=8", "init_state=9", "init_state=10", "init_state=11", "init_state=12", "init_state=13", "init_state=14", "init_state=15", "init_state=16", "init_state=17", "init_state=18", "init_state=19", "init_state=20", "init_state=21", "init_state=22", "init_state=23", "init_state=24", "init_state=25", "init_state=26", "init_state=27", "init_state=28", "init_state=29", "init_state=30", "init_state=31", "init_state=32", "init_state=33", "init_state=34", "init_state=35", "init_state=36", "init_state=37", "init_state=38", "init_state=39", "init_state=40", "init_state=41", "init_state=42", "init_state=43", "init_state=44", "init_state=45", "init_state=46", "init_state=47", "init_state=48", "init_state=49", "init_state=50", "init_state=51", "init_state=52", "init_state=53", "init_state=54", "init_state=55", "init_state=56", "init_state=57", "init_state=58", "init_state=59", "init_state=60", "init_state=61", "init_state=62", "init_state=63", "init_state=64", "init_state=65", "init_state=66", "init_state=67", "init_state=68", "init_state=69", "init_state=70", "init_state=71", "init_state=72", "init_state=73", "init_state=74", "init_state=75", "init_state=76", "init_state=77", "init_state=78", "init_state=79", "init_state=80", "init_state=81", "init_state=82", "init_state=83", "init_state=84", "init_state=85", "init_state=86", "init_state=87", "init_state=88", "init_state=89", "init_state=90", "init_state=91", "init_state=92", "init_state=93", "init_state=94", "init_state=95", "init_state=96", "init_state=97", "init_state=98", "init_state=99"]

# Apply action "init_state=78"
action: 78

# State 1
# (8, 7, 0)
IsTerminal() = False
History() = [78]
HistoryString() = "78"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "78"
Rewards() = [5.605170185988091]
Returns() = [5.605170185988091]
LegalActions() = [0, 1, 2, 3, 4]
StringLegalActions() = ["(0,-1)", "(-1,0)", "(0,0)", "(1,0)", "(0,1)"]

# Apply action "(0,1)"
action: 4

# State 2
# (8, 8, 0)_a
IsTerminal() = False
History() = [78, 4]
HistoryString() = "78, 4"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = -5
InformationStateString(0) = "78, 4"
Rewards() = [0.0]
Returns() = [5.605170185988091]
DistributionSupport() = ['(0, 0, 0)', '(0, 1, 0)', '(0, 2, 0)', '(0, 3, 0)', '(0, 4, 0)', '(0, 5, 0)', '(0, 6, 0)', '(0, 7, 0)', '(0, 8, 0)', '(0, 9, 0)', '(1, 0, 0)', '(1, 1, 0)', '(1, 2, 0)', '(1, 3, 0)', '(1, 4, 0)', '(1, 5, 0)', '(1, 6, 0)', '(1, 7, 0)', '(1, 8, 0)', '(1, 9, 0)', '(2, 0, 0)', '(2, 1, 0)', '(2, 2, 0)', '(2, 3, 0)', '(2, 4, 0)', '(2, 5, 0)', '(2, 6, 0)', '(2, 7, 0)', '(2, 8, 0)', '(2, 9, 0)', '(3, 0, 0)', '(3, 1, 0)', '(3, 2, 0)', '(3, 3, 0)', '(3, 4, 0)', '(3, 5, 0)', '(3, 6, 0)', '(3, 7, 0)', '(3, 8, 0)', '(3, 9, 0)', '(4, 0, 0)', '(4, 1, 0)', '(4, 2, 0)', '(4, 3, 0)', '(4, 4, 0)', '(4, 5, 0)', '(4, 6, 0)', '(4, 7, 0)', '(4, 8, 0)', '(4, 9, 0)', '(5, 0, 0)', '(5, 1, 0)', '(5, 2, 0)', '(5, 3, 0)', '(5, 4, 0)', '(5, 5, 0)', '(5, 6, 0)', '(5, 7, 0)', '(5, 8, 0)', '(5, 9, 0)', '(6, 0, 0)', '(6, 1, 0)', '(6, 2, 0)', '(6, 3, 0)', '(6, 4, 0)', '(6, 5, 0)', '(6, 6, 0)', '(6, 7, 0)', '(6, 8, 0)', '(6, 9, 0)', '(7, 0, 0)', '(7, 1, 0)', '(7, 2, 0)', '(7, 3, 0)', '(7, 4, 0)', '(7, 5, 0)', '(7, 6, 0)', '(7, 7, 0)', '(7, 8, 0)', '(7, 9, 0)', '(8, 0, 0)', '(8, 1, 0)', '(8, 2, 0)', '(8, 3, 0)', '(8, 4, 0)', '(8, 5, 0)', '(8, 6, 0)', '(8, 7, 0)', '(8, 8, 0)', '(8, 9, 0)', '(9, 0, 0)', '(9, 1, 0)', '(9, 2, 0)', '(9, 3, 0)', '(9, 4, 0)', '(9, 5, 0)', '(9, 6, 0)', '(9, 7, 0)', '(9, 8, 0)', '(9, 9, 0)']

# Set mean field distribution to be uniform
action: update_distribution

# State 3
# (8, 8, 0)_a_mu
IsTerminal() = False
History() = [78, 4]
HistoryString() = "78, 4"
IsChanceNode() = True
IsSimultaneousNode() = False
CurrentPlayer() = -1
InformationStateString(0) = "78, 4"
ChanceOutcomes() = [(0, 0.2), (1, 0.2), (2, 0.2), (3, 0.2), (4, 0.2)]
LegalActions() = [0, 1, 2, 3, 4]
StringLegalActions() = ["(0,-1)", "(-1,0)", "(0,0)", "(1,0)", "(0,1)"]

# Apply action "(0,1)"
action: 4

# State 4
# (8, 9, 1)
IsTerminal() = False
History() = [78, 4, 4]
HistoryString() = "78, 4, 4"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "78, 4, 4"
Rewards() = [5.105170185988091]
Returns() = [10.710340371976182]
LegalActions() = [0, 1, 2, 3, 4]
StringLegalActions() = ["(0,-1)", "(-1,0)", "(0,0)", "(1,0)", "(0,1)"]

# Apply action "(0,-1)"
action: 0

# State 5
# (8, 8, 1)_a
IsTerminal() = False
History() = [78, 4, 4, 0]
HistoryString() = "78, 4, 4, 0"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = -5
InformationStateString(0) = "78, 4, 4, 0"
Rewards() = [0.0]
Returns() = [10.710340371976182]
DistributionSupport() = ['(0, 0, 1)', '(0, 1, 1)', '(0, 2, 1)', '(0, 3, 1)', '(0, 4, 1)', '(0, 5, 1)', '(0, 6, 1)', '(0, 7, 1)', '(0, 8, 1)', '(0, 9, 1)', '(1, 0, 1)', '(1, 1, 1)', '(1, 2, 1)', '(1, 3, 1)', '(1, 4, 1)', '(1, 5, 1)', '(1, 6, 1)', '(1, 7, 1)', '(1, 8, 1)', '(1, 9, 1)', '(2, 0, 1)', '(2, 1, 1)', '(2, 2, 1)', '(2, 3, 1)', '(2, 4, 1)', '(2, 5, 1)', '(2, 6, 1)', '(2, 7, 1)', '(2, 8, 1)', '(2, 9, 1)', '(3, 0, 1)', '(3, 1, 1)', '(3, 2, 1)', '(3, 3, 1)', '(3, 4, 1)', '(3, 5, 1)', '(3, 6, 1)', '(3, 7, 1)', '(3, 8, 1)', '(3, 9, 1)', '(4, 0, 1)', '(4, 1, 1)', '(4, 2, 1)', '(4, 3, 1)', '(4, 4, 1)', '(4, 5, 1)', '(4, 6, 1)', '(4, 7, 1)', '(4, 8, 1)', '(4, 9, 1)', '(5, 0, 1)', '(5, 1, 1)', '(5, 2, 1)', '(5, 3, 1)', '(5, 4, 1)', '(5, 5, 1)', '(5, 6, 1)', '(5, 7, 1)', '(5, 8, 1)', '(5, 9, 1)', '(6, 0, 1)', '(6, 1, 1)', '(6, 2, 1)', '(6, 3, 1)', '(6, 4, 1)', '(6, 5, 1)', '(6, 6, 1)', '(6, 7, 1)', '(6, 8, 1)', '(6, 9, 1)', '(7, 0, 1)', '(7, 1, 1)', '(7, 2, 1)', '(7, 3, 1)', '(7, 4, 1)', '(7, 5, 1)', '(7, 6, 1)', '(7, 7, 1)', '(7, 8, 1)', '(7, 9, 1)', '(8, 0, 1)', '(8, 1, 1)', '(8, 2, 1)', '(8, 3, 1)', '(8, 4, 1)', '(8, 5, 1)', '(8, 6, 1)', '(8, 7, 1)', '(8, 8, 1)', '(8, 9, 1)', '(9, 0, 1)', '(9, 1, 1)', '(9, 2, 1)', '(9, 3, 1)', '(9, 4, 1)', '(9, 5, 1)', '(9, 6, 1)', '(9, 7, 1)', '(9, 8, 1)', '(9, 9, 1)']

# Set mean field distribution to be uniform
action: update_distribution

# State 6
# Apply action "(0,1)"
action: 4

# State 7
# (8, 9, 2)
IsTerminal() = False
History() = [78, 4, 4, 0, 4]
HistoryString() = "78, 4, 4, 0, 4"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = 0
InformationStateString(0) = "78, 4, 4, 0, 4"
Rewards() = [5.105170185988091]
Returns() = [15.815510557964274]
LegalActions() = [0, 1, 2, 3, 4]
StringLegalActions() = ["(0,-1)", "(-1,0)", "(0,0)", "(1,0)", "(0,1)"]

# Apply action "(0,-1)"
action: 0

# State 8
# (8, 8, 2)_a
IsTerminal() = False
History() = [78, 4, 4, 0, 4, 0]
HistoryString() = "78, 4, 4, 0, 4, 0"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = -5
InformationStateString(0) = "78, 4, 4, 0, 4, 0"
Rewards() = [0.0]
Returns() = [15.815510557964274]
DistributionSupport() = ['(0, 0, 2)', '(0, 1, 2)', '(0, 2, 2)', '(0, 3, 2)', '(0, 4, 2)', '(0, 5, 2)', '(0, 6, 2)', '(0, 7, 2)', '(0, 8, 2)', '(0, 9, 2)', '(1, 0, 2)', '(1, 1, 2)', '(1, 2, 2)', '(1, 3, 2)', '(1, 4, 2)', '(1, 5, 2)', '(1, 6, 2)', '(1, 7, 2)', '(1, 8, 2)', '(1, 9, 2)', '(2, 0, 2)', '(2, 1, 2)', '(2, 2, 2)', '(2, 3, 2)', '(2, 4, 2)', '(2, 5, 2)', '(2, 6, 2)', '(2, 7, 2)', '(2, 8, 2)', '(2, 9, 2)', '(3, 0, 2)', '(3, 1, 2)', '(3, 2, 2)', '(3, 3, 2)', '(3, 4, 2)', '(3, 5, 2)', '(3, 6, 2)', '(3, 7, 2)', '(3, 8, 2)', '(3, 9, 2)', '(4, 0, 2)', '(4, 1, 2)', '(4, 2, 2)', '(4, 3, 2)', '(4, 4, 2)', '(4, 5, 2)', '(4, 6, 2)', '(4, 7, 2)', '(4, 8, 2)', '(4, 9, 2)', '(5, 0, 2)', '(5, 1, 2)', '(5, 2, 2)', '(5, 3, 2)', '(5, 4, 2)', '(5, 5, 2)', '(5, 6, 2)', '(5, 7, 2)', '(5, 8, 2)', '(5, 9, 2)', '(6, 0, 2)', '(6, 1, 2)', '(6, 2, 2)', '(6, 3, 2)', '(6, 4, 2)', '(6, 5, 2)', '(6, 6, 2)', '(6, 7, 2)', '(6, 8, 2)', '(6, 9, 2)', '(7, 0, 2)', '(7, 1, 2)', '(7, 2, 2)', '(7, 3, 2)', '(7, 4, 2)', '(7, 5, 2)', '(7, 6, 2)', '(7, 7, 2)', '(7, 8, 2)', '(7, 9, 2)', '(8, 0, 2)', '(8, 1, 2)', '(8, 2, 2)', '(8, 3, 2)', '(8, 4, 2)', '(8, 5, 2)', '(8, 6, 2)', '(8, 7, 2)', '(8, 8, 2)', '(8, 9, 2)', '(9, 0, 2)', '(9, 1, 2)', '(9, 2, 2)', '(9, 3, 2)', '(9, 4, 2)', '(9, 5, 2)', '(9, 6, 2)', '(9, 7, 2)', '(9, 8, 2)', '(9, 9, 2)']

# Set mean field distribution to be uniform
action: update_distribution

# State 9
# Apply action "(0,-1)"
action: 0

# State 10
# Apply action "(-1,0)"
action: 1

# State 11
# Set mean field distribution to be uniform
action: update_distribution

# State 12
# Apply action "(-1,0)"
action: 1

# State 13
# Apply action "(0,-1)"
action: 0

# State 14
# Set mean field distribution to be uniform
action: update_distribution

# State 15
# Apply action "(0,0)"
action: 2

# State 16
# Apply action "(0,-1)"
action: 0

# State 17
# Set mean field distribution to be uniform
action: update_distribution

# State 18
# Apply action "(0,-1)"
action: 0

# State 19
# Apply action "(1,0)"
action: 3

# State 20
# Set mean field distribution to be uniform
action: update_distribution

# State 21
# Apply action "(1,0)"
action: 3

# State 22
# Apply action "(0,-1)"
action: 0

# State 23
# Set mean field distribution to be uniform
action: update_distribution

# State 24
# Apply action "(0,-1)"
action: 0

# State 25
# Apply action "(0,0)"
action: 2

# State 26
# Set mean field distribution to be uniform
action: update_distribution

# State 27
# Apply action "(1,0)"
action: 3

# State 28
# Apply action "(-1,0)"
action: 1

# State 29
# Set mean field distribution to be uniform
action: update_distribution

# State 30
# Apply action "(-1,0)"
action: 1

# State 31
# (7, 2, 10)
IsTerminal() = True
History() = [78, 4, 4, 0, 4, 0, 0, 1, 1, 0, 2, 0, 0, 3, 3, 0, 0, 2, 3, 1, 1]
HistoryString() = "78, 4, 4, 0, 4, 0, 0, 1, 1, 0, 2, 0, 0, 3, 3, 0, 0, 2, 3, 1, 1"
IsChanceNode() = False
IsSimultaneousNode() = False
CurrentPlayer() = -4
InformationStateString(0) = "78, 4, 4, 0, 4, 0, 0, 1, 1, 0, 2, 0, 0, 3, 3, 0, 0, 2, 3, 1, 1"
Rewards() = [5.505170185988091]
Returns() = [61.156872045869]
